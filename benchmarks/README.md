# Benchmarking

The two main benchmarking scripts are 
  - `experiment_runner.py` to run benchmark experiments, and 
  - `result_analyzer.py` to aggregate the benchmark result in CSV form.


## Experiment runner

Run the `experiment_runner.py` from the `pytorch` directory, which should be the
parent of the `xla` directory.

The following example runs the alexnet benchmark on GPU through the
Pytorch/XLA-dynamo path and through the Inductor-dynamo with 5 repetitions each.
The results will be stored in a json file in `experiment_results`.

```
cd pytorch
python xla/benchmarks/experiment_runner.py                   \
    --dynamo=openxla_eval --dynamo=openxla --dynamo=inductor \
    --xla=PJRT --xla=None                                    \
    --test=eval --test=train                                 \
    --suite-name=torchbench                                  \
    --accelerator=cuda                                       \
    --output-dirname=experiment_results                      \
    --repeat=5                                               \
    --print-subprocess                                       \
    --no-resume                                              \
    --filter="^alexnet$"
```

You can change the flags to add the configurations you are interested in. The
`experiment_runner.py` will expand the options to all supported configurations.
For example, in the case above, it will consider all the possible combinations
among the flags `--dynamo`, `--xla`, and `--test`, 4 of which are supported:

  - `dynamo=openxla_eval`, `xla=PJRT`, `test=eval`
  - `dynamo=openxla`, `xla=PJRT`, `test=train`
  - `dynamo=inductor`, `xla=None`, `test=eval`
  - `dynamo=inductor`, `xla=None`, `test=train`


## Result analyzer

Run the `result_analyzer.py` from the `pytorch` directory, which should be the
parent of the `xla` directory.

The following example analyzes the results generated by the above invocation of
`experiment_runner.py`. The aggregates are saved in CSV format in
`experiment_results/metric_report.csv`.

```
cd pytorch
python xla/benchmarks/result_analyzer.py --output-dirname=experiment_results
```
