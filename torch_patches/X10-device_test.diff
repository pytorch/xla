diff --git a/test/common_device_type.py b/test/common_device_type.py
index b3352182c6..5818f994c4 100644
--- a/test/common_device_type.py
+++ b/test/common_device_type.py
@@ -216,10 +216,81 @@ class CUDATestBase(DeviceTypeTestBase):
         cls.primary_device = 'cuda:{0}'.format(torch.cuda.current_device())
 
 
+import torch_xla
+import torch_xla.core.xla_model as xm
+
+# Acquires XLA test metadata
+import os
+from runpy import run_path
+assert 'XLA_TEST_DIR' in os.environ, "XLA_TEST_DIR environment variable must be set"
+xla_test_path = os.environ['XLA_TEST_DIR']
+xla_meta_path = xla_test_path + "/torch_test_meta.py"
+xla_meta = run_path(xla_meta_path)
+assert xla_meta, "XLA metadata not found!"
+allowed_torch_tests = xla_meta.get('allowed_torch_tests', None)
+assert allowed_torch_tests is not None, "XLA tests not found!"
+
+
+class XLATestBase(DeviceTypeTestBase):
+    device_type = 'xla'
+    unsupported_dtypes = {torch.half}
+
+    # Overrides to instantiate tests that are known to run quickly
+    # and correctly on XLA.
+    @classmethod
+    def instantiate_test(cls, name, test):
+        test_name = name + "_" + cls.device_type
+        if test_name not in allowed_torch_tests and test.__name__ not in allowed_torch_tests:
+            assert not hasattr(cls, test_name), "Redefinition of test {0}".format(test_name)
+
+            @wraps(test)
+            def disallowed_test(self, test=test):
+                raise unittest.SkipTest("skipped on XLA")
+                return test(self, cls.device_type)
+
+            setattr(cls, test_name, disallowed_test)
+        else:  # Test is allowed
+            dtypes = cls._get_dtypes(test)
+            if dtypes is None:  # Tests without dtype variants are instantiated as usual
+                super().instantiate_test(name, test)
+            else:  # Tests with dtype variants have unsupported dtypes skipped
+                skipped_dtypes = [dtype for dtype in dtypes if dtype in cls.unsupported_dtypes]
+
+                # Skips unsupported dtypes
+                for dtype in skipped_dtypes:
+                    dtype_str = str(dtype).split('.')[1]
+                    dtype_test_name = test_name + "_" + dtype_str
+                    reason = "XLA does not support dtype {0}".format(str(dtype))
+
+                    @wraps(test)
+                    def skipped_test(self, test=test, reason=reason):
+                        raise unittest.SkipTest(reason)
+                        return test(self, cls.device_type)
+
+                    assert not hasattr(cls, dtype_test_name), "Redefinition of test {0}".format(dtype_test_name)
+                    setattr(cls, dtype_test_name, skipped_test)
+
+                # Instantiates supported dtypes as normal
+                xla_dtypes = [dtype for dtype in dtypes if dtype not in cls.unsupported_dtypes]
+                if len(xla_dtypes) != 0:
+                    test.dtypes[cls.device_type] = xla_dtypes
+                    super().instantiate_test(name, test)
+
+    @classmethod
+    def get_primary_device(cls):
+        return cls.primary_device
+
+    @classmethod
+    def setUpClass(cls):
+        # Sets the primary test device to the xla_device (CPU or TPU)
+        cls.primary_device = str(xm.xla_device())
+
+
 # Adds available device-type-specific test base classes
 device_type_test_bases.append(CPUTestBase)
 if torch.cuda.is_available():
     device_type_test_bases.append(CUDATestBase)
+device_type_test_bases.append(XLATestBase)
 
 
 # Adds 'instantiated' device-specific test cases to the given scope.
