{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_TPU_XRT_1_13 JIT MNIST",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fdBz0cmnDkLJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2019 Google LLC.\n",
        "SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "metadata": {
        "id": "IQG3y7IGvc7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install \\\n",
        "  http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch-1.0.0a0+1d94a2b-cp36-cp36m-linux_x86_64.whl  \\\n",
        "  http://storage.googleapis.com/pytorch-tpu-releases/tf-1.13/torch_xla-0.1+5622d42-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brEkCkFI-Hmy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_xla\n",
        "\n",
        "class XlaMulAdd(nn.Module):\n",
        "  def forward(self, x, y):\n",
        "    return x * y + y\n",
        "\n",
        "# Inputs and output to/from XLA models are always in replicated mode. The shapes\n",
        "# are [NUM_REPLICAS][NUM_VALUES]. A non replicated, single core, execution will\n",
        "# has NUM_REPLICAS == 1, but retain the same shape rank.\n",
        "x = torch.rand(3, 5)\n",
        "y = torch.rand(3, 5)\n",
        "model = XlaMulAdd()\n",
        "traced_model = torch.jit.trace(model, (x, y))\n",
        "xla_model = torch_xla._XLAC.XlaModule(traced_model)\n",
        "output_xla = xla_model((torch_xla._XLAC.XLATensor(x), torch_xla._XLAC.XLATensor(y)))\n",
        "expected = model(x, y)\n",
        "print(output_xla[0][0].to_tensor().data)\n",
        "print(expected.data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PM8Iljy-OXhx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch_xla\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "datadir = '/tmp/mnist-data'\n",
        "num_workers = 4\n",
        "\n",
        "class MNIST(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MNIST, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.bn1 = nn.BatchNorm2d(10)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.bn2 = nn.BatchNorm2d(20)\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "    x = self.bn2(x)\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train_mnist():\n",
        "  torch.manual_seed(1)\n",
        "  num_cores = 8\n",
        "  # Training settings\n",
        "  lr = 0.01\n",
        "  momentum = 0.5\n",
        "  log_interval = 5\n",
        "  batch_size = 256\n",
        "  num_epochs = 10\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST(\n",
        "          datadir,\n",
        "          train=True,\n",
        "          download=True,\n",
        "          transform=transforms.Compose([\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize((0.1307,), (0.3081,))\n",
        "          ])),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST(\n",
        "          datadir,\n",
        "          train=False,\n",
        "          transform=transforms.Compose([\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize((0.1307,), (0.3081,))\n",
        "          ])),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers)\n",
        "\n",
        "  model = MNIST()\n",
        "\n",
        "  # Trace the model.\n",
        "  devices = [':{}'.format(n) for n in range(0, num_cores)]\n",
        "  inputs = torch.zeros(batch_size, 1, 28, 28)\n",
        "  target = torch.zeros(batch_size, dtype=torch.int64)\n",
        "  xla_model = xm.XlaModel(\n",
        "      model, [inputs],\n",
        "      loss_fn=F.nll_loss,\n",
        "      target=target,\n",
        "      num_cores=num_cores,\n",
        "      devices=devices)\n",
        "  optimizer = optim.SGD(xla_model.parameters_list(), lr=lr, momentum=momentum)\n",
        "\n",
        "  log_fn = xm.get_log_fn()\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    xla_model.train(\n",
        "        train_loader,\n",
        "        optimizer,\n",
        "        batch_size,\n",
        "        log_interval=log_interval,\n",
        "        metrics_debug=False,\n",
        "        log_fn=log_fn)\n",
        "    accuracy = xla_model.test(\n",
        "        test_loader,\n",
        "        xm.category_eval_fn(F.nll_loss),\n",
        "        batch_size,\n",
        "        log_fn=log_fn)\n",
        "\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "train_mnist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}