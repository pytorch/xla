- name: Create /dist directory for exported wheels
  ansible.builtin.file:
    path: /dist
    state: directory
    mode: '0755'

- name: Build PyTorch/XLA CUDA Plugin
  ansible.builtin.command:
    cmd: pip wheel plugins/cuda -v
    chdir: "{{ (src_root, 'pytorch/xla') | path_join }}"
  environment: "{{ env_vars }}"
  when: accelerator == "cuda"

- name: Find the built CUDA plugin wheel
  ansible.builtin.find:
    paths: "{{ (src_root, 'pytorch/xla') | path_join }}" # Look in the dir where pip saved the wheel
    patterns: "torch_xla_cuda_plugin-*.whl"
    recurse: no
  when: accelerator == "cuda"
  register: built_plugin_wheel_info

- name: Copy the CUDA plugin wheel to /dist
  ansible.builtin.copy:
    src: "{{ item.path }}"
    dest: "/dist/{{ item.path | basename }}" # Ensure only the filename is used for dest
  loop: "{{ built_plugin_wheel_info.files }}"
  when: accelerator == "cuda" and built_plugin_wheel_info.files | length > 0

- name: Find CUDA plugin wheel in /dist
  ansible.builtin.find:
    path: "/dist"
    pattern: "torch_xla_cuda_plugin*.whl"
  when: accelerator == "cuda"
  register: plugin_wheels

- name: Install CUDA plugin wheels
  ansible.builtin.pip:
    name: "{{ plugin_wheels.files | map(attribute='path') }}"
    state: "forcereinstall"
  when: accelerator == "cuda"

# TODO: Pass libtpu to next release stage somehow. This only runs during build
- name: Install libtpu
  ansible.builtin.pip:
    name: torch_xla[tpu]
    extra_args: -f https://storage.googleapis.com/libtpu-releases/index.html -f https://storage.googleapis.com/libtpu-wheels/index.html
  when: accelerator == "tpuvm"
