name: build-cuda-plugin
on:
  workflow_call:
    inputs:
      dev-image:
        required: true
        type: string
        description: Base image for builds
      runner:
        required: false
        type: string
        description: Runner type for the test
        default: linux.12xlarge

    secrets:
      gcloud-service-key:
        required: true
        description: Secret to access Bazel build cache
jobs:
  build:
    runs-on: ${{ inputs.runner }}
    container:
      image: ${{ inputs.dev-image }}
    env:
      GCLOUD_SERVICE_KEY: ${{ secrets.gcloud-service-key }}
      BAZEL_JOBS: 16
      # TODO: Enable remote cache once https://github.com/pytorch/xla/issues/8839 is fixed.
      # BAZEL_REMOTE_CACHE: ${{ github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository }}
      BAZEL_REMOTE_CACHE: "0"
    steps:
      - name: Checkout actions
        uses: actions/checkout@v4
        with:
          sparse-checkout: |
            .github/workflows/setup
          path: .actions
      - name: Setup
        uses: ./.actions/.github/workflows/setup
        with:
          torch-commit: ${{ inputs.torch-commit }}
          cuda: true
      - name: Build
        shell: bash
        run: |
          cd pytorch/xla/infra/ansible
          ansible-playbook playbook.yaml -vvv -e "stage=build_plugin arch=amd64 accelerator=cuda cuda_compute_capabilities=5.2,7.5,8.6 src_root=${GITHUB_WORKSPACE} cache_suffix=-ci" --skip-tags=fetch_srcs,install_deps
      - name: Upload wheel
        uses: actions/upload-artifact@v4
        with:
          name: cuda-plugin
          path: /dist/*.whl
