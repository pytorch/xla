[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  __init__ (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py:533)
  _wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/wrap.py:147)
  recursive_wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/wrap.py:213)
  recursive_wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/wrap.py:196)
  _auto_wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py:1635)
  __init__ (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py:372)
  <lambda> (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:235)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:247)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (968f7a417173a2e1b368916bd85f25f6, 1e6a3d7aaed8febde2623b6b17ed73dd, 5b77dca71236b3517801d9746015b455)

## BEGIN_GRAPH
HloModule IrToHlo.9, entry_computation_layout={(s8[80,50]{0,1})->(bf16[1]{0}, s8[80,50]{0,1}, s8[1]{0})}

ENTRY %IrToHlo.9 (p0.4: s8[80,50]) -> (bf16[1], s8[80,50], s8[1]) {
  %constant.1 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %reshape.2 = bf16[1]{0} reshape(bf16[] %constant.1), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %broadcast.3 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %p0.4 = s8[80,50]{0,1} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.5 = s8[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.6 = s8[1]{0} reshape(s8[] %constant.5), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.7 = s8[1]{0} broadcast(s8[1]{0} %reshape.6), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  ROOT %tuple.8 = (bf16[1]{0}, s8[80,50]{0,1}, s8[1]{0}) tuple(bf16[1]{0} %broadcast.3, s8[80,50]{0,1} %p0.4, s8[1]{0} %broadcast.7)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  __init__ (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py:533)
  _wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/wrap.py:147)
  recursive_wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/wrap.py:213)
  recursive_wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/wrap.py:196)
  _auto_wrap (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py:1635)
  __init__ (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py:372)
  <lambda> (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:235)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:247)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (968f7a417173a2e1b368916bd85f25f6, 992c6a38301a67886f771e59af2546d2, 5b77dca71236b3517801d9746015b455)

## BEGIN_GRAPH
HloModule IrToHlo.9, entry_computation_layout={(s8[13,10]{0,1})->(bf16[1]{0}, s8[13,10]{0,1}, s8[1]{0})}

ENTRY %IrToHlo.9 (p0.4: s8[13,10]) -> (bf16[1], s8[13,10], s8[1]) {
  %constant.1 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %reshape.2 = bf16[1]{0} reshape(bf16[] %constant.1), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %broadcast.3 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %p0.4 = s8[13,10]{0,1} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.5 = s8[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.6 = s8[1]{0} reshape(s8[] %constant.5), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.7 = s8[1]{0} broadcast(s8[1]{0} %reshape.6), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  ROOT %tuple.8 = (bf16[1]{0}, s8[13,10]{0,1}, s8[1]{0}) tuple(bf16[1]{0} %broadcast.3, s8[13,10]{0,1} %p0.4, s8[1]{0} %broadcast.7)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  __init__ (/workspaces/work/pytorch/xla/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py:533)
  <lambda> (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:235)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:247)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (968f7a417173a2e1b368916bd85f25f6, dc225278bdcd07ff78e6dbc512e1882f, 968f7a417173a2e1b368916bd85f25f6, fa1dbc4df7b527815cd75d199f4e6b33, 968f7a417173a2e1b368916bd85f25f6, fa1dbc4df7b527815cd75d199f4e6b33, 968f7a417173a2e1b368916bd85f25f6, fa1dbc4df7b527815cd75d199f4e6b33, 968f7a417173a2e1b368916bd85f25f6, e7a9b81c682cb1be25eea014981e9d78, 968f7a417173a2e1b368916bd85f25f6, 364c1607fa7a0b6e13de590292a6f9a3, 968f7a417173a2e1b368916bd85f25f6, 364c1607fa7a0b6e13de590292a6f9a3, 968f7a417173a2e1b368916bd85f25f6, 364c1607fa7a0b6e13de590292a6f9a3, 968f7a417173a2e1b368916bd85f25f6, abfeb1fd0d3ffcc80670084f69703128, abfeb1fd0d3ffcc80670084f69703128, eb03aa3a8858b23facf7cc6922ab39b6, ce75e646308080112098812aa3c9dcde, ce75e646308080112098812aa3c9dcde, eb03aa3a8858b23facf7cc6922ab39b6)

## BEGIN_GRAPH
HloModule IrToHlo.43, entry_computation_layout={(bf16[3,1,5,5]{3,2,0,1},bf16[3]{0},bf16[3]{0},bf16[3]{0},bf16[5,10,5,5]{1,3,2,0},bf16[5]{0},bf16[5]{0},bf16[5]{0},bf16[10]{0},bf16[10]{0},bf16[20]{0},bf16[20]{0})->(bf16[1]{0}, bf16[3,1,5,5]{3,2,0,1}, bf16[1]{0}, bf16[3]{0}, bf16[1]{0}, /*index=5*/bf16[3]{0}, bf16[1]{0}, bf16[3]{0}, bf16[1]{0}, bf16[5,10,5,5]{1,3,2,0}, /*index=10*/bf16[1]{0}, bf16[5]{0}, bf16[1]{0}, bf16[5]{0}, bf16[1]{0}, /*index=15*/bf16[5]{0}, bf16[1]{0}, bf16[10]{0}, bf16[10]{0}, s64[], /*index=20*/bf16[20]{0}, bf16[20]{0}, s64[])}

ENTRY %IrToHlo.43 (p0.4: bf16[3,1,5,5], p1.8: bf16[3], p2.12: bf16[3], p3.16: bf16[3], p4.20: bf16[5,10,5,5], p5.24: bf16[5], p6.28: bf16[5], p7.32: bf16[5], p8.36: bf16[10], p9.37: bf16[10], p10.39: bf16[20], p11.40: bf16[20]) -> (bf16[1], bf16[3,1,5,5], bf16[1], bf16[3], bf16[1], /*index=5*/bf16[3], bf16[1], bf16[3], bf16[1], bf16[5,10,5,5], /*index=10*/bf16[1], bf16[5], bf16[1], bf16[5], bf16[1], /*index=15*/bf16[5], bf16[1], bf16[10], bf16[10], s64[], /*index=20*/bf16[20], bf16[20], s64[]) {
  %constant.1 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %reshape.2 = bf16[1]{0} reshape(bf16[] %constant.1), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %broadcast.3 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=659}
  %p0.4 = bf16[3,1,5,5]{3,2,0,1} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.5 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.6 = bf16[1]{0} reshape(bf16[] %constant.5), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.7 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.6), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p1.8 = bf16[3]{0} parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.9 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.10 = bf16[1]{0} reshape(bf16[] %constant.9), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.11 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.10), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p2.12 = bf16[3]{0} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.13 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.14 = bf16[1]{0} reshape(bf16[] %constant.13), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.15 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.14), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p3.16 = bf16[3]{0} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.17 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.18 = bf16[1]{0} reshape(bf16[] %constant.17), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.19 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.18), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p4.20 = bf16[5,10,5,5]{1,3,2,0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.21 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.22 = bf16[1]{0} reshape(bf16[] %constant.21), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.23 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.22), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p5.24 = bf16[5]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.25 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.26 = bf16[1]{0} reshape(bf16[] %constant.25), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.27 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.26), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p6.28 = bf16[5]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.29 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.30 = bf16[1]{0} reshape(bf16[] %constant.29), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.31 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.30), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p7.32 = bf16[5]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=699}
  %constant.33 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %reshape.34 = bf16[1]{0} reshape(bf16[] %constant.33), metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.34), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="_shard_parameters_@xla_fully_sharded_data_parallel.py" source_line=718}
  %p8.36 = bf16[10]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_cast_buffers@xla_fully_sharded_data_parallel.py" source_line=780}
  %p9.37 = bf16[10]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_cast_buffers@xla_fully_sharded_data_parallel.py" source_line=780}
  %constant.38 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_cast_buffers@xla_fully_sharded_data_parallel.py" source_line=780}
  %p10.39 = bf16[20]{0} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_cast_buffers@xla_fully_sharded_data_parallel.py" source_line=780}
  %p11.40 = bf16[20]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_cast_buffers@xla_fully_sharded_data_parallel.py" source_line=780}
  %constant.41 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="_cast_buffers@xla_fully_sharded_data_parallel.py" source_line=780}
  ROOT %tuple.42 = (bf16[1]{0}, bf16[3,1,5,5]{3,2,0,1}, bf16[1]{0}, bf16[3]{0}, bf16[1]{0}, /*index=5*/bf16[3]{0}, bf16[1]{0}, bf16[3]{0}, bf16[1]{0}, bf16[5,10,5,5]{1,3,2,0}, /*index=10*/bf16[1]{0}, bf16[5]{0}, bf16[1]{0}, bf16[5]{0}, bf16[1]{0}, /*index=15*/bf16[5]{0}, bf16[1]{0}, bf16[10]{0}, bf16[10]{0}, s64[], /*index=20*/bf16[20]{0}, bf16[20]{0}, s64[]) tuple(bf16[1]{0} %broadcast.3, bf16[3,1,5,5]{3,2,0,1} %p0.4, bf16[1]{0} %broadcast.7, bf16[3]{0} %p1.8, bf16[1]{0} %broadcast.11, /*index=5*/bf16[3]{0} %p2.12, bf16[1]{0} %broadcast.15, bf16[3]{0} %p3.16, bf16[1]{0} %broadcast.19, bf16[5,10,5,5]{1,3,2,0} %p4.20, /*index=10*/bf16[1]{0} %broadcast.23, bf16[5]{0} %p5.24, bf16[1]{0} %broadcast.27, bf16[5]{0} %p6.28, bf16[1]{0} %broadcast.31, /*index=15*/bf16[5]{0} %p7.32, bf16[1]{0} %broadcast.35, bf16[10]{0} %p8.36, bf16[10]{0} %p9.37, s64[] %constant.38, /*index=20*/bf16[20]{0} %p10.39, bf16[20]{0} %p11.40, s64[] %constant.41)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (a3cfffa0e2f592d1d8c40672a1f0ddf1, c6ce42013343ea1bf8649be89f0d7bb8, bc7c721ba69dc561850a50a0ce180028, e00de3593c815d38a56aba7fe87d57d1, 75fc66096e7436cfbd93af5ad09aee7c, 6c358e1ac4dd5645c1d14ec880cf2fa1, 5958cd1df2a7d3ad8c4142fb24d928f9, 6ce7121b6a29bd731935f6c0dc63834c, 23780ccad86b801f1d2384083f314237)

## BEGIN_GRAPH
HloModule IrToHlo.295, entry_computation_layout={(f32[],bf16[3,1,5,5]{3,2,0,1},bf16[3]{0},bf16[3]{0},bf16[3]{0},bf16[5,10,5,5]{1,3,2,0},bf16[5]{0},bf16[5]{0},bf16[5]{0},bf16[1]{0},s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[10]{0},bf16[10]{0},f32[128,1,28,28]{0,3,2,1})->(bf16[10,1,5,5]{3,2,1,0}, bf16[10]{0}, bf16[10]{0}, bf16[10]{0}, bf16[20,10,5,5]{3,2,1,0}, /*index=5*/bf16[20]{0}, bf16[20]{0}, bf16[20]{0}, bf16[128,10]{1,0})}

%AddComputation.9 (x.10: bf16[], y.11: bf16[]) -> bf16[] {
  %x.10 = bf16[] parameter(0)
  %y.11 = bf16[] parameter(1)
  ROOT %add.12 = bf16[] add(bf16[] %x.10, bf16[] %y.11)
}

%AddComputation.25 (x.26: bf16[], y.27: bf16[]) -> bf16[] {
  %x.26 = bf16[] parameter(0)
  %y.27 = bf16[] parameter(1)
  ROOT %add.28 = bf16[] add(bf16[] %x.26, bf16[] %y.27)
}

%AddComputation.41 (x.42: bf16[], y.43: bf16[]) -> bf16[] {
  %x.42 = bf16[] parameter(0)
  %y.43 = bf16[] parameter(1)
  ROOT %add.44 = bf16[] add(bf16[] %x.42, bf16[] %y.43)
}

%AddComputation.57 (x.58: bf16[], y.59: bf16[]) -> bf16[] {
  %x.58 = bf16[] parameter(0)
  %y.59 = bf16[] parameter(1)
  ROOT %add.60 = bf16[] add(bf16[] %x.58, bf16[] %y.59)
}

%AddComputation.73 (x.74: bf16[], y.75: bf16[]) -> bf16[] {
  %x.74 = bf16[] parameter(0)
  %y.75 = bf16[] parameter(1)
  ROOT %add.76 = bf16[] add(bf16[] %x.74, bf16[] %y.75)
}

%AddComputation.89 (x.90: bf16[], y.91: bf16[]) -> bf16[] {
  %x.90 = bf16[] parameter(0)
  %y.91 = bf16[] parameter(1)
  ROOT %add.92 = bf16[] add(bf16[] %x.90, bf16[] %y.91)
}

%AddComputation.105 (x.106: bf16[], y.107: bf16[]) -> bf16[] {
  %x.106 = bf16[] parameter(0)
  %y.107 = bf16[] parameter(1)
  ROOT %add.108 = bf16[] add(bf16[] %x.106, bf16[] %y.107)
}

%AddComputation.121 (x.122: bf16[], y.123: bf16[]) -> bf16[] {
  %x.122 = bf16[] parameter(0)
  %y.123 = bf16[] parameter(1)
  ROOT %add.124 = bf16[] add(bf16[] %x.122, bf16[] %y.123)
}

%AddComputation.138 (x.139: s8[], y.140: s8[]) -> s8[] {
  %x.139 = s8[] parameter(0)
  %y.140 = s8[] parameter(1)
  ROOT %add.141 = s8[] add(s8[] %x.139, s8[] %y.140)
}

%AddComputation.153 (x.154: s8[], y.155: s8[]) -> s8[] {
  %x.154 = s8[] parameter(0)
  %y.155 = s8[] parameter(1)
  ROOT %add.156 = s8[] add(s8[] %x.154, s8[] %y.155)
}

%max_BF16.189 (lhs.190: bf16[], rhs.191: bf16[]) -> bf16[] {
  %lhs.190 = bf16[] parameter(0)
  %rhs.191 = bf16[] parameter(1)
  ROOT %maximum.192 = bf16[] maximum(bf16[] %lhs.190, bf16[] %rhs.191)
}

%ge_BF16.195 (lhs.196: bf16[], rhs.197: bf16[]) -> pred[] {
  %lhs.196 = bf16[] parameter(0)
  %rhs.197 = bf16[] parameter(1)
  ROOT %compare.198 = pred[] compare(bf16[] %lhs.196, bf16[] %rhs.197), direction=GE
}

%max_BF16.199 (lhs.200: bf16[], rhs.201: bf16[]) -> bf16[] {
  %lhs.200 = bf16[] parameter(0)
  %rhs.201 = bf16[] parameter(1)
  ROOT %maximum.202 = bf16[] maximum(bf16[] %lhs.200, bf16[] %rhs.201)
}

%min_U32.213 (lhs.214: u32[], rhs.215: u32[]) -> u32[] {
  %lhs.214 = u32[] parameter(0)
  %rhs.215 = u32[] parameter(1)
  ROOT %minimum.216 = u32[] minimum(u32[] %lhs.214, u32[] %rhs.215)
}

%max_BF16.233 (lhs.234: bf16[], rhs.235: bf16[]) -> bf16[] {
  %lhs.234 = bf16[] parameter(0)
  %rhs.235 = bf16[] parameter(1)
  ROOT %maximum.236 = bf16[] maximum(bf16[] %lhs.234, bf16[] %rhs.235)
}

%ge_BF16.239 (lhs.240: bf16[], rhs.241: bf16[]) -> pred[] {
  %lhs.240 = bf16[] parameter(0)
  %rhs.241 = bf16[] parameter(1)
  ROOT %compare.242 = pred[] compare(bf16[] %lhs.240, bf16[] %rhs.241), direction=GE
}

%max_BF16.243 (lhs.244: bf16[], rhs.245: bf16[]) -> bf16[] {
  %lhs.244 = bf16[] parameter(0)
  %rhs.245 = bf16[] parameter(1)
  ROOT %maximum.246 = bf16[] maximum(bf16[] %lhs.244, bf16[] %rhs.245)
}

%min_U32.257 (lhs.258: u32[], rhs.259: u32[]) -> u32[] {
  %lhs.258 = u32[] parameter(0)
  %rhs.259 = u32[] parameter(1)
  ROOT %minimum.260 = u32[] minimum(u32[] %lhs.258, u32[] %rhs.259)
}

%MaxComputation.277 (x.278: bf16[], y.279: bf16[]) -> bf16[] {
  %x.278 = bf16[] parameter(0)
  %y.279 = bf16[] parameter(1)
  ROOT %maximum.280 = bf16[] maximum(bf16[] %x.278, bf16[] %y.279)
}

%AddComputation.286 (x.287: bf16[], y.288: bf16[]) -> bf16[] {
  %x.287 = bf16[] parameter(0)
  %y.288 = bf16[] parameter(1)
  ROOT %add.289 = bf16[] add(bf16[] %x.287, bf16[] %y.288)
}

ENTRY %IrToHlo.295 (p0.1: f32[], p1.2: bf16[3,1,5,5], p2.18: bf16[3], p3.34: bf16[3], p4.50: bf16[3], p5.66: bf16[5,10,5,5], p6.82: bf16[5], p7.98: bf16[5], p8.114: bf16[5], p9.130: bf16[1], p10.131: s8[80,50], p11.146: s8[13,10], p12.168: bf16[1], p13.176: bf16[20], p14.177: bf16[20], p15.178: bf16[10], p16.179: bf16[10], p17.180: f32[128,1,28,28]) -> (bf16[10,1,5,5], bf16[10], bf16[10], bf16[10], bf16[20,10,5,5], /*index=5*/bf16[20], bf16[20], bf16[20], bf16[128,10]) {
  %p11.146 = s8[13,10]{0,1} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.147 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.148 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p11.146, s8[] %constant.147), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p10.131 = s8[80,50]{0,1} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.132 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.133 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p10.131, s8[] %constant.132), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p8.114 = bf16[5]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.115 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.116 = bf16[20]{0} pad(bf16[5]{0} %p8.114, bf16[] %constant.115), padding=0_15, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p7.98 = bf16[5]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.99 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.100 = bf16[20]{0} pad(bf16[5]{0} %p7.98, bf16[] %constant.99), padding=0_15, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p6.82 = bf16[5]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.83 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.84 = bf16[20]{0} pad(bf16[5]{0} %p6.82, bf16[] %constant.83), padding=0_15, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p5.66 = bf16[5,10,5,5]{1,3,2,0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.67 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.68 = bf16[20,10,5,5]{3,2,1,0} pad(bf16[5,10,5,5]{1,3,2,0} %p5.66, bf16[] %constant.67), padding=0_15x0_0x0_0x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p4.50 = bf16[3]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.51 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.52 = bf16[12]{0} pad(bf16[3]{0} %p4.50, bf16[] %constant.51), padding=0_9, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p3.34 = bf16[3]{0} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.35 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.36 = bf16[12]{0} pad(bf16[3]{0} %p3.34, bf16[] %constant.35), padding=0_9, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.18 = bf16[3]{0} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = bf16[12]{0} pad(bf16[3]{0} %p2.18, bf16[] %constant.19), padding=0_9, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = bf16[3,1,5,5]{3,2,0,1} parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.3 = bf16[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.4 = bf16[12,1,5,5]{3,2,1,0} pad(bf16[3,1,5,5]{3,2,0,1} %p1.2, bf16[] %constant.3), padding=0_9x0_0x0_0x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p0.1 = f32[] parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.5 = bf16[] convert(f32[] %p0.1), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.6 = (bf16[12,1,5,5]{3,2,1,0}, bf16[]) tuple(bf16[12,1,5,5]{3,2,1,0} %pad.4, bf16[] %convert.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.7 = bf16[12,1,5,5]{3,2,1,0} get-tuple-element((bf16[12,1,5,5]{3,2,1,0}, bf16[]) %tuple.6), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = bf16[] get-tuple-element((bf16[12,1,5,5]{3,2,1,0}, bf16[]) %tuple.6), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.13 = (bf16[12,1,5,5]{0,3,2,1}, bf16[]) all-reduce(bf16[12,1,5,5]{3,2,1,0} %get-tuple-element.7, bf16[] %get-tuple-element.8), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.9, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.15 = bf16[] get-tuple-element((bf16[12,1,5,5]{0,3,2,1}, bf16[]) %all-reduce.13), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.16 = f32[] convert(bf16[] %get-tuple-element.15), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = bf16[] convert(f32[] %convert.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (bf16[12]{0}, bf16[]) tuple(bf16[12]{0} %pad.20, bf16[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = bf16[12]{0} get-tuple-element((bf16[12]{0}, bf16[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = bf16[] get-tuple-element((bf16[12]{0}, bf16[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (bf16[12]{0}, bf16[]) all-reduce(bf16[12]{0} %get-tuple-element.23, bf16[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = bf16[] get-tuple-element((bf16[12]{0}, bf16[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(bf16[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.37 = bf16[] convert(f32[] %convert.32), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.38 = (bf16[12]{0}, bf16[]) tuple(bf16[12]{0} %pad.36, bf16[] %convert.37), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.39 = bf16[12]{0} get-tuple-element((bf16[12]{0}, bf16[]) %tuple.38), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.40 = bf16[] get-tuple-element((bf16[12]{0}, bf16[]) %tuple.38), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.45 = (bf16[12]{0}, bf16[]) all-reduce(bf16[12]{0} %get-tuple-element.39, bf16[] %get-tuple-element.40), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.41, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.47 = bf16[] get-tuple-element((bf16[12]{0}, bf16[]) %all-reduce.45), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.48 = f32[] convert(bf16[] %get-tuple-element.47), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.53 = bf16[] convert(f32[] %convert.48), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.54 = (bf16[12]{0}, bf16[]) tuple(bf16[12]{0} %pad.52, bf16[] %convert.53), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.55 = bf16[12]{0} get-tuple-element((bf16[12]{0}, bf16[]) %tuple.54), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.56 = bf16[] get-tuple-element((bf16[12]{0}, bf16[]) %tuple.54), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.61 = (bf16[12]{0}, bf16[]) all-reduce(bf16[12]{0} %get-tuple-element.55, bf16[] %get-tuple-element.56), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.57, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.63 = bf16[] get-tuple-element((bf16[12]{0}, bf16[]) %all-reduce.61), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.64 = f32[] convert(bf16[] %get-tuple-element.63), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.69 = bf16[] convert(f32[] %convert.64), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.70 = (bf16[20,10,5,5]{3,2,1,0}, bf16[]) tuple(bf16[20,10,5,5]{3,2,1,0} %pad.68, bf16[] %convert.69), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.71 = bf16[20,10,5,5]{3,2,1,0} get-tuple-element((bf16[20,10,5,5]{3,2,1,0}, bf16[]) %tuple.70), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.72 = bf16[] get-tuple-element((bf16[20,10,5,5]{3,2,1,0}, bf16[]) %tuple.70), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.77 = (bf16[20,10,5,5]{0,1,3,2}, bf16[]) all-reduce(bf16[20,10,5,5]{3,2,1,0} %get-tuple-element.71, bf16[] %get-tuple-element.72), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.73, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.79 = bf16[] get-tuple-element((bf16[20,10,5,5]{0,1,3,2}, bf16[]) %all-reduce.77), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.80 = f32[] convert(bf16[] %get-tuple-element.79), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.85 = bf16[] convert(f32[] %convert.80), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.86 = (bf16[20]{0}, bf16[]) tuple(bf16[20]{0} %pad.84, bf16[] %convert.85), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.87 = bf16[20]{0} get-tuple-element((bf16[20]{0}, bf16[]) %tuple.86), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.88 = bf16[] get-tuple-element((bf16[20]{0}, bf16[]) %tuple.86), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.93 = (bf16[20]{0}, bf16[]) all-reduce(bf16[20]{0} %get-tuple-element.87, bf16[] %get-tuple-element.88), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.89, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.95 = bf16[] get-tuple-element((bf16[20]{0}, bf16[]) %all-reduce.93), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.96 = f32[] convert(bf16[] %get-tuple-element.95), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.101 = bf16[] convert(f32[] %convert.96), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.102 = (bf16[20]{0}, bf16[]) tuple(bf16[20]{0} %pad.100, bf16[] %convert.101), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.103 = bf16[20]{0} get-tuple-element((bf16[20]{0}, bf16[]) %tuple.102), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.104 = bf16[] get-tuple-element((bf16[20]{0}, bf16[]) %tuple.102), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.109 = (bf16[20]{0}, bf16[]) all-reduce(bf16[20]{0} %get-tuple-element.103, bf16[] %get-tuple-element.104), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.105, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.111 = bf16[] get-tuple-element((bf16[20]{0}, bf16[]) %all-reduce.109), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.112 = f32[] convert(bf16[] %get-tuple-element.111), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.117 = bf16[] convert(f32[] %convert.112), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.118 = (bf16[20]{0}, bf16[]) tuple(bf16[20]{0} %pad.116, bf16[] %convert.117), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.119 = bf16[20]{0} get-tuple-element((bf16[20]{0}, bf16[]) %tuple.118), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.120 = bf16[] get-tuple-element((bf16[20]{0}, bf16[]) %tuple.118), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.125 = (bf16[20]{0}, bf16[]) all-reduce(bf16[20]{0} %get-tuple-element.119, bf16[] %get-tuple-element.120), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.121, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.127 = bf16[] get-tuple-element((bf16[20]{0}, bf16[]) %all-reduce.125), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.128 = f32[] convert(bf16[] %get-tuple-element.127), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.134 = s8[] convert(f32[] %convert.128), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.135 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.133, s8[] %convert.134), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.136 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.135), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.137 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.135), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.142 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.136, s8[] %get-tuple-element.137), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.138, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.144 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.142), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.145 = f32[] convert(s8[] %get-tuple-element.144), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.149 = s8[] convert(f32[] %convert.145), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.150 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.148, s8[] %convert.149), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.151 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.150), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.152 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.150), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.157 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.151, s8[] %get-tuple-element.152), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.153, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.159 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.157), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.160 = f32[] convert(s8[] %get-tuple-element.159), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.180 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.181 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.180), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %get-tuple-element.14 = bf16[12,1,5,5]{0,3,2,1} get-tuple-element((bf16[12,1,5,5]{0,3,2,1}, bf16[]) %all-reduce.13), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.17 = bf16[10,1,5,5]{3,2,1,0} slice(bf16[12,1,5,5]{0,3,2,1} %get-tuple-element.14), slice={[0:10], [0:1], [0:5], [0:5]}, metadata={op_type="xla__select" op_name="xla__select" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.182 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.181, bf16[10,1,5,5]{3,2,1,0} %slice.17), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %get-tuple-element.30 = bf16[12]{0} get-tuple-element((bf16[12]{0}, bf16[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = bf16[10]{0} slice(bf16[12]{0} %get-tuple-element.30), slice={[0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.183 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %slice.33), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.184 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.183), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.185 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.182, bf16[128,10,24,24]{1,3,2,0} %transpose.184), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.186 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.187 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.185, bf16[] %constant.186), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.188 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.193 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.187, bf16[] %constant.188), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.189, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.194 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.203 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.187, bf16[128,10,12,12]{3,2,1,0} %reduce-window.193, bf16[] %constant.194), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.195, scatter=%max_BF16.199, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.210 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.194), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.211 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.203, bf16[128,10,24,24]{3,2,1,0} %broadcast.210), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.204 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.205 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.204), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.206 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.205), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.207 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.208 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.206, u32[] %constant.207), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.209 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.207), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.212 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.211, u32[128,10,24,24]{3,2,1,0} %pad.208, u32[128,10,24,24]{3,2,1,0} %broadcast.209), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.217 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.212, u32[] %constant.207), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.213, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p15.178 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.222 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.223 = bf16[10]{0} broadcast(bf16[] %constant.222), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.224 = bf16[10]{0} add(bf16[10]{0} %p15.178, bf16[10]{0} %broadcast.223), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.225 = bf16[10]{0} rsqrt(bf16[10]{0} %add.224), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.218 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.219 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.218), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.220 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.193, bf16[128,10,12,12]{3,2,1,0} %broadcast.219), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.46 = bf16[12]{0} get-tuple-element((bf16[12]{0}, bf16[]) %all-reduce.45), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.49 = bf16[10]{0} slice(bf16[12]{0} %get-tuple-element.46), slice={[0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="batch_norm@functional.py" source_line=2455}
  %get-tuple-element.62 = bf16[12]{0} get-tuple-element((bf16[12]{0}, bf16[]) %all-reduce.61), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.65 = bf16[10]{0} slice(bf16[12]{0} %get-tuple-element.62), slice={[0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="batch_norm@functional.py" source_line=2455}
  %p16.179 = bf16[10]{0} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.221 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.220, bf16[10]{0} %slice.49, bf16[10]{0} %slice.65, bf16[10]{0} %p16.179, bf16[10]{0} %p15.178), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %get-tuple-element.78 = bf16[20,10,5,5]{0,1,3,2} get-tuple-element((bf16[20,10,5,5]{0,1,3,2}, bf16[]) %all-reduce.77), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.81 = bf16[20,10,5,5]{3,2,1,0} slice(bf16[20,10,5,5]{0,1,3,2} %get-tuple-element.78), slice={[0:20], [0:10], [0:5], [0:5]}, metadata={op_type="xla__select" op_name="xla__select" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.226 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.221, bf16[20,10,5,5]{3,2,1,0} %slice.81), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %get-tuple-element.94 = bf16[20]{0} get-tuple-element((bf16[20]{0}, bf16[]) %all-reduce.93), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.97 = bf16[20]{0} slice(bf16[20]{0} %get-tuple-element.94), slice={[0:20]}, metadata={op_type="xla__select" op_name="xla__select" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.227 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %slice.97), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.228 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.227), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.229 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.226, bf16[128,20,8,8]{1,3,2,0} %transpose.228), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.230 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.231 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.229, bf16[] %constant.230), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.232 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.237 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.231, bf16[] %constant.232), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.233, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.238 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.247 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.231, bf16[128,20,4,4]{3,2,1,0} %reduce-window.237, bf16[] %constant.238), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.239, scatter=%max_BF16.243, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.254 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.238), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.255 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.247, bf16[128,20,8,8]{3,2,1,0} %broadcast.254), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.248 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.249 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.248), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.250 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.249), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.251 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.252 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.250, u32[] %constant.251), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.253 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.251), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.256 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.255, u32[128,20,8,8]{3,2,1,0} %pad.252, u32[128,20,8,8]{3,2,1,0} %broadcast.253), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.261 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.256, u32[] %constant.251), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.257, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p13.176 = bf16[20]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.266 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.267 = bf16[20]{0} broadcast(bf16[] %constant.266), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.268 = bf16[20]{0} add(bf16[20]{0} %p13.176, bf16[20]{0} %broadcast.267), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.269 = bf16[20]{0} rsqrt(bf16[20]{0} %add.268), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %get-tuple-element.110 = bf16[20]{0} get-tuple-element((bf16[20]{0}, bf16[]) %all-reduce.109), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.113 = bf16[20]{0} slice(bf16[20]{0} %get-tuple-element.110), slice={[0:20]}, metadata={op_type="xla__select" op_name="xla__select" source_file="batch_norm@functional.py" source_line=2455}
  %get-tuple-element.126 = bf16[20]{0} get-tuple-element((bf16[20]{0}, bf16[]) %all-reduce.125), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.129 = bf16[20]{0} slice(bf16[20]{0} %get-tuple-element.126), slice={[0:20]}, metadata={op_type="xla__select" op_name="xla__select" source_file="batch_norm@functional.py" source_line=2455}
  %constant.262 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.263 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.262), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.264 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.237, bf16[128,20,4,4]{3,2,1,0} %broadcast.263), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.177 = bf16[20]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.265 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.264, bf16[20]{0} %slice.113, bf16[20]{0} %slice.129, bf16[20]{0} %p14.177, bf16[20]{0} %p13.176), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.270 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.265), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.143 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.142), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.169 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.143), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.170 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.169), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p12.168 = bf16[1]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.171 = bf16[1]{0} broadcast(bf16[1]{0} %p12.168), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.172 = bf16[] reshape(bf16[1]{0} %broadcast.171), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.173 = bf16[50]{0} broadcast(bf16[] %reshape.172), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.174 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.173), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.175 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.170, bf16[320,50]{1,0} %broadcast.174), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.271 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.270, bf16[320,50]{1,0} %multiply.175), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.272 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.273 = bf16[128,50]{1,0} broadcast(bf16[] %constant.272), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.274 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.271, bf16[128,50]{1,0} %broadcast.273), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.158 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.157), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.161 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.158), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.162 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.161), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p9.130 = bf16[1]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.163 = bf16[1]{0} broadcast(bf16[1]{0} %p9.130), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.164 = bf16[] reshape(bf16[1]{0} %broadcast.163), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.165 = bf16[10]{0} broadcast(bf16[] %reshape.164), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.166 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.165), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.167 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.162, bf16[50,10]{1,0} %broadcast.166), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.275 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.274, bf16[50,10]{1,0} %multiply.167), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.276 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.281 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.275, bf16[] %constant.276), dimensions={1}, to_apply=%MaxComputation.277, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.282 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.281), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.283 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.275, bf16[128,10]{1,0} %broadcast.282), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.284 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.283), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.285 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.290 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.284, bf16[] %constant.285), dimensions={1}, to_apply=%AddComputation.286, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.291 = bf16[128]{0} log(bf16[128]{0} %reduce.290), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.292 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.291), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.293 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.283, bf16[128,10]{1,0} %broadcast.292), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.294 = (bf16[10,1,5,5]{3,2,1,0}, bf16[10]{0}, bf16[10]{0}, bf16[10]{0}, bf16[20,10,5,5]{3,2,1,0}, /*index=5*/bf16[20]{0}, bf16[20]{0}, bf16[20]{0}, bf16[128,10]{1,0}) tuple(bf16[10,1,5,5]{3,2,1,0} %slice.17, bf16[10]{0} %slice.33, bf16[10]{0} %slice.49, bf16[10]{0} %slice.65, bf16[20,10,5,5]{3,2,1,0} %slice.81, /*index=5*/bf16[20]{0} %slice.97, bf16[20]{0} %slice.113, bf16[20]{0} %slice.129, bf16[128,10]{1,0} %subtract.293)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (f3f1effa368c2cd86e2204978eee64ac)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[128,1,28,28]{0,3,2,1})->(bf16[128,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[128,1,28,28]) -> (bf16[128,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[128,1,28,28]{0,3,2,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[128,1,28,28]{0,3,2,1} convert(f32[128,1,28,28]{0,3,2,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[128,10,24,24]{3,2,1,0} convolution(bf16[128,1,28,28]{0,3,2,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[128,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[128,10,24,24]{1,3,2,0} transpose(bf16[128,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[128,10,24,24]{3,2,1,0} add(bf16[128,10,24,24]{3,2,1,0} %convolution.62, bf16[128,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[128,10,24,24]{3,2,1,0} pad(bf16[128,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[128,10,12,12]{3,2,1,0} reduce-window(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[128,10,24,24]{3,2,1,0} select-and-scatter(bf16[128,10,24,24]{3,2,1,0} %pad.67, bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[128,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[128,10,24,24]{3,2,1,0} compare(bf16[128,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[128,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[128,10,24,24]{3,2,1,0} pad(u32[128,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[128,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[128,10,24,24]{3,2,1,0} select(pred[128,10,24,24]{3,2,1,0} %compare.91, u32[128,10,24,24]{3,2,1,0} %pad.88, u32[128,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[128,10,12,12]{3,2,1,0} reduce-window(u32[128,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[128,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[128,10,12,12]{3,2,1,0} maximum(bf16[128,10,12,12]{3,2,1,0} %reduce-window.73, bf16[128,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[128,10,12,12]{3,2,1,0} batch-norm-inference(bf16[128,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[128,20,8,8]{3,2,1,0} convolution(bf16[128,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[128,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[128,20,8,8]{1,3,2,0} transpose(bf16[128,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[128,20,8,8]{3,2,1,0} add(bf16[128,20,8,8]{3,2,1,0} %convolution.106, bf16[128,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[128,20,8,8]{3,2,1,0} pad(bf16[128,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[128,20,4,4]{3,2,1,0} reduce-window(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[128,20,8,8]{3,2,1,0} select-and-scatter(bf16[128,20,8,8]{3,2,1,0} %pad.111, bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[128,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[128,20,8,8]{3,2,1,0} compare(bf16[128,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[128,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[128,20,8,8]{3,2,1,0} pad(u32[128,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[128,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[128,20,8,8]{3,2,1,0} select(pred[128,20,8,8]{3,2,1,0} %compare.135, u32[128,20,8,8]{3,2,1,0} %pad.132, u32[128,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[128,20,4,4]{3,2,1,0} reduce-window(u32[128,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[128,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[128,20,4,4]{3,2,1,0} maximum(bf16[128,20,4,4]{3,2,1,0} %reduce-window.117, bf16[128,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[128,20,4,4]{3,2,1,0} batch-norm-inference(bf16[128,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[128,320]{1,0} reshape(bf16[128,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[128,50]{1,0} dot(bf16[128,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[128,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[128,50]{1,0} maximum(bf16[128,50]{1,0} %dot.151, bf16[128,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[128,10]{1,0} dot(bf16[128,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[128]{0} reduce(bf16[128,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %dot.155, bf16[128,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[128,10]{1,0} exponential(bf16[128,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[128]{0} reduce(bf16[128,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[128]{0} log(bf16[128]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[128,10]{1,0} broadcast(bf16[128]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[128,10]{1,0} subtract(bf16[128,10]{1,0} %subtract.163, bf16[128,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[128,10]{1,0}) tuple(bf16[128,10]{1,0} %subtract.173)
}


## END_GRAPH


[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  mark_step (/workspaces/work/pytorch/xla/torch_xla/core/xla_model.py:949)
  next (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:42)
  __next__ (/workspaces/work/pytorch/xla/torch_xla/distributed/parallel_loader.py:30)
  inference_loop_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:260)
  inference_mnist (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:291)
  _mp_fn (/workspaces/work/pytorch/xla/test/fsdp_mnist_quant_test.py:302)
  __call__ (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:341)
  _thread_fn (/workspaces/work/pytorch/xla/torch_xla/experimental/pjrt.py:238)
  run (/usr/local/lib/python3.8/concurrent/futures/thread.py:57)
  _worker (/usr/local/lib/python3.8/concurrent/futures/thread.py:80)
  run (/usr/local/lib/python3.8/threading.py:870)
  _bootstrap_inner (/usr/local/lib/python3.8/threading.py:932)
  _bootstrap (/usr/local/lib/python3.8/threading.py:890)

Hashes: (1b4ef2d994d6302ffd7eba8bbaba9ab)

## BEGIN_GRAPH
HloModule IrToHlo.175, entry_computation_layout={(bf16[1]{0},f32[],s8[80,50]{0,1},s8[13,10]{0,1},bf16[1]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20]{0},bf16[20,10,5,5]{0,1,3,2},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10]{0},bf16[10,1,5,5]{0,3,2,1},f32[16,1,28,28]{3,2,0,1})->(bf16[16,10]{1,0})}

%AddComputation.10 (x.11: s8[], y.12: s8[]) -> s8[] {
  %x.11 = s8[] parameter(0)
  %y.12 = s8[] parameter(1)
  ROOT %add.13 = s8[] add(s8[] %x.11, s8[] %y.12)
}

%AddComputation.25 (x.26: s8[], y.27: s8[]) -> s8[] {
  %x.26 = s8[] parameter(0)
  %y.27 = s8[] parameter(1)
  ROOT %add.28 = s8[] add(s8[] %x.26, s8[] %y.27)
}

%max_BF16.69 (lhs.70: bf16[], rhs.71: bf16[]) -> bf16[] {
  %lhs.70 = bf16[] parameter(0)
  %rhs.71 = bf16[] parameter(1)
  ROOT %maximum.72 = bf16[] maximum(bf16[] %lhs.70, bf16[] %rhs.71)
}

%ge_BF16.75 (lhs.76: bf16[], rhs.77: bf16[]) -> pred[] {
  %lhs.76 = bf16[] parameter(0)
  %rhs.77 = bf16[] parameter(1)
  ROOT %compare.78 = pred[] compare(bf16[] %lhs.76, bf16[] %rhs.77), direction=GE
}

%max_BF16.79 (lhs.80: bf16[], rhs.81: bf16[]) -> bf16[] {
  %lhs.80 = bf16[] parameter(0)
  %rhs.81 = bf16[] parameter(1)
  ROOT %maximum.82 = bf16[] maximum(bf16[] %lhs.80, bf16[] %rhs.81)
}

%min_U32.93 (lhs.94: u32[], rhs.95: u32[]) -> u32[] {
  %lhs.94 = u32[] parameter(0)
  %rhs.95 = u32[] parameter(1)
  ROOT %minimum.96 = u32[] minimum(u32[] %lhs.94, u32[] %rhs.95)
}

%max_BF16.113 (lhs.114: bf16[], rhs.115: bf16[]) -> bf16[] {
  %lhs.114 = bf16[] parameter(0)
  %rhs.115 = bf16[] parameter(1)
  ROOT %maximum.116 = bf16[] maximum(bf16[] %lhs.114, bf16[] %rhs.115)
}

%ge_BF16.119 (lhs.120: bf16[], rhs.121: bf16[]) -> pred[] {
  %lhs.120 = bf16[] parameter(0)
  %rhs.121 = bf16[] parameter(1)
  ROOT %compare.122 = pred[] compare(bf16[] %lhs.120, bf16[] %rhs.121), direction=GE
}

%max_BF16.123 (lhs.124: bf16[], rhs.125: bf16[]) -> bf16[] {
  %lhs.124 = bf16[] parameter(0)
  %rhs.125 = bf16[] parameter(1)
  ROOT %maximum.126 = bf16[] maximum(bf16[] %lhs.124, bf16[] %rhs.125)
}

%min_U32.137 (lhs.138: u32[], rhs.139: u32[]) -> u32[] {
  %lhs.138 = u32[] parameter(0)
  %rhs.139 = u32[] parameter(1)
  ROOT %minimum.140 = u32[] minimum(u32[] %lhs.138, u32[] %rhs.139)
}

%MaxComputation.157 (x.158: bf16[], y.159: bf16[]) -> bf16[] {
  %x.158 = bf16[] parameter(0)
  %y.159 = bf16[] parameter(1)
  ROOT %maximum.160 = bf16[] maximum(bf16[] %x.158, bf16[] %y.159)
}

%AddComputation.166 (x.167: bf16[], y.168: bf16[]) -> bf16[] {
  %x.167 = bf16[] parameter(0)
  %y.168 = bf16[] parameter(1)
  ROOT %add.169 = bf16[] add(bf16[] %x.167, bf16[] %y.168)
}

ENTRY %IrToHlo.175 (p0.1: bf16[1], p1.2: f32[], p2.3: s8[80,50], p3.18: s8[13,10], p4.40: bf16[1], p5.48: bf16[20], p6.49: bf16[20], p7.50: bf16[20], p8.51: bf16[20], p9.52: bf16[20], p10.53: bf16[20,10,5,5], p11.54: bf16[10], p12.55: bf16[10], p13.56: bf16[10], p14.57: bf16[10], p15.58: bf16[10], p16.59: bf16[10,1,5,5], p17.60: f32[16,1,28,28]) -> (bf16[16,10]) {
  %p3.18 = s8[13,10]{0,1} parameter(3), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.19 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.20 = s8[52,10]{1,0} pad(s8[13,10]{0,1} %p3.18, s8[] %constant.19), padding=0_39x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p2.3 = s8[80,50]{0,1} parameter(2), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %constant.4 = s8[] constant(0), metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %pad.5 = s8[320,50]{1,0} pad(s8[80,50]{0,1} %p2.3, s8[] %constant.4), padding=0_240x0_0, metadata={op_type="aten__constant_pad_nd" op_name="aten__constant_pad_nd" source_file="_all_gather_using_all_reduce@xla_model.py" source_line=653}
  %p1.2 = f32[] parameter(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_get_all_reduce_token@xla_model.py" source_line=484}
  %convert.6 = s8[] convert(f32[] %p1.2), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.7 = (s8[320,50]{1,0}, s8[]) tuple(s8[320,50]{1,0} %pad.5, s8[] %convert.6), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.8 = s8[320,50]{1,0} get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.9 = s8[] get-tuple-element((s8[320,50]{1,0}, s8[]) %tuple.7), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.14 = (s8[320,50]{0,1}, s8[]) all-reduce(s8[320,50]{1,0} %get-tuple-element.8, s8[] %get-tuple-element.9), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.16 = s8[] get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.17 = f32[] convert(s8[] %get-tuple-element.16), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.21 = s8[] convert(f32[] %convert.17), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %tuple.22 = (s8[52,10]{1,0}, s8[]) tuple(s8[52,10]{1,0} %pad.20, s8[] %convert.21), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.23 = s8[52,10]{1,0} get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.24 = s8[] get-tuple-element((s8[52,10]{1,0}, s8[]) %tuple.22), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %all-reduce.29 = (s8[52,10]{0,1}, s8[]) all-reduce(s8[52,10]{1,0} %get-tuple-element.23, s8[] %get-tuple-element.24), replica_groups={}, constrain_layout=true, to_apply=%AddComputation.25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %get-tuple-element.31 = s8[] get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %convert.32 = f32[] convert(s8[] %get-tuple-element.31), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %p17.60 = f32[16,1,28,28]{3,2,0,1} parameter(17), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %convert.61 = bf16[16,1,28,28]{3,2,0,1} convert(f32[16,1,28,28]{3,2,0,1} %p17.60), metadata={op_type="xla__cast" op_name="xla__cast" source_file="fn@xla_fully_sharded_data_parallel.py" source_line=1722}
  %p16.59 = bf16[10,1,5,5]{0,3,2,1} parameter(16), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.62 = bf16[16,10,24,24]{3,2,1,0} convolution(bf16[16,1,28,28]{3,2,0,1} %convert.61, bf16[10,1,5,5]{0,3,2,1} %p16.59), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p15.58 = bf16[10]{0} parameter(15), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.63 = bf16[16,24,24,10]{3,2,1,0} broadcast(bf16[10]{0} %p15.58), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.64 = bf16[16,10,24,24]{1,3,2,0} transpose(bf16[16,24,24,10]{3,2,1,0} %broadcast.63), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.65 = bf16[16,10,24,24]{3,2,1,0} add(bf16[16,10,24,24]{3,2,1,0} %convolution.62, bf16[16,10,24,24]{1,3,2,0} %transpose.64), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.66 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.67 = bf16[16,10,24,24]{3,2,1,0} pad(bf16[16,10,24,24]{3,2,1,0} %add.65, bf16[] %constant.66), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.68 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.73 = bf16[16,10,12,12]{3,2,1,0} reduce-window(bf16[16,10,24,24]{3,2,1,0} %pad.67, bf16[] %constant.68), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.69, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.74 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.83 = bf16[16,10,24,24]{3,2,1,0} select-and-scatter(bf16[16,10,24,24]{3,2,1,0} %pad.67, bf16[16,10,12,12]{3,2,1,0} %reduce-window.73, bf16[] %constant.74), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.75, scatter=%max_BF16.79, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.90 = bf16[16,10,24,24]{3,2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.91 = pred[16,10,24,24]{3,2,1,0} compare(bf16[16,10,24,24]{3,2,1,0} %select-and-scatter.83, bf16[16,10,24,24]{3,2,1,0} %broadcast.90), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.84 = u32[576]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.85 = u32[24,24]{1,0} reshape(u32[576]{0} %iota.84), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.86 = u32[16,10,24,24]{3,2,1,0} broadcast(u32[24,24]{1,0} %reshape.85), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.87 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.88 = u32[16,10,24,24]{3,2,1,0} pad(u32[16,10,24,24]{3,2,1,0} %broadcast.86, u32[] %constant.87), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.89 = u32[16,10,24,24]{3,2,1,0} broadcast(u32[] %constant.87), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.92 = u32[16,10,24,24]{3,2,1,0} select(pred[16,10,24,24]{3,2,1,0} %compare.91, u32[16,10,24,24]{3,2,1,0} %pad.88, u32[16,10,24,24]{3,2,1,0} %broadcast.89), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.97 = u32[16,10,12,12]{3,2,1,0} reduce-window(u32[16,10,24,24]{3,2,1,0} %select.92, u32[] %constant.87), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.93, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p11.54 = bf16[10]{0} parameter(11), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.102 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.103 = bf16[10]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.104 = bf16[10]{0} add(bf16[10]{0} %p11.54, bf16[10]{0} %broadcast.103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.105 = bf16[10]{0} rsqrt(bf16[10]{0} %add.104), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.98 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.99 = bf16[16,10,12,12]{3,2,1,0} broadcast(bf16[] %constant.98), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.100 = bf16[16,10,12,12]{3,2,1,0} maximum(bf16[16,10,12,12]{3,2,1,0} %reduce-window.73, bf16[16,10,12,12]{3,2,1,0} %broadcast.99), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p14.57 = bf16[10]{0} parameter(14), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p13.56 = bf16[10]{0} parameter(13), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p12.55 = bf16[10]{0} parameter(12), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.101 = bf16[16,10,12,12]{3,2,1,0} batch-norm-inference(bf16[16,10,12,12]{3,2,1,0} %maximum.100, bf16[10]{0} %p14.57, bf16[10]{0} %p13.56, bf16[10]{0} %p12.55, bf16[10]{0} %p11.54), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %p10.53 = bf16[20,10,5,5]{0,1,3,2} parameter(10), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %convolution.106 = bf16[16,20,8,8]{3,2,1,0} convolution(bf16[16,10,12,12]{3,2,1,0} %batch-norm-inference.101, bf16[20,10,5,5]{0,1,3,2} %p10.53), window={size=5x5}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %p9.52 = bf16[20]{0} parameter(9), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="_conv_forward@conv.py" source_line=459}
  %broadcast.107 = bf16[16,8,8,20]{3,2,1,0} broadcast(bf16[20]{0} %p9.52), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %transpose.108 = bf16[16,20,8,8]{1,3,2,0} transpose(bf16[16,8,8,20]{3,2,1,0} %broadcast.107), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %add.109 = bf16[16,20,8,8]{3,2,1,0} add(bf16[16,20,8,8]{3,2,1,0} %convolution.106, bf16[16,20,8,8]{1,3,2,0} %transpose.108), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="_conv_forward@conv.py" source_line=459}
  %constant.110 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.111 = bf16[16,20,8,8]{3,2,1,0} pad(bf16[16,20,8,8]{3,2,1,0} %add.109, bf16[] %constant.110), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.112 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.117 = bf16[16,20,4,4]{3,2,1,0} reduce-window(bf16[16,20,8,8]{3,2,1,0} %pad.111, bf16[] %constant.112), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%max_BF16.113, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.118 = bf16[] constant(-inf), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select-and-scatter.127 = bf16[16,20,8,8]{3,2,1,0} select-and-scatter(bf16[16,20,8,8]{3,2,1,0} %pad.111, bf16[16,20,4,4]{3,2,1,0} %reduce-window.117, bf16[] %constant.118), window={size=1x1x2x2 stride=1x1x2x2}, select=%ge_BF16.119, scatter=%max_BF16.123, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.134 = bf16[16,20,8,8]{3,2,1,0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %compare.135 = pred[16,20,8,8]{3,2,1,0} compare(bf16[16,20,8,8]{3,2,1,0} %select-and-scatter.127, bf16[16,20,8,8]{3,2,1,0} %broadcast.134), direction=NE, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %iota.128 = u32[64]{0} iota(), iota_dimension=0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reshape.129 = u32[8,8]{1,0} reshape(u32[64]{0} %iota.128), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.130 = u32[16,20,8,8]{3,2,1,0} broadcast(u32[8,8]{1,0} %reshape.129), dimensions={2,3}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %constant.131 = u32[] constant(4294967295), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %pad.132 = u32[16,20,8,8]{3,2,1,0} pad(u32[16,20,8,8]{3,2,1,0} %broadcast.130, u32[] %constant.131), padding=0_0x0_0x0_0x0_0, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %broadcast.133 = u32[16,20,8,8]{3,2,1,0} broadcast(u32[] %constant.131), dimensions={}, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %select.136 = u32[16,20,8,8]{3,2,1,0} select(pred[16,20,8,8]{3,2,1,0} %compare.135, u32[16,20,8,8]{3,2,1,0} %pad.132, u32[16,20,8,8]{3,2,1,0} %broadcast.133), metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %reduce-window.141 = u32[16,20,4,4]{3,2,1,0} reduce-window(u32[16,20,8,8]{3,2,1,0} %select.136, u32[] %constant.131), window={size=1x1x2x2 stride=1x1x2x2}, to_apply=%min_U32.137, metadata={op_type="aten__max_pool2d" op_name="aten__max_pool2d" source_file="_max_pool2d@functional.py" source_line=782}
  %p5.48 = bf16[20]{0} parameter(5), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %constant.146 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %broadcast.147 = bf16[20]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %add.148 = bf16[20]{0} add(bf16[20]{0} %p5.48, bf16[20]{0} %broadcast.147), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %rsqrt.149 = bf16[20]{0} rsqrt(bf16[20]{0} %add.148), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %constant.142 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.143 = bf16[16,20,4,4]{3,2,1,0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.144 = bf16[16,20,4,4]{3,2,1,0} maximum(bf16[16,20,4,4]{3,2,1,0} %reduce-window.117, bf16[16,20,4,4]{3,2,1,0} %broadcast.143), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %p8.51 = bf16[20]{0} parameter(8), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p7.50 = bf16[20]{0} parameter(7), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %p6.49 = bf16[20]{0} parameter(6), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="batch_norm@functional.py" source_line=2455}
  %batch-norm-inference.145 = bf16[16,20,4,4]{3,2,1,0} batch-norm-inference(bf16[16,20,4,4]{3,2,1,0} %maximum.144, bf16[20]{0} %p8.51, bf16[20]{0} %p7.50, bf16[20]{0} %p6.49, bf16[20]{0} %p5.48), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="batch_norm@functional.py" source_line=2455}
  %reshape.150 = bf16[16,320]{1,0} reshape(bf16[16,20,4,4]{3,2,1,0} %batch-norm-inference.145), metadata={op_type="aten__view" op_name="aten__view" source_file="forward@quant_utils.py" source_line=61}
  %get-tuple-element.15 = s8[320,50]{0,1} get-tuple-element((s8[320,50]{0,1}, s8[]) %all-reduce.14), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.41 = s8[320,50]{1,0} slice(s8[320,50]{0,1} %get-tuple-element.15), slice={[0:320], [0:50]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.42 = bf16[320,50]{1,0} convert(s8[320,50]{1,0} %slice.41), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p4.40 = bf16[1]{0} parameter(4), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.43 = bf16[1]{0} broadcast(bf16[1]{0} %p4.40), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.44 = bf16[] reshape(bf16[1]{0} %broadcast.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.45 = bf16[50]{0} broadcast(bf16[] %reshape.44), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.46 = bf16[320,50]{1,0} broadcast(bf16[50]{0} %broadcast.45), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.47 = bf16[320,50]{1,0} multiply(bf16[320,50]{1,0} %convert.42, bf16[320,50]{1,0} %broadcast.46), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.151 = bf16[16,50]{1,0} dot(bf16[16,320]{1,0} %reshape.150, bf16[320,50]{1,0} %multiply.47), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.152 = bf16[] constant(0), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %broadcast.153 = bf16[16,50]{1,0} broadcast(bf16[] %constant.152), dimensions={}, metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %maximum.154 = bf16[16,50]{1,0} maximum(bf16[16,50]{1,0} %dot.151, bf16[16,50]{1,0} %broadcast.153), metadata={op_type="aten__relu" op_name="aten__relu" source_file="relu@functional.py" source_line=1457}
  %get-tuple-element.30 = s8[52,10]{0,1} get-tuple-element((s8[52,10]{0,1}, s8[]) %all-reduce.29), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="all_reduce@xla_model.py" source_line=592}
  %slice.33 = s8[50,10]{1,0} slice(s8[52,10]{0,1} %get-tuple-element.30), slice={[0:50], [0:10]}, metadata={op_type="xla__select" op_name="xla__select" source_file="forward@quant_utils.py" source_line=60}
  %convert.34 = bf16[50,10]{1,0} convert(s8[50,10]{1,0} %slice.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %p0.1 = bf16[1]{0} parameter(0), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.35 = bf16[1]{0} broadcast(bf16[1]{0} %p0.1), dimensions={0}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %reshape.36 = bf16[] reshape(bf16[1]{0} %broadcast.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.37 = bf16[10]{0} broadcast(bf16[] %reshape.36), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %broadcast.38 = bf16[50,10]{1,0} broadcast(bf16[10]{0} %broadcast.37), dimensions={1}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %multiply.39 = bf16[50,10]{1,0} multiply(bf16[50,10]{1,0} %convert.34, bf16[50,10]{1,0} %broadcast.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="forward@quant_utils.py" source_line=60}
  %dot.155 = bf16[16,10]{1,0} dot(bf16[16,50]{1,0} %maximum.154, bf16[50,10]{1,0} %multiply.39), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="forward@quant_utils.py" source_line=61}
  %constant.156 = bf16[] constant(-inf), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.161 = bf16[16]{0} reduce(bf16[16,10]{1,0} %dot.155, bf16[] %constant.156), dimensions={1}, to_apply=%MaxComputation.157, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.162 = bf16[16,10]{1,0} broadcast(bf16[16]{0} %reduce.161), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.163 = bf16[16,10]{1,0} subtract(bf16[16,10]{1,0} %dot.155, bf16[16,10]{1,0} %broadcast.162), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %exponential.164 = bf16[16,10]{1,0} exponential(bf16[16,10]{1,0} %subtract.163), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %constant.165 = bf16[] constant(0), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %reduce.170 = bf16[16]{0} reduce(bf16[16,10]{1,0} %exponential.164, bf16[] %constant.165), dimensions={1}, to_apply=%AddComputation.166, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %log.171 = bf16[16]{0} log(bf16[16]{0} %reduce.170), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %broadcast.172 = bf16[16,10]{1,0} broadcast(bf16[16]{0} %log.171), dimensions={0}, metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  %subtract.173 = bf16[16,10]{1,0} subtract(bf16[16,10]{1,0} %subtract.163, bf16[16,10]{1,0} %broadcast.172), metadata={op_type="aten__log_softmax" op_name="aten__log_softmax" source_file="log_softmax@functional.py" source_line=1932}
  ROOT %tuple.174 = (bf16[16,10]{1,0}) tuple(bf16[16,10]{1,0} %subtract.173)
}


## END_GRAPH


