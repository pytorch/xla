


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Troubleshooting &mdash; PyTorch/XLA master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Eager Mode + Compile API" href="eager_mode.html" />
    <link rel="prev" title="PyTorch/XLA documentation" href="index.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2023">
                  <span class="dropdown-title">Contributor Awards - 2023</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                  <p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (2.6.0+gitf088810 )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">PyTorch/XLA documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Docs</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="eager_mode.html">Eager Mode + Compile API</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu.html">How to run with PyTorch/XLA:GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_process_distributed.html">How to do DistributedDataParallel(DDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantized_ops.html">Quantized Operations for XLA device (Experimental feature)</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">PJRT Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="spmd.html">PyTorch/XLA SPMD User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="spmd.html#fully-sharded-data-parallel-fsdp-via-spmd">Fully Sharded Data Parallel(FSDP) via SPMD</a></li>
<li class="toctree-l1"><a class="reference internal" href="spmd.html#pytorch-xla-spmd-advanced-topics">PyTorch/XLA SPMD advanced topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="spmd.html#distributed-checkpointing">Distributed Checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile.html">TorchDynamo(torch.compile) integration in PyTorch XLA</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Troubleshooting</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/debug.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id="
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="troubleshooting">
<h1>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this heading">¶</a></h1>
<p>Note that the information in this section is subject to be removed in future releases of the <em>PyTorch/XLA</em> software,
since many of them are peculiar to a given internal implementation which might change.</p>
<div class="section" id="sanity-check">
<h2>Sanity Check<a class="headerlink" href="#sanity-check" title="Permalink to this heading">¶</a></h2>
<p>Before performing any in depth debugging, we want to do a sanity check on the installed PyTorch/XLA.</p>
<div class="section" id="check-pytorch-xla-version">
<h3>Check PyTorch/XLA Version<a class="headerlink" href="#check-pytorch-xla-version" title="Permalink to this heading">¶</a></h3>
<p>PyTorch and PyTorch/XLA version should match. Check out our <a class="reference external" href="https://github.com/pytorch/xla#getting-started">README</a> for more detials on versions available.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vm:~$ python
&gt;&gt;&gt; import torch
&gt;&gt;&gt; import torch_xla
&gt;&gt;&gt; print(torch.__version__)
2.1.0+cu121
&gt;&gt;&gt; print(torch_xla.__version__)
2.1.0
</pre></div>
</div>
</div>
<div class="section" id="perform-a-simple-calculation">
<h3>Perform A Simple Calculation<a class="headerlink" href="#perform-a-simple-calculation" title="Permalink to this heading">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vm:~$ export PJRT_DEVICE=TPU
vm:~$ python3
&gt;&gt;&gt; import torch
&gt;&gt;&gt; import torch_xla.core.xla_model as xm
&gt;&gt;&gt; t1 = torch.tensor(100, device=xm.xla_device())
&gt;&gt;&gt; t2 = torch.tensor(200, device=xm.xla_device())
&gt;&gt;&gt; print(t1 + t2)
tensor(300, device=&#39;xla:0&#39;)
</pre></div>
</div>
</div>
<div class="section" id="run-resnet-with-fake-data">
<h3>Run Resnet With Fake Data<a class="headerlink" href="#run-resnet-with-fake-data" title="Permalink to this heading">¶</a></h3>
<p>For nightly</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vm:~$ git clone https://github.com/pytorch/xla.git
vm:~$ python xla/test/test_train_mp_imagenet.py --fake_data
</pre></div>
</div>
<p>For release version <code class="docutils literal notranslate"><span class="pre">x.y</span></code>, you want to use the branch <code class="docutils literal notranslate"><span class="pre">rx.y</span></code>. For example if you installed 2.1 release, you should do</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vm:~$ git clone --branch r2.1 https://github.com/pytorch/xla.git
vm:~$ python xla/test/test_train_mp_imagenet.py --fake_data
</pre></div>
</div>
<p>If you can get the resnet to run we can conclude that torch_xla is installed correctly.</p>
</div>
</div>
<div class="section" id="performance-debugging">
<h2>Performance Debugging<a class="headerlink" href="#performance-debugging" title="Permalink to this heading">¶</a></h2>
<p>To diagnose performance issues, we can use the execution metrics and counters provided by <em>PyTorch/XLA</em>
The <strong>first thing</strong> to check when model is slow is to generate a metrics report.</p>
<p>Metrics report is extremely helpful in diagnosing issues. Please try to include it in your bug
report sent to us if you have it.</p>
</div>
<div class="section" id="pytorch-xla-debugging-tool">
<h2>PyTorch/XLA Debugging Tool<a class="headerlink" href="#pytorch-xla-debugging-tool" title="Permalink to this heading">¶</a></h2>
<p>You can enable the PyTorch/XLA debugging tool by setting <code class="docutils literal notranslate"><span class="pre">PT_XLA_DEBUG_LEVEL=2</span></code>, which provides a couple useful debugging features. You can also lower the debug level to <code class="docutils literal notranslate"><span class="pre">1</span></code> to slip the execution analysis.</p>
<div class="section" id="perform-a-auto-metrics-analysis">
<h3>Perform A Auto-Metrics Analysis<a class="headerlink" href="#perform-a-auto-metrics-analysis" title="Permalink to this heading">¶</a></h3>
<p>The debugging tool will analyze the metrics report and provide a summary. Some example output would be</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pt</span><span class="o">-</span><span class="n">xla</span><span class="o">-</span><span class="n">profiler</span><span class="p">:</span> <span class="n">CompileTime</span> <span class="n">too</span> <span class="n">frequent</span><span class="p">:</span> <span class="mi">21</span> <span class="n">counts</span> <span class="n">during</span> <span class="mi">11</span> <span class="n">steps</span>
<span class="n">pt</span><span class="o">-</span><span class="n">xla</span><span class="o">-</span><span class="n">profiler</span><span class="p">:</span> <span class="n">TransferFromDeviceTime</span> <span class="n">too</span> <span class="n">frequent</span><span class="p">:</span> <span class="mi">11</span> <span class="n">counts</span> <span class="n">during</span> <span class="mi">11</span> <span class="n">steps</span>
<span class="n">pt</span><span class="o">-</span><span class="n">xla</span><span class="o">-</span><span class="n">profiler</span><span class="p">:</span> <span class="n">Op</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="ow">not</span> <span class="n">lowered</span><span class="p">:</span> <span class="n">aten</span><span class="p">::</span><span class="n">_ctc_loss</span><span class="p">,</span> <span class="n">aten</span><span class="p">::</span><span class="n">_ctc_loss_backward</span><span class="p">,</span>  <span class="n">Please</span> <span class="nb">open</span> <span class="n">a</span> <span class="n">GitHub</span> <span class="n">issue</span> <span class="k">with</span> <span class="n">the</span> <span class="n">above</span> <span class="n">op</span> <span class="n">lowering</span> <span class="n">requests</span><span class="o">.</span>
<span class="n">pt</span><span class="o">-</span><span class="n">xla</span><span class="o">-</span><span class="n">profiler</span><span class="p">:</span> <span class="n">CompileTime</span> <span class="n">too</span> <span class="n">frequent</span><span class="p">:</span> <span class="mi">23</span> <span class="n">counts</span> <span class="n">during</span> <span class="mi">12</span> <span class="n">steps</span>
<span class="n">pt</span><span class="o">-</span><span class="n">xla</span><span class="o">-</span><span class="n">profiler</span><span class="p">:</span> <span class="n">TransferFromDeviceTime</span> <span class="n">too</span> <span class="n">frequent</span><span class="p">:</span> <span class="mi">12</span> <span class="n">counts</span> <span class="n">during</span> <span class="mi">12</span> <span class="n">steps</span>
</pre></div>
</div>
</div>
<div class="section" id="compilation-execution-analysis">
<h3>Compilation &amp; Execution Analysis<a class="headerlink" href="#compilation-execution-analysis" title="Permalink to this heading">¶</a></h3>
<p>The debugging tool will analyze every compilation and execution for your model. Some example output would be</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">================================================================================</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Compilation</span> <span class="n">Cause</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">mark_step</span> <span class="ow">in</span> <span class="n">parallel</span> <span class="n">loader</span> <span class="n">at</span> <span class="n">step</span> <span class="n">end</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Graph</span> <span class="n">Info</span><span class="p">:</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">Graph</span> <span class="n">Hash</span><span class="p">:</span> <span class="n">c74c3b91b855b2b123f833b0d5f86943</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">Number</span> <span class="n">of</span> <span class="n">Graph</span> <span class="n">Inputs</span><span class="p">:</span> <span class="mi">35</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">Number</span> <span class="n">of</span> <span class="n">Graph</span> <span class="n">Outputs</span><span class="p">:</span> <span class="mi">107</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Python</span> <span class="n">Frame</span> <span class="n">Triggered</span> <span class="n">Execution</span><span class="p">:</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">mark_step</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">torch_xla</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">xla_model</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1055</span><span class="p">)</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="nb">next</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">torch_xla</span><span class="o">/</span><span class="n">distributed</span><span class="o">/</span><span class="n">parallel_loader</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">44</span><span class="p">)</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="fm">__next__</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">torch_xla</span><span class="o">/</span><span class="n">distributed</span><span class="o">/</span><span class="n">parallel_loader</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">32</span><span class="p">)</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">train_loop_fn</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">train_decoder_only_base</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">48</span><span class="p">)</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">start_training</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">train_decoder_only_base</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">65</span><span class="p">)</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">train_decoder_only_base</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">73</span><span class="p">)</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">--------------------------------------------------------------------------------</span>
<span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">================================================================================</span>

<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">================================================================================</span>
<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Graph</span> <span class="nb">input</span> <span class="n">size</span><span class="p">:</span> <span class="mf">1.548000</span> <span class="n">GB</span>
<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Graph</span> <span class="n">output</span> <span class="n">size</span><span class="p">:</span> <span class="mf">7.922460</span> <span class="n">GB</span>
<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Aliased</span> <span class="n">Input</span> <span class="n">size</span><span class="p">:</span> <span class="mf">1.547871</span> <span class="n">GB</span>
<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Intermediate</span> <span class="n">tensor</span> <span class="n">size</span><span class="p">:</span> <span class="mf">12.124478</span> <span class="n">GB</span>
<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Compiled</span> <span class="n">program</span> <span class="n">size</span><span class="p">:</span> <span class="mf">0.028210</span> <span class="n">GB</span>
<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">--------------------------------------------------------------------------------</span>
<span class="n">Post</span> <span class="n">Compilation</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">================================================================================</span>

<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">================================================================================</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Execution</span> <span class="n">Cause</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">mark_step</span> <span class="ow">in</span> <span class="n">parallel</span> <span class="n">loader</span> <span class="n">at</span> <span class="n">step</span> <span class="n">end</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Graph</span> <span class="n">Info</span><span class="p">:</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">Graph</span> <span class="n">Hash</span><span class="p">:</span> <span class="n">c74c3b91b855b2b123f833b0d5f86943</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">Number</span> <span class="n">of</span> <span class="n">Graph</span> <span class="n">Inputs</span><span class="p">:</span> <span class="mi">35</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">Number</span> <span class="n">of</span> <span class="n">Graph</span> <span class="n">Outputs</span><span class="p">:</span> <span class="mi">107</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span> <span class="n">Python</span> <span class="n">Frame</span> <span class="n">Triggered</span> <span class="n">Execution</span><span class="p">:</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">mark_step</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">torch_xla</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">xla_model</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1055</span><span class="p">)</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="nb">next</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">torch_xla</span><span class="o">/</span><span class="n">distributed</span><span class="o">/</span><span class="n">parallel_loader</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">44</span><span class="p">)</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="fm">__next__</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">torch_xla</span><span class="o">/</span><span class="n">distributed</span><span class="o">/</span><span class="n">parallel_loader</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">32</span><span class="p">)</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">train_loop_fn</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">train_decoder_only_base</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">48</span><span class="p">)</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="n">start_training</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">train_decoder_only_base</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">65</span><span class="p">)</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span>   <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span> <span class="p">(</span><span class="o">/</span><span class="n">workspaces</span><span class="o">/</span><span class="n">dk3</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">train_decoder_only_base</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">73</span><span class="p">)</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">--------------------------------------------------------------------------------</span>
<span class="n">Execution</span> <span class="n">Analysis</span><span class="p">:</span> <span class="o">================================================================================</span>
</pre></div>
</div>
<p>Some common causes of Compilation/Executation are</p>
<ol class="arabic simple">
<li><p>User manually call <code class="docutils literal notranslate"><span class="pre">mark_step</span></code>.</p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/xla/blob/fe4af0080af07f78ca2b614dd91b71885a3bbbb8/torch_xla/distributed/parallel_loader.py#L49-L51">Parallel loader</a> call <code class="docutils literal notranslate"><span class="pre">mark_step</span></code> for every x (configurable) batch.</p></li>
<li><p>Exiting a <a class="reference external" href="https://github.com/pytorch/xla/blob/fe4af0080af07f78ca2b614dd91b71885a3bbbb8/torch_xla/debug/profiler.py#L165-L171">profiler StepTrace region</a>.</p></li>
<li><p>Dynamo decide to compile/execute the graph.</p></li>
<li><p>User trying to access(often due to logging) the value of a tensor before the <code class="docutils literal notranslate"><span class="pre">mark_step</span></code>.</p></li>
</ol>
<p>The executation caused by 1-4 are expected, and we want to avoid 5 by either reduce the frequency of accessing tensor values or manually add a <code class="docutils literal notranslate"><span class="pre">mark_step</span></code> before accessing.</p>
<p>Users should expect to see this <code class="docutils literal notranslate"><span class="pre">Compilation</span> <span class="pre">Cause</span></code> + <code class="docutils literal notranslate"><span class="pre">Executation</span> <span class="pre">Cause</span></code> pairs for first couple steps. After the model stabilize users should expect to only see <code class="docutils literal notranslate"><span class="pre">Execution</span> <span class="pre">Cause</span></code>(you can disable execution analysis by <code class="docutils literal notranslate"><span class="pre">PT_XLA_DEBUG_LEVEL=1</span></code>). To use PyTorch/XLA efficiently, we expect the same models code to be run for every step and compilation only happen once for every graph. If you keep seeing <code class="docutils literal notranslate"><span class="pre">Compilation</span> <span class="pre">Cause</span></code>, you should try to dump the IR/HLO following <a class="reference external" href="#common-debugging-environment-variables-combinations">this section</a> and compare the graphs for each step and understand the source of the differences.</p>
<p>Following section will explain how to get and understand a more detail metrics report.</p>
</div>
</div>
<div class="section" id="get-a-metrics-report">
<h2>Get A Metrics Report<a class="headerlink" href="#get-a-metrics-report" title="Permalink to this heading">¶</a></h2>
<p>Put the following line in your program to generate a report:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch_xla.debug.metrics</span> <span class="k">as</span> <span class="nn">met</span>

<span class="c1"># For short report that only contains a few key metrics.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">met</span><span class="o">.</span><span class="n">short_metrics_report</span><span class="p">())</span>
<span class="c1"># For full report that includes all metrics.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">met</span><span class="o">.</span><span class="n">metrics_report</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="section" id="understand-the-metrics-report">
<h2>Understand The Metrics Report<a class="headerlink" href="#understand-the-metrics-report" title="Permalink to this heading">¶</a></h2>
<p>The report includes things like:</p>
<ul class="simple">
<li><p>how many time we issue <em>XLA</em> compilations and time spent on issuing.</p></li>
<li><p>how many times we execute and time spent on execution</p></li>
<li><p>how many device data handles we create/destroy etc.</p></li>
</ul>
<p>This information is reported in terms of percentiles of the samples. An example is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Metric</span><span class="p">:</span> <span class="n">CompileTime</span>
  <span class="n">TotalSamples</span><span class="p">:</span> <span class="mi">202</span>
  <span class="n">Counter</span><span class="p">:</span> <span class="mi">06</span><span class="n">m09s401ms746</span><span class="mf">.001</span><span class="n">us</span>
  <span class="n">ValueRate</span><span class="p">:</span> <span class="mi">778</span><span class="n">ms572</span><span class="mf">.062</span><span class="n">us</span> <span class="o">/</span> <span class="n">second</span>
  <span class="n">Rate</span><span class="p">:</span> <span class="mf">0.425201</span> <span class="o">/</span> <span class="n">second</span>
  <span class="n">Percentiles</span><span class="p">:</span> <span class="mi">1</span><span class="o">%=</span><span class="mi">001</span><span class="n">ms32</span><span class="mf">.778</span><span class="n">us</span><span class="p">;</span> <span class="mi">5</span><span class="o">%=</span><span class="mi">001</span><span class="n">ms61</span><span class="mf">.283</span><span class="n">us</span><span class="p">;</span> <span class="mi">10</span><span class="o">%=</span><span class="mi">001</span><span class="n">ms79</span><span class="mf">.236</span><span class="n">us</span><span class="p">;</span> <span class="mi">20</span><span class="o">%=</span><span class="mi">001</span><span class="n">ms110</span><span class="mf">.973</span><span class="n">us</span><span class="p">;</span> <span class="mi">50</span><span class="o">%=</span><span class="mi">001</span><span class="n">ms228</span><span class="mf">.773</span><span class="n">us</span><span class="p">;</span> <span class="mi">80</span><span class="o">%=</span><span class="mi">001</span><span class="n">ms339</span><span class="mf">.183</span><span class="n">us</span><span class="p">;</span> <span class="mi">90</span><span class="o">%=</span><span class="mi">001</span><span class="n">ms434</span><span class="mf">.305</span><span class="n">us</span><span class="p">;</span> <span class="mi">95</span><span class="o">%=</span><span class="mi">002</span><span class="n">ms921</span><span class="mf">.063</span><span class="n">us</span><span class="p">;</span> <span class="mi">99</span><span class="o">%=</span><span class="mi">21</span><span class="n">s102ms853</span><span class="mf">.173</span><span class="n">us</span>
</pre></div>
</div>
<p>We also provide counters, which are named integer variables which track internal software status. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">:</span> <span class="n">CachedSyncTensors</span>
  <span class="n">Value</span><span class="p">:</span> <span class="mi">395</span>
</pre></div>
</div>
<p>In this report, any counter that starts with <code class="docutils literal notranslate"><span class="pre">aten::</span></code>
indicates a context switch between the XLA device and CPU, which can be a
potential performance optimization area in the model code.</p>
<p>Counters are useful to understand which operations are routed back to the CPU engine of <em>PyTorch</em>.
They are fully qualified with their C++ namespace:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">:</span> <span class="n">aten</span><span class="p">::</span><span class="n">nonzero</span>
  <span class="n">Value</span><span class="p">:</span> <span class="mi">33</span>
</pre></div>
</div>
<p>If you see <code class="docutils literal notranslate"><span class="pre">aten::</span></code> ops other than <code class="docutils literal notranslate"><span class="pre">nonzero</span></code> and <code class="docutils literal notranslate"><span class="pre">_local_scalar_dense</span></code>, that usually means a missing
lowering in PyTorch/XLA. Feel free to open a feature request for it on <a class="reference external" href="https://github.com/pytorch/xla/issues">GitHub issues</a>.</p>
</div>
<div class="section" id="clear-the-metrics-report">
<h2>Clear The Metrics Report<a class="headerlink" href="#clear-the-metrics-report" title="Permalink to this heading">¶</a></h2>
<p>If you want to clear the metrics between steps/epochs, you can use</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch_xla.debug.metrics</span> <span class="k">as</span> <span class="nn">met</span>

<span class="n">met</span><span class="o">.</span><span class="n">clear_all</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="pytorch-xla-dynamo-debugging-tool">
<h2>PyTorch/XLA + Dynamo Debugging Tool<a class="headerlink" href="#pytorch-xla-dynamo-debugging-tool" title="Permalink to this heading">¶</a></h2>
<p>You can enable the PyTorch/XLA + Dynamo debugging tool by setting <code class="docutils literal notranslate"><span class="pre">XLA_DYNAMO_DEBUG=1</span></code>.</p>
</div>
<div class="section" id="performance-profiling">
<h2>Performance Profiling<a class="headerlink" href="#performance-profiling" title="Permalink to this heading">¶</a></h2>
<p>To profile your workload in depth to understand bottlenecks please check the following resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cloud.google.com/tpu/docs/pytorch-xla-performance-profiling-tpu-vm">Official tutorial</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/pytorch-xla-profiling-colab.ipynb">Colab notebook</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/xla/blob/master/test/test_profile_mp_mnist.py">Sample MNIST training script with profiling</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/xla/blob/master/scripts/capture_profile.py">Utility script for capturing performance profiles</a></p></li>
</ul>
</div>
<div class="section" id="simple-benchmarking">
<h2>Simple Benchmarking<a class="headerlink" href="#simple-benchmarking" title="Permalink to this heading">¶</a></h2>
<p>Take a look at <cite>``examples/train_resnet_benchmark.py`</cite> &lt;<a class="reference external" href="https://github.com/pytorch/xla/blob/master/examples/train_resnet_benchmark.py">https://github.com/pytorch/xla/blob/master/examples/train_resnet_benchmark.py</a>&gt;`_ for how to benchmark a PyTorch/XLA model.</p>
</div>
<div class="section" id="known-performance-caveats">
<h2>Known Performance Caveats<a class="headerlink" href="#known-performance-caveats" title="Permalink to this heading">¶</a></h2>
<p>PyTorch/XLA behaves semantically like regular PyTorch and XLA tensors share the full tensor interface with CPU &amp; GPU tensors.
However, constraints in XLA/hardware and the lazy evaluation model suggest certain patterns might result in bad performance.</p>
<p>If your model shows bad performance, keep in mind the following caveats:</p>
<ol class="arabic">
<li><p><strong>XLA/TPU yield degraded performance with too many recompilations.</strong></p>
<p>XLA compilation is expensive. PyTorch/XLA automatically recompiles the graph every time new shapes are encountered.
Usually models should stabilize within a few steps and you can see huge speedup for the rest of training.</p>
<p>In order to avoid recompilations, not only must shapes be constant, but computations across XLA devices in all hosts should also be constant.</p>
<p><em>Possible sources</em>:</p>
<ul class="simple">
<li><p>Direct or indirect uses of <code class="docutils literal notranslate"><span class="pre">nonzero</span></code> introduce dynamic shapes; for example, masked indexing <code class="docutils literal notranslate"><span class="pre">base[index]</span></code> where <code class="docutils literal notranslate"><span class="pre">index</span></code> is a mask tensor.</p></li>
<li><p>Loops with a different number of iterations between steps can result in different execution graphs, thus require recompilations.</p></li>
</ul>
<p><em>Solution</em>:</p>
<ul class="simple">
<li><p>Tensor shapes should be the same between iterations, or a low number of shape variations should be used.</p></li>
<li><p>Pad tensors to fixed sizes when possible.</p></li>
</ul>
</li>
<li><p><strong>Certain operations don’t have native translations to XLA.</strong></p>
<p>For these operations PyTorch/XLA automatically transfers to the CPU memory, evaluates on CPU, and transfers the result back to the XLA device.
Doing too many such operations during the training step can lead to significant slowdowns.</p>
<p><em>Possible sources</em>:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">item()</span></code> operation explicitly asks to evaluate the result. Don’t use it unless it’s necessary.</p></li>
</ul>
<p><em>Solution</em>:</p>
<ul>
<li><p>For most ops we can lower them to XLA to fix it. Checkout <a class="reference external" href="#metrics-report">metrics report section</a> to find out the missing ops and open a feature request on <a class="reference external" href="https://github.com/pytorch/xla/issues">GitHub</a>.</p></li>
<li><p>Even when a PyTorch tensor is known as a scalar, avoid using <code class="docutils literal notranslate"><span class="pre">tensor.item()</span></code>. Keep it as a tensor and use tensor operations on it.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">torch.where</span></code> to substitute control flow when applicable.
E.g. The control flow with <code class="docutils literal notranslate"><span class="pre">item()</span></code> used in <a class="reference external" href="https://github.com/pytorch/pytorch/blob/de19eeee99a2a282fc441f637b23d8e50c75ecd1/torch/nn/utils/clip_grad.py#L33">clip_grad*norm*</a> is problematic and impacts performance, so we have <a class="reference external" href="https://github.com/pytorch/xla/blob/master/torch_patches/X10-clip_grad.diff">patched</a> <code class="docutils literal notranslate"><span class="pre">clip_grad_norm_</span></code> by calling <code class="docutils literal notranslate"><span class="pre">torch.where</span></code> instead, which gives us a dramatic performance improvement.
.. code-block:: python</p>
<blockquote>
<div><p>…
else:</p>
<blockquote>
<div><p>device = parameters[0].device
total_norm = torch.zeros([], device=device if parameters else None)
for p in parameters:</p>
<blockquote>
<div><p>param_norm = p.grad.data.norm(norm_type) ** norm_type
total_norm.add_(param_norm)</p>
</div></blockquote>
<p>total_norm = (total_norm ** (1. / norm_type))</p>
</div></blockquote>
<p>clip_coef = torch.tensor(max_norm, device=device) / (total_norm + 1e-6)
for p in parameters:</p>
<blockquote>
<div><p>p.grad.data.mul_(torch.where(clip_coef &lt; 1, clip_coef, torch.tensor(1., device=device)))</p>
</div></blockquote>
</div></blockquote>
</li>
</ul>
</li>
<li><p><strong>Iterators in ``torch_xla.distributed.data_parallel`` may drop the last few batches in the input iterator.</strong></p>
<p>This is to make sure we do the same amount of work on all XLA devices.</p>
<p><em>Solution</em>:</p>
<ul class="simple">
<li><p>When dataset is small, and there are too few steps, this may result in a no-op epoch. Therefore, it is better to use
small batch sizes in those cases.</p></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="xla-tensor-quirks">
<h2>XLA Tensor Quirks<a class="headerlink" href="#xla-tensor-quirks" title="Permalink to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p><strong>XLA tensor internals are opaque.</strong> XLA tensors always appear to be
contiguous and without storage. Networks should not try to check the strides
of XLA tensors.</p></li>
<li><p><strong>XLA tensors should be moved to the CPU before saving them.</strong> Saving
XLA tensors directly causes them to be loaded back on the device(s) they were
saved from. If a device is unavailable at load time then the load will fail.
Moving XLA tensors to the CPU before saving them lets you decide which
device(s) to put the loaded tensors on. This is necessary if you want to
load the tensors on a machine without XLA devices. Care should be taken
moving the XLA tensors to the CPU before saving them, however, as moving
tensors across device types does not preserve view relationships. Instead,
views should be reconstructed as necessary after the tensors are loaded.</p></li>
<li><p><strong>Copying an XLA Tensor with Python’s copy.copy returns a deep copy, not a
shallow copy.</strong> Use a view of an XLA tensor to get a shallow copy of it.</p></li>
<li><p><strong>Handling shared weights.</strong> Modules can share weights by setting the
Parameters of one module to another. This “tying” of module weights should
be done <strong>AFTER</strong> the modules are moved to an XLA device. Otherwise two
independent copies of the shared tensor will be made on the XLA device.</p></li>
</ol>
</div>
<div class="section" id="more-debugging-tools">
<h2>More Debugging Tools<a class="headerlink" href="#more-debugging-tools" title="Permalink to this heading">¶</a></h2>
<p>We don’t expect users to use tools in this section to debug their models. But we might ask for
them when you submit a bug report since they provide additional information that metrics report
doesn’t have.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">print(torch_xla._XLAC._get_xla_tensors_text([res]))</span></code> where <code class="docutils literal notranslate"><span class="pre">res</span></code> is the result tensor prints out the IR.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">print(torch_xla._XLAC._get_xla_tensors_hlo([res]))</span></code> where <code class="docutils literal notranslate"><span class="pre">res</span></code> is the result tensor prints out the generated XLA HLO.</p></li>
</ul>
<p>Note these functions must be called prior to <code class="docutils literal notranslate"><span class="pre">mark_step()</span></code>, otherwise the tensor will already be materialized.</p>
<div class="section" id="environment-variables">
<h3>Environment Variables<a class="headerlink" href="#environment-variables" title="Permalink to this heading">¶</a></h3>
<p>There are also a number of environment variables which control the behavior of the <em>PyTorch/XLA</em>
software stack.</p>
<p>Setting such variables will cause different degrees of performance degradation, so they should
only be enabled for debugging.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_IR_DEBUG</span></code>: Enables the <em>Python</em> stack trace to be captured where creating IR nodes,
hence allowing to understand which <em>PyTorch</em> operation was responsible for generating the IR.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_HLO_DEBUG</span></code>: Enables the <em>Python</em> stack frame captured when _XLA_IR<em>DEBUG</em> is active,
to be propagated to the <em>XLA</em> <em>HLO</em> metadata.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_SAVE_TENSORS_FILE</span></code>: The path to a file which will be used to dump the IR graphs during
execution. Note that the file can become really big if the option is left enabled and the
<em>PyTorch</em> program let run for long time. The graphs are appended to the file, so to have a clean
sheet from run to run, the file should be explicitly removed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_SAVE_TENSORS_FMT</span></code>: The format of the graphs stored within the _XLA_SAVE_TENSORS<em>FILE</em>
file. Can be <code class="docutils literal notranslate"><span class="pre">text</span></code> (the default), <code class="docutils literal notranslate"><span class="pre">dot</span></code> (the <em>Graphviz</em> format) or <code class="docutils literal notranslate"><span class="pre">hlo</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_FLAGS=--xla_dump_to</span></code>: If set to <code class="docutils literal notranslate"><span class="pre">=/tmp/dir_name</span></code>, XLA compiler will dump the unoptimized and optimzed HLO per compilation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_METRICS_FILE</span></code>: If set, the path to a local file where the internal metrics will be
saved at every step. Metrics will be appended to the file, if already existing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_SAVE_HLO_FILE</span></code>: If set, the path to a local file where, in case of compilation/execution
error, the offending HLO graph will be saved.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_SYNC_WAIT</span></code>: Forces the XLA tensor sync operation to wait for its completion, before
moving to the next step.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_USE_EAGER_DEBUG_MODE</span></code>: Forces the XLA tensor to execute eagerly, meaning compile and execute the torch operations one
by one. This is useful to bypass the long compilation time but overall step time will be a lot slower and memory usage will be higher
since all compiler optimizaiton will be skipped.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TF_CPP_LOG_THREAD_ID</span></code>: If set to 1, the TF logs will show the thread ID
helping with debugging multithreaded processes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TF_CPP_VMODULE</span></code>: Environment variable used for TF VLOGs and takes the
form of <code class="docutils literal notranslate"><span class="pre">TF_CPP_VMODULE=name=value,...</span></code>. Note that for VLOGs you must set
<code class="docutils literal notranslate"><span class="pre">TF_CPP_MIN_LOG_LEVEL=0</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TF_CPP_MIN_LOG_LEVEL</span></code>: Level to print messages for. <code class="docutils literal notranslate"><span class="pre">TF_CPP_MIN_LOG_LEVEL=0</span></code> will turn
on INFO logging, <code class="docutils literal notranslate"><span class="pre">TF_CPP_MIN_LOG_LEVEL=1</span></code> WARNING and so on. Our PyTorch/XLA <code class="docutils literal notranslate"><span class="pre">TF_VLOG</span></code> uses
<code class="docutils literal notranslate"><span class="pre">tensorflow::INFO</span></code> level by default so to see VLOGs set <code class="docutils literal notranslate"><span class="pre">TF_CPP_MIN_LOG_LEVEL=0</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">XLA_DUMP_HLO_GRAPH</span></code>: If set to <code class="docutils literal notranslate"><span class="pre">=1</span></code> in case of a compilation or execution error the
offending HLO graph will be dumped as part of the runtime error raised by <code class="docutils literal notranslate"><span class="pre">xla_util.cc</span></code>.</p></li>
</ul>
</div>
<div class="section" id="common-debugging-environment-variables-combinations">
<h3>Common Debugging Environment Variables Combinations<a class="headerlink" href="#common-debugging-environment-variables-combinations" title="Permalink to this heading">¶</a></h3>
<ul>
<li><p>Record the graph execution in the IR format</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">XLA_IR_DEBUG</span><span class="o">=</span><span class="mi">1</span> <span class="n">XLA_HLO_DEBUG</span><span class="o">=</span><span class="mi">1</span> <span class="n">XLA_SAVE_TENSORS_FMT</span><span class="o">=</span><span class="s2">&quot;text&quot;</span> <span class="n">XLA_SAVE_TENSORS_FILE</span><span class="o">=</span><span class="s2">&quot;/tmp/save1.ir&quot;</span>
</pre></div>
</div>
</li>
<li><p>Record the graph execution in the HLO format</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">XLA_IR_DEBUG</span><span class="o">=</span><span class="mi">1</span> <span class="n">XLA_HLO_DEBUG</span><span class="o">=</span><span class="mi">1</span> <span class="n">XLA_SAVE_TENSORS_FMT</span><span class="o">=</span><span class="s2">&quot;hlo&quot;</span> <span class="n">XLA_SAVE_TENSORS_FILE</span><span class="o">=</span><span class="s2">&quot;/tmp/save1.hlo&quot;</span>
</pre></div>
</div>
</li>
<li><p>Show debugging VLOG for runtime and graph compilation/execution</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TF_CPP_MIN_LOG_LEVEL</span><span class="o">=</span><span class="mi">0</span> <span class="n">TF_CPP_VMODULE</span><span class="o">=</span><span class="s2">&quot;xla_graph_executor=5,pjrt_computation_client=3&quot;</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="reproducing-pytorch-xla-ci-cd-unit-test-failures">
<h3>Reproducing PyTorch/XLA CI/CD unit test failures.<a class="headerlink" href="#reproducing-pytorch-xla-ci-cd-unit-test-failures" title="Permalink to this heading">¶</a></h3>
<p>You may see some test failures for a PR such as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">To</span> <span class="n">execute</span> <span class="n">this</span> <span class="n">test</span><span class="p">,</span> <span class="n">run</span> <span class="n">the</span> <span class="n">following</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">base</span> <span class="n">repo</span> <span class="nb">dir</span><span class="p">:</span>
    <span class="n">PYTORCH_TEST_WITH_SLOW</span><span class="o">=</span><span class="mi">1</span> <span class="n">python</span> <span class="o">../</span><span class="n">test</span><span class="o">/</span><span class="n">test_torch</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">k</span> <span class="n">test_put_xla_uint8</span>
</pre></div>
</div>
<p>Running this directly in the command line does not work. You need to set the environment variable <code class="docutils literal notranslate"><span class="pre">TORCH_TEST_DEVICES</span></code> to your local <code class="docutils literal notranslate"><span class="pre">pytorch/xla/test/pytorch_test_base.py</span></code>. For example:</p>
<p><code class="docutils literal notranslate"><span class="pre">TORCH_TEST_DEVICES=/path/to/pytorch/xla/test/pytorch_test_base.py</span> <span class="pre">PYTORCH_TEST_WITH_SLOW=1</span> <span class="pre">python</span> <span class="pre">../test/test_torch.py</span> <span class="pre">-k</span> <span class="pre">test_put_xla_uint8</span></code> should work.</p>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="eager_mode.html" class="btn btn-neutral float-right" title="Eager Mode + Compile API" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="PyTorch/XLA documentation" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright .

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Troubleshooting</a><ul>
<li><a class="reference internal" href="#sanity-check">Sanity Check</a><ul>
<li><a class="reference internal" href="#check-pytorch-xla-version">Check PyTorch/XLA Version</a></li>
<li><a class="reference internal" href="#perform-a-simple-calculation">Perform A Simple Calculation</a></li>
<li><a class="reference internal" href="#run-resnet-with-fake-data">Run Resnet With Fake Data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#performance-debugging">Performance Debugging</a></li>
<li><a class="reference internal" href="#pytorch-xla-debugging-tool">PyTorch/XLA Debugging Tool</a><ul>
<li><a class="reference internal" href="#perform-a-auto-metrics-analysis">Perform A Auto-Metrics Analysis</a></li>
<li><a class="reference internal" href="#compilation-execution-analysis">Compilation &amp; Execution Analysis</a></li>
</ul>
</li>
<li><a class="reference internal" href="#get-a-metrics-report">Get A Metrics Report</a></li>
<li><a class="reference internal" href="#understand-the-metrics-report">Understand The Metrics Report</a></li>
<li><a class="reference internal" href="#clear-the-metrics-report">Clear The Metrics Report</a></li>
<li><a class="reference internal" href="#pytorch-xla-dynamo-debugging-tool">PyTorch/XLA + Dynamo Debugging Tool</a></li>
<li><a class="reference internal" href="#performance-profiling">Performance Profiling</a></li>
<li><a class="reference internal" href="#simple-benchmarking">Simple Benchmarking</a></li>
<li><a class="reference internal" href="#known-performance-caveats">Known Performance Caveats</a></li>
<li><a class="reference internal" href="#xla-tensor-quirks">XLA Tensor Quirks</a></li>
<li><a class="reference internal" href="#more-debugging-tools">More Debugging Tools</a><ul>
<li><a class="reference internal" href="#environment-variables">Environment Variables</a></li>
<li><a class="reference internal" href="#common-debugging-environment-variables-combinations">Common Debugging Environment Variables Combinations</a></li>
<li><a class="reference internal" href="#reproducing-pytorch-xla-ci-cd-unit-test-failures">Reproducing PyTorch/XLA CI/CD unit test failures.</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>