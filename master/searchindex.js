Search.setIndex({"docnames": ["accelerators/gpu", "accelerators/tpu", "contribute/bazel", "contribute/codegen_migration", "contribute/configure-environment", "contribute/op_lowering", "contribute/plugins", "features/pallas", "features/stablehlo", "features/triton", "index", "learn/api-guide", "learn/dynamic_shape", "learn/eager", "learn/pjrt", "learn/pytorch-on-xla-devices", "learn/troubleshoot", "learn/xla-overview", "notes/source_of_recompilation", "perf/amp", "perf/ddp", "perf/dynamo", "perf/fori_loop", "perf/fsdp", "perf/fsdpv2", "perf/quantized_ops", "perf/recompilation", "perf/spmd_advanced", "perf/spmd_basic", "perf/spmd_distributed_checkpoint", "perf/spmd_gpu"], "filenames": ["accelerators/gpu.md", "accelerators/tpu.md", "contribute/bazel.md", "contribute/codegen_migration.md", "contribute/configure-environment.md", "contribute/op_lowering.md", "contribute/plugins.md", "features/pallas.md", "features/stablehlo.md", "features/triton.md", "index.rst", "learn/api-guide.rst", "learn/dynamic_shape.md", "learn/eager.md", "learn/pjrt.md", "learn/pytorch-on-xla-devices.md", "learn/troubleshoot.md", "learn/xla-overview.md", "notes/source_of_recompilation.md", "perf/amp.md", "perf/ddp.md", "perf/dynamo.md", "perf/fori_loop.md", "perf/fsdp.md", "perf/fsdpv2.md", "perf/quantized_ops.md", "perf/recompilation.md", "perf/spmd_advanced.md", "perf/spmd_basic.md", "perf/spmd_distributed_checkpoint.md", "perf/spmd_gpu.md"], "titles": ["Learn about GPUs", "Learn about TPUs", "Bazel in Pytorch/XLA", "Codegen migration Guide", "Configure a development environment", "OP Lowering Guide", "Custom Hardware Plugins", "Custom Kernels via Pallas", "Torch Export to StableHLO", "Custom GPU Kernels via Triton", "PyTorch/XLA documentation", "PyTorch/XLA API", "Dynamic shape", "Eager Mode + Compile API", "PJRT Runtime", "PyTorch on XLA Devices", "Troubleshoot", "Pytorch/XLA overview", "Source of recompilations in torch_xla", "Automatic Mixed Precision", "How to do DistributedDataParallel(DDP)", "TorchDynamo integration in PyTorch XLA", "Optimize memory utilization using <code class=\"docutils literal notranslate\"><span class=\"pre\">while_loop</span></code>", "Fully Sharded Data Parallel in PyTorch XLA", "Fully Sharded Data Parallel using SPMD", "Quantized Operations for XLA (Experimental feature)", "Source of recompilations in Pytorch/XLA", "PyTorch/XLA SPMD advanced topics", "PyTorch/XLA SPMD User Guide", "Distributed Checkpointing", "Running SPMD on GPU"], "terms": {"For": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30], "inform": [0, 1, 4, 9, 11, 13, 14, 15, 16, 17, 18, 26, 30], "googl": [0, 1, 7, 14, 15], "cloud": [0, 1, 2, 4, 6, 10, 14, 15, 21, 29], "see": [0, 1, 2, 3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 26], "machin": [0, 2, 4, 14, 16, 17, 30], "type": [0, 4, 6, 8, 11, 14, 15, 16, 17, 19, 20], "ar": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29], "custom": [1, 3, 4, 10, 11, 18, 20, 23, 25, 26, 27, 28], "design": [1, 14, 15, 21, 24, 28], "ai": 1, "acceler": [1, 4, 11, 12, 14, 15, 17, 19], "which": [1, 2, 3, 5, 6, 8, 11, 12, 14, 15, 16, 17, 18, 19, 21, 23, 24, 26, 27, 29], "optim": [1, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26], "train": [1, 7, 11, 12, 15, 16, 17, 19, 27, 29, 30], "infer": [1, 3, 11, 14, 19, 27, 30], "larg": [1, 12, 14, 17, 18, 23, 26, 28], "model": [1, 3, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30], "thei": [1, 2, 5, 6, 11, 14, 15, 16, 17, 18, 19, 26, 27, 28], "ideal": [1, 2, 3, 18, 21, 26], "varieti": 1, "us": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 21, 23, 27, 29, 30], "case": [1, 2, 3, 5, 8, 11, 14, 15, 16, 17, 21, 24, 27], "chatbot": 1, "code": [1, 3, 5, 8, 9, 11, 13, 14, 15, 16, 18, 20, 21, 26, 27], "gener": [1, 5, 11, 13, 14, 15, 16, 17, 18, 26], "media": 1, "content": [1, 11], "synthet": 1, "speech": 1, "vision": [1, 23], "servic": [1, 2, 14], "recommend": [1, 2, 3, 4, 5, 11, 13, 14, 15, 19, 27], "engin": [1, 16], "person": 1, "among": 1, "other": [1, 2, 3, 5, 7, 11, 12, 14, 15, 16, 17, 18, 19, 20, 25, 26, 28], "scale": [1, 8, 11, 14, 19, 21, 28], "cost": [1, 21], "effici": [1, 8, 16, 17, 21], "wide": [1, 5, 18, 26], "rang": [1, 5, 11, 14, 24, 27, 28], "workload": [1, 14, 15, 16, 27, 28], "span": [1, 3], "fine": 1, "tune": [1, 27], "provid": [1, 2, 3, 5, 6, 7, 8, 11, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29], "versatil": 1, "lead": [1, 16, 17], "framework": [1, 8, 10, 13, 18, 25, 26], "includ": [1, 2, 5, 11, 14, 16, 17, 18, 19, 22, 26, 29], "pytorch": [1, 5, 9, 12, 13, 14, 18, 19, 20, 22, 25, 29, 30], "jax": [1, 6, 7, 8, 14], "tensorflow": [1, 2, 6, 8, 11, 14, 16, 18, 26], "seamlessli": 1, "orchestr": 1, "through": [1, 3, 5, 6, 7, 15, 17, 18, 19, 26, 29], "integr": [1, 9, 10, 24, 25, 28], "kubernet": 1, "gke": 1, "leverag": [1, 9, 30], "dynam": [1, 3, 5, 10, 16, 17, 21], "schedul": [1, 17], "improv": [1, 14, 15, 16, 17, 19, 21, 27], "scalabl": 1, "all": [1, 2, 3, 5, 9, 11, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 29], "need": [1, 2, 3, 5, 11, 14, 15, 16, 17, 18, 20, 23, 24, 26, 27, 28], "simultan": 1, "look": [1, 3, 5, 15, 16, 17, 27], "simplest": 1, "wai": [1, 2, 5, 7, 11, 14, 15, 17, 18, 20, 21, 25, 26, 27], "develop": [1, 2, 9, 10, 13, 15, 20, 21, 25, 28], "can": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30], "also": [1, 2, 3, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 21, 23, 24, 25, 26, 27, 28], "vertex": 1, "fulli": [1, 10, 13, 14, 16, 28], "manag": [1, 7, 11, 19, 29], "platform": 1, "more": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 26, 27, 28, 30], "introduct": [1, 7], "set": [1, 2, 11, 14, 16, 17, 18, 19, 21, 23, 26, 27, 29], "up": [1, 2, 3, 14, 15, 17, 18, 21, 24, 26], "environ": [1, 2, 10, 14, 15, 17, 20, 27, 29], "resourc": [1, 11, 16], "i": [2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29], "free": [2, 5, 12, 16, 19, 20, 23], "softwar": [2, 16], "tool": [2, 5, 17, 23], "autom": 2, "openxla": [2, 6, 13, 21, 25], "both": [2, 4, 5, 8, 14, 17, 18, 19, 21, 23, 24, 25, 26, 28, 29], "make": [2, 4, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27], "good": [2, 3, 5, 17, 18, 26, 27], "fit": [2, 3, 17, 23], "well": [2, 3, 6, 8, 11, 14, 17, 18, 26, 28], "extern": [2, 4, 7], "seen": [2, 17, 21], "workspac": [2, 16], "file": [2, 4, 11, 14, 16, 17, 19, 20], "http_archiv": 2, "name": [2, 4, 5, 8, 11, 14, 16, 18, 24, 26, 27, 28], "org_tensorflow": 2, "strip_prefix": 2, "f7759359f8420d3ca7b9fd19493f2a01bd47b4ef": 2, "url": 2, "http": [2, 3, 4, 7, 9, 11, 14, 16, 17, 23, 27], "github": [2, 3, 4, 5, 9, 11, 14, 16, 17, 20, 23, 27], "com": [2, 3, 4, 7, 9, 11, 14, 16, 17, 23, 27], "archiv": 2, "tar": 2, "gz": 2, "pin": [2, 11], "updat": [2, 3, 15, 17, 18, 19, 26, 27], "point": [2, 3, 4, 5, 6, 8, 11, 17, 18, 19, 26], "thi": [2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30], "repositori": [2, 14], "differ": [2, 6, 11, 15, 16, 17, 18, 20, 22, 23, 26, 27, 28], "revis": 2, "patch": [2, 16], "mai": [2, 3, 6, 14, 15, 16, 17, 18, 19, 26, 27], "ad": [2, 5, 11, 15, 17, 18, 21, 22, 26, 27], "resolv": 2, "prepar": 2, "hermet": 2, "mechan": 2, "deploi": 2, "becaus": [2, 3, 8, 13, 14, 15, 17, 19, 27], "local": [2, 4, 11, 14, 15, 16, 27], "checkout": [2, 16], "ha": [2, 3, 4, 5, 7, 11, 13, 14, 15, 17, 18, 26, 27, 28], "built": [2, 4], "from": [2, 3, 4, 5, 7, 8, 9, 11, 12, 16, 17, 19, 20, 21, 22, 23, 24, 27, 28, 29], "sourc": [2, 3, 5, 6, 8, 10, 11, 16], "instal": [2, 3, 4, 5, 6, 7, 8, 9, 14, 16, 17], "system": [2, 28], "version": [2, 3, 4, 7, 14, 17, 19, 27], "compat": [2, 8, 14, 25, 29], "e": [2, 4, 6, 8, 11, 12, 14, 16, 17, 18, 19, 23, 25, 26, 27], "g": [2, 4, 6, 8, 11, 12, 14, 16, 17, 18, 25, 26, 27, 29], "codegen": [2, 5, 10], "torchgen": [2, 3], "python": [2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 26, 27], "modul": [2, 7, 8, 11, 15, 16, 20, 23, 24, 27], "should": [2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 26, 27, 29], "The": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30], "directori": [2, 3, 5, 8], "either": [2, 5, 11, 14, 16, 18, 19, 26], "bzl": 2, "overriden": 2, "command": [2, 3, 4, 14, 15, 16, 17, 20, 23], "line": [2, 3, 11, 13, 15, 16, 17, 18, 23, 26], "override_repositori": 2, "path": [2, 6, 8, 11, 15, 16, 18, 23, 26], "export": [2, 3, 4, 5, 10, 14, 16, 17], "tf_repo": 2, "torch_repo": 2, "pleas": [2, 3, 5, 8, 11, 14, 15, 16, 17, 19, 23, 24, 25, 27, 30], "sure": [2, 15, 16], "overridden": [2, 3], "appropri": [2, 17], "been": [2, 5, 11, 14, 15, 17, 18, 26, 27], "use_cuda": 2, "0": [2, 3, 4, 6, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30], "setup": [2, 3, 6, 15, 20], "py": [2, 3, 4, 5, 9, 12, 13, 14, 15, 16, 17, 20, 23, 27, 30], "bdist_wheel": 2, "expect": [2, 3, 6, 9, 13, 14, 16, 18, 21, 25, 26], "object": [2, 11, 27], "present": [2, 29], "new_local_repositori": 2, "build_fil": 2, "pytorch_local_dir": 2, "header": 2, "directli": [2, 3, 5, 6, 11, 14, 15, 16, 17, 18, 19, 23, 26, 27, 29], "share": [2, 3, 6, 14, 15, 16, 27], "libtorch": 2, "so": [2, 3, 6, 9, 11, 12, 14, 15, 16, 17, 18, 23, 26, 29], "same": [2, 3, 5, 6, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 22, 25, 26, 27, 28, 30], "where": [2, 4, 7, 11, 12, 14, 15, 16, 17, 18, 23, 24, 26], "lib": [2, 6], "contain": [2, 3, 5, 6, 8, 9, 11, 14, 16, 17, 18, 26], "work": [2, 3, 11, 12, 14, 15, 16, 17, 18, 20, 21, 25, 26, 27, 28], "": [2, 4, 5, 6, 7, 8, 11, 13, 14, 15, 16, 17, 19, 20, 21, 25, 27, 28, 29], "requir": [2, 3, 5, 11, 12, 14, 15, 16, 17, 18, 19, 26, 27, 29, 30], "pass": [2, 5, 8, 9, 11, 14, 17, 19, 20, 27], "isystemextern": 2, "compil": [2, 5, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, 25, 26, 28, 29], "find": [2, 3, 5, 8, 14, 16, 17, 20, 24], "satisfi": [2, 27], "them": [2, 3, 5, 8, 11, 14, 15, 16, 17, 18, 26], "some": [2, 3, 5, 11, 12, 13, 14, 15, 16, 20, 25, 27], "user": [2, 4, 6, 8, 10, 13, 14, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 29], "bring": [2, 3, 24], "pybind11": 2, "embed": 2, "link": [2, 3], "against": [2, 20], "libpython": 2, "instead": [2, 11, 13, 14, 15, 16, 17, 18, 20, 21, 23, 26, 27, 29], "These": [2, 3, 5, 7, 14, 17, 25, 29], "pybind11_emb": 2, "option": [2, 3, 4, 6, 8, 11, 14, 16, 17, 25, 27, 29], "transit": [2, 15], "simpl": [2, 3, 7, 14, 17, 19, 23, 28], "torch_xla": [2, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "csrc": [2, 5], "runtim": [2, 3, 4, 6, 10, 15, 16, 20, 23, 27, 28, 29], "configr": 2, "via": [2, 4, 10, 14, 22, 23, 24, 27, 28], "bazelrc": 2, "take": [2, 3, 8, 9, 11, 15, 16, 17, 18, 26, 27], "flag": [2, 3, 11, 12, 19], "config": [2, 4], "remote_cach": 2, "configur": [2, 3, 5, 10, 11, 14, 16, 17, 29], "gcloud": [2, 4, 14, 15, 17], "usual": [2, 3, 5, 13, 15, 16], "faster": [2, 14, 17, 18, 21, 26], "authent": [2, 14], "easi": [2, 14, 15, 18, 26], "express": [2, 24, 28], "complex": [2, 9, 21], "lot": [2, 15, 16, 17, 18, 26], "gain": [2, 14], "have": [2, 3, 4, 5, 6, 7, 8, 11, 14, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 29], "singl": [2, 11, 13, 18, 20, 21, 23, 24, 26, 27, 28, 30], "graph": [2, 8, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27], "everyth": [2, 18, 20, 26], "therefor": [2, 16, 17], "separ": [2, 3, 5, 15, 17, 21, 23, 24], "rest": [2, 14, 16, 18, 26], "plu": [2, 20, 22], "whole": [2, 11, 13, 18, 21, 26], "everythin": 2, "els": [2, 16, 18, 26], "enough": [2, 17, 18, 26], "normal": [2, 3, 14, 18, 24, 26, 27], "achiev": [2, 5, 13, 20], "invok": [2, 3, 21, 27], "standard": [2, 8], "c": [2, 3, 5, 11, 14, 16, 18, 19, 26], "bind": [2, 8], "simpli": [2, 14], "_xlac": [2, 9, 16, 18, 26], "client": [2, 6, 11, 14], "togeth": [2, 13, 14, 15, 20, 23, 27], "when": [2, 3, 5, 9, 11, 12, 13, 14, 15, 16, 17, 19, 21, 23, 27, 28, 29], "chang": [2, 5, 12, 15, 16, 17, 18, 19, 20, 25, 26, 27], "abl": [2, 15, 18, 26, 29], "without": [2, 5, 11, 14, 16, 17, 27, 28, 29], "iter": [2, 11, 12, 15, 16, 17, 21, 27], "cycl": 2, "come": [2, 11, 18, 26], "There": [2, 3, 13, 15, 16, 17, 18, 20, 21, 26, 27], "plenti": 2, "backend": [2, 3, 11, 13, 14, 18, 21, 22, 25, 26, 27, 29], "we": [2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30], "our": [2, 3, 4, 5, 6, 7, 8, 12, 14, 15, 16, 18, 19, 20, 21, 26, 27], "gc": [2, 29], "storag": [2, 4, 7, 15, 16, 17, 23, 29], "you": [2, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 24, 27, 28, 30], "under": [2, 3, 5, 11, 14, 15, 20], "disabl": [2, 11, 13, 16, 17], "default": [2, 5, 11, 13, 14, 15, 16, 17, 19, 23, 27, 29], "speed": [2, 17, 18, 21, 26], "increment": [2, 3], "huge": [2, 16, 17, 18, 20, 26], "margin": 2, "almost": [2, 28], "alwai": [2, 14, 15, 16, 18, 26, 28], "enabl": [2, 9, 11, 12, 13, 16, 17, 19, 20, 25, 27, 28, 29], "ci": [2, 5], "To": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 23, 24, 26, 27, 29, 30], "ensur": [2, 8, 11, 18, 24, 26, 27, 29], "credenti": 2, "auth": [2, 14], "applic": [2, 16, 25, 29], "login": [2, 17], "launch": [2, 11, 14, 15, 17, 20, 21, 23], "browser": 2, "gcp": [2, 4, 14], "variou": [2, 9], "individu": [2, 23, 24, 28], "who": [2, 20], "access": [2, 3, 5, 7, 11, 14, 15, 16, 17, 18, 26, 29], "project": [2, 4, 6, 14, 15, 17], "one": [2, 3, 5, 7, 8, 11, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 30], "onli": [2, 3, 5, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 26, 28, 29], "specifi": [2, 8, 11, 15, 17, 23, 27], "google_default_credenti": 2, "token": [2, 13, 17, 25], "out": [2, 5, 8, 11, 12, 13, 14, 15, 16, 17, 19, 21, 27], "box": [2, 5, 27], "log": [2, 16, 17], "permiss": 2, "add": [2, 3, 5, 8, 9, 11, 15, 16, 17, 18, 21, 22, 23, 26], "new": [2, 3, 4, 5, 13, 15, 16, 17, 18, 21, 26, 27], "role": 2, "In": [2, 3, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 26, 27, 28, 29], "account": [2, 17], "kei": [2, 4, 6, 14, 16, 17, 29], "google_credenti": 2, "On": [2, 14, 29], "docker": [2, 8], "network": [2, 11, 14, 15, 16, 19, 27], "cloudbuild": 2, "down": [2, 5, 17], "imag": [2, 14, 17, 18, 20, 23, 26], "do": [2, 3, 5, 10, 12, 14, 15, 16, 17, 18, 19, 23, 25, 26, 27], "doe": [2, 3, 11, 12, 14, 15, 16, 17, 18, 19, 26, 27], "read": [2, 4, 5, 11, 14, 27], "write": [2, 5, 9, 11, 15, 28], "silo": 2, "each": [2, 3, 5, 9, 11, 14, 15, 16, 17, 18, 21, 23, 24, 26, 27, 28, 29], "uniqu": [2, 15, 17, 18, 26], "benefit": [2, 17, 24, 25, 29], "consist": [2, 8, 14], "remote_default_exec_properti": 2, "some_silo_kei": 2, "bazel_remote_cach": 2, "1": [2, 4, 6, 7, 8, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 30], "silo_nam": 2, "your": [2, 3, 6, 7, 8, 14, 15, 16, 17, 18, 20, 24, 26, 27, 29], "tpuvm_mod": 2, "gcloud_service_key_fil": 2, "application_default_credenti": 2, "json": [2, 8], "might": [2, 5, 11, 15, 16, 17, 18, 26], "help": [2, 16, 17, 18, 26], "too": [2, 16, 18, 26], "cannot": [2, 7, 17, 18, 19, 23, 26], "here": [2, 3, 5, 7, 8, 12, 15, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29], "author": 2, "usernam": 2, "behavior": [2, 3, 5, 14, 15, 16, 19], "function": [2, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 21, 22, 24, 25, 29], "intend": 2, "first": [2, 3, 4, 8, 9, 11, 12, 14, 16, 17, 20, 27, 28, 29, 30], "time": [2, 3, 4, 11, 12, 14, 15, 16, 17, 18, 21, 22, 26, 27], "slow": [2, 16, 17], "scratch": [2, 3], "veri": [2, 6, 7, 13, 15, 17, 18, 26], "fast": [2, 18, 26], "onc": [2, 11, 15, 16, 17, 18, 21, 26, 27], "again": [2, 3, 8, 15, 17], "bit": [2, 15, 25], "slower": [2, 16, 17, 20], "per": [2, 8, 11, 14, 15, 16, 19, 20, 21, 25], "until": [2, 11, 15, 17, 29], "next": [2, 11, 16, 17, 18, 25, 26, 27], "quit": 2, "current": [2, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 27, 30], "migrat": [2, 10, 14], "futur": [2, 3, 4, 6, 8, 12, 14, 15, 16, 17, 18, 24, 26], "plafrom": 2, "cpp": [2, 5], "main": [2, 4, 8, 9, 13, 14, 27], "Of": 2, "cours": 2, "pjrt": [2, 10, 11, 15, 27], "Not": 2, "environment": 2, "variabl": [2, 4, 12, 14, 17, 18, 26], "miss": [2, 5, 11, 16], "common": [2, 14, 18, 24, 25, 26, 28, 29], "part": [2, 3, 6, 9, 11, 13, 14, 16, 17, 27], "ones": [2, 11, 18, 26], "helper": [2, 3, 8, 11], "script": [2, 3, 4, 7, 14, 15, 16, 17, 19, 20, 30], "run_test": 2, "sh": 2, "r": [2, 17], "xla_client": 2, "pure": [2, 3], "easili": [2, 5, 18, 21, 26], "execut": [2, 9, 11, 13, 14, 15, 17, 18, 19, 20, 21, 26, 27, 28, 30], "parallel": [2, 10, 11, 14, 16, 20, 27, 28], "sinc": [2, 3, 5, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 29], "xrt": [2, 11], "port": [2, 14, 30], "gpu": [2, 5, 6, 7, 10, 12, 16, 17, 27], "tpu": [2, 3, 5, 6, 7, 10, 11, 12, 16, 20, 21, 22, 29, 30], "devic": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 25, 26, 28, 29], "avail": [2, 11, 14, 15, 16, 17, 18, 23, 26, 30], "reason": [2, 3, 5, 13, 14, 17, 20], "bundl": 2, "target": [2, 8, 13, 14, 15, 17, 18, 19, 21, 26], "sequenti": [2, 11], "calcul": 2, "visual": [2, 27], "lcov": 2, "describ": [2, 3, 4, 8, 11, 15, 17, 19, 20, 28], "document": [2, 3, 4, 5, 6, 8, 14, 15, 19, 20, 25], "editor": 2, "choic": [2, 18, 26], "gutter": 2, "vscode": 2, "power": 2, "like": [2, 3, 4, 5, 7, 11, 14, 15, 16, 17, 18, 19, 23, 26, 27], "clangd": 2, "refer": [2, 3, 5, 7, 8, 9, 12, 14, 15, 17, 23, 25, 27, 30], "autocomplet": 2, "semant": [2, 5, 16, 18, 26], "understand": [2, 17, 18, 26], "underli": [2, 11, 15], "stack": [2, 15, 16, 18, 19, 26, 27], "combin": [2, 5, 11, 18, 26], "studio": 2, "extens": [2, 4, 5, 6], "featur": [2, 7, 12, 14, 16, 20, 24, 27, 28, 29], "assist": 2, "edit": 2, "As": [2, 3, 17, 18, 24, 26], "distutil": 2, "ltc": 3, "lazi": [3, 16, 17, 18, 21, 26, 27], "tensor": [3, 5, 8, 11, 12, 14, 17, 19, 21, 22, 24, 25, 27, 28], "core": [3, 5, 8, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 28], "clean": [3, 16, 21], "exist": [3, 8, 11, 13, 14, 15, 16, 21, 27], "stub": 3, "over": [3, 11, 13, 14, 15, 17, 23, 29], "6": [3, 4, 5, 8, 11, 16, 17, 18, 26], "were": [3, 15, 16, 17, 18, 26], "complet": [3, 11, 15, 16], "process": [3, 5, 6, 9, 11, 13, 14, 16, 17, 20, 23, 25], "found": [3, 14, 17], "ref": [3, 4, 14], "replac": [3, 17, 22], "support": [3, 6, 7, 8, 9, 11, 12, 14, 18, 21, 22, 23, 26, 27, 29, 30], "NOT": 3, "introduc": [3, 7, 13, 14, 16, 17, 20, 27], "ani": [3, 7, 8, 11, 12, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30], "purpos": [3, 5, 25], "follow": [3, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 27, 30], "instruct": [3, 5, 17], "depend": [3, 4, 5, 12, 13, 15, 17, 18, 19, 26], "build": [3, 5, 15, 17, 23], "It": [3, 4, 5, 11, 12, 13, 15, 17, 18, 21, 23, 24, 25, 26, 27], "experi": [3, 5, 13, 14, 20, 29], "workstat": [3, 5], "cpu": [3, 5, 8, 11, 16, 17, 18, 23, 25, 26, 27, 29], "pjrt_devic": [3, 5, 6, 12, 14, 15, 16, 22, 30], "re": [3, 11, 13, 14, 16, 17, 18, 19, 22, 24, 26], "familiar": [3, 15, 24], "issu": [3, 5, 11, 13, 14, 15, 16, 17, 19, 20, 24], "3560": 3, "track": [3, 16, 29], "statu": [3, 16], "put": [3, 5, 15, 16, 20], "alia": [3, 11], "avoid": [3, 16, 17, 19], "duplic": 3, "mention": [3, 5, 18, 21, 26], "below": [3, 5, 8, 13, 14, 17, 18, 19, 26, 29, 30], "live": [3, 5, 11, 18, 26], "folder": [3, 4, 5], "except": [3, 5, 17, 27], "xla_native_funct": [3, 5], "yaml": [3, 5], "torch": [3, 4, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29], "shape_infer": 3, "shape": [3, 5, 7, 8, 9, 10, 11, 16, 17, 22, 27, 28], "defin": [3, 5, 7, 9, 11, 17, 19, 22, 24, 27, 28], "input": [3, 5, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 22, 24, 27, 28, 29], "return": [3, 5, 6, 7, 8, 11, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 29], "output": [3, 4, 7, 8, 9, 11, 14, 15, 16, 19, 20, 21, 22, 23, 27], "manual": [3, 5, 7, 13, 16, 23], "gen_lazy_tensor": 3, "data": [3, 8, 10, 11, 13, 14, 15, 17, 18, 19, 21, 26, 28, 29], "aten": [3, 5, 16, 18, 26], "specif": [3, 11, 15, 17, 19, 20, 25], "run_gen_lazy_tensor": 3, "dest": 3, "lazy_ir": 3, "class": [3, 6, 8, 11, 20, 23, 25, 29], "genlazyir": 3, "back": [3, 5, 8, 11, 15, 16, 17, 27], "todai": [3, 12], "most": [3, 6, 11, 14, 16, 21], "categori": [3, 24], "goal": [3, 4, 5, 13], "move": [3, 8, 11, 14, 16, 18, 20, 26, 29], "full_codegen": 3, "necessari": [3, 11, 16, 19], "call": [3, 5, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 29], "upstream": [3, 12, 21], "api": [3, 5, 10, 14, 15, 18, 20, 21, 23, 25, 26, 27, 28, 29], "xlanativefunct": [3, 5], "column": 3, "declar": [3, 5], "anoth": [3, 8, 12, 15, 16, 17, 18, 26], "wrap": [3, 5, 6, 7, 8, 11, 13, 15, 17, 19, 23, 24, 25, 27], "around": [3, 14, 18, 23, 26], "xlatensor": [3, 5, 11, 27], "construct": [3, 5, 15, 17, 23, 27, 28, 29], "aten_xla_typ": [3, 5], "Will": 3, "method": [3, 8, 11, 14, 19, 24, 27, 29], "map": [3, 5, 11], "node": [3, 5, 9, 16, 18, 26, 30], "remov": [3, 14, 16, 17], "tensor_method": [3, 5], "possibl": [3, 14, 15, 16, 17, 23, 24, 27], "multipl": [3, 8, 11, 13, 18, 21, 25, 26], "few": [3, 15, 16, 17, 18, 20, 26, 29], "simpler": [3, 14], "go": [3, 13, 15, 17, 19, 27], "unari": 3, "binari": [3, 6, 8, 21], "exampl": [3, 4, 5, 6, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 25, 26, 27, 28, 29, 30], "characterist": 3, "fallback": [3, 5], "_adaptive_avg_pool3d": 3, "condit": [3, 18, 22, 26], "issupportedadaptivepool": 3, "xlahelp": 3, "i64list": 3, "self": [3, 5, 6, 8, 11, 17, 20, 25, 27], "size": [3, 9, 12, 14, 15, 16, 17, 18, 26, 29], "output_size_list": 3, "pool_dim": 3, "nativ": [3, 5, 13, 14, 16, 19, 20, 27], "call_fallback_fn": 3, "xla_fallback": 3, "aten_op": 3, "output_s": 3, "wip": 3, "evolv": 3, "At": [3, 6, 11], "self_tensor": 3, "static": [3, 12, 18, 26], "bool": [3, 11], "sync_upd": 3, "sys_util": 3, "getenvbool": 3, "xla_tensor_update_sync": 3, "true": [3, 11, 13, 14, 17, 18, 20, 23, 26, 27, 29], "xla_check": 3, "dst_tensor": 3, "updatefromtensor": 3, "sync": [3, 11, 13, 16, 17, 19], "complic": [3, 5, 7], "an": [3, 4, 5, 6, 7, 11, 14, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29], "would": [3, 4, 5, 11, 14, 15, 16, 17, 18, 22, 26], "someth": [3, 17], "ab": [3, 23], "const": [3, 5], "torch_lazy_fn_count": 3, "bridg": [3, 21], "atenfromxlatensor": 3, "getxlatensor": 3, "fail": [3, 11, 15, 16, 29], "explain": [3, 6, 15, 16, 17, 18, 26, 28], "later": [3, 17], "still": [3, 14, 15, 18, 19, 20, 26, 29], "snippet": [3, 15, 27], "auto": [3, 5, 11, 23, 29], "common_devic": 3, "getxladevic": 3, "torch_internal_assert": 3, "xlatensorptr": 3, "lazy_self": 3, "getxlatensororcreateforwrappednumb": 3, "nodeptr": 3, "reusenod": 3, "getirvalu": 3, "makenod": 3, "cachenod": 3, "creat": [3, 8, 9, 11, 14, 16, 17, 19, 20, 27, 29], "std": [3, 20], "get": [3, 5, 11, 12, 13, 14, 17, 18, 20, 23, 25, 26], "check": [3, 4, 5, 11, 15, 25, 28], "reus": [3, 15, 17, 19], "previou": [3, 14, 15, 17, 18, 26], "creation": [3, 11], "If": [3, 4, 5, 8, 11, 14, 15, 16, 17, 18, 25, 26, 27], "correspond": [3, 5, 11, 17, 19, 23, 27, 28], "cach": [3, 7, 11, 12, 17], "newli": [3, 8], "And": [3, 18, 20, 26, 27], "within": [3, 8, 11, 15, 16, 17, 25, 29], "note": [3, 4, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 21, 23, 24, 25, 26, 28], "done": [3, 4, 7, 15, 16, 17, 18, 26], "public": [3, 14], "xlanod": 3, "xlavalu": 3, "opkind": [3, 5], "absoutputshap": 3, "num_output": [3, 18, 26], "mhash": 3, "string": [3, 11, 27], "tostr": 3, "overrid": [3, 11, 19], "stringstream": 3, "ss": 3, "str": [3, 6, 11], "xlaopvector": 3, "loweringcontext": 3, "loctx": 3, "A": [3, 4, 6, 11, 14, 15, 17, 18, 19, 24, 25, 26, 27], "coupl": [3, 15, 16], "thing": [3, 16, 17], "keep": [3, 4, 12, 14, 16, 18, 26], "mind": [3, 14, 16], "clone": [3, 14, 16, 17], "even": [3, 11, 14, 15, 16, 18, 20, 26], "everi": [3, 5, 7, 8, 11, 14, 15, 16, 18, 21, 26, 27, 29], "outputshap": 3, "xla_shap": 3, "overli": 3, "simplifi": 3, "buildxxxop": 3, "slightli": [3, 5, 11], "better": [3, 5, 13, 14, 15, 16, 17, 18, 21, 22, 26], "maximumoutputshap": 3, "lower_for_shape_fn": 3, "absl": 3, "xlaop": [3, 5], "operand": 3, "promot": 3, "max": [3, 18, 26, 29], "second": [3, 9, 12, 14, 16, 17, 20, 28, 30], "inferoutputshap": 3, "comput": [3, 4, 11, 14, 15, 16, 17, 18, 19, 26, 27, 28], "logic": [3, 11, 13, 18, 22, 26, 27, 28], "two": [3, 6, 11, 14, 16, 17, 18, 26, 27, 28], "xla_input": 3, "getoutputop": 3, "returnop": 3, "buildab": 3, "origin": [3, 8, 17], "genericop": 3, "modifi": [3, 17, 19, 21, 27], "abov": [3, 5, 6, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 28], "delet": 3, "sometim": [3, 17, 18, 26], "being": [3, 11, 15, 17, 20, 28], "tensor_op": 3, "cross": [3, 15, 27], "s1": [3, 27], "sub": 3, "mul": [3, 18, 26], "u2": 3, "v3": [3, 15, 20], "u3": 3, "v2": [3, 4, 15], "irnod": 3, "those": [3, 5, 8, 11, 16, 17, 20], "long": [3, 13, 16, 17, 18, 20, 26], "term": [3, 9, 13, 16, 18, 26], "rid": [3, 18, 26], "composit": [3, 5], "end": [3, 5, 9, 11, 12, 14, 15, 16, 17, 20, 23, 24], "exp": 3, "pow": 3, "norm_exp": 3, "vector": [3, 9], "involv": [3, 18, 26, 27], "don": [3, 5, 12, 13, 14, 15, 16, 18, 23, 26], "t": [3, 5, 8, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 26, 27, 28, 29], "build_cpp_test": 3, "skip": [3, 5, 16, 21], "desir": [3, 8, 17, 29], "test_ptxla": 3, "gtest_filt": 3, "atenxlatensortest": 3, "testab": 3, "correct": [3, 18, 26], "counter": [3, 5, 11, 16], "correctli": [3, 16, 24], "gt": [3, 4, 8, 14, 17], "erf": 3, "erfc": 3, "erfinv": 3, "pull": [3, 8, 19, 20, 23], "3659": 3, "binary_cross_entropi": [3, 19], "backward": [3, 5, 8, 13, 14, 15, 19, 20, 21, 23, 24], "3809": 3, "scalar": [3, 5, 16, 18, 26], "addcdiv": 3, "addcmul": 3, "3768": 3, "neg": 3, "index": [3, 4, 6, 11, 14, 15, 16, 17, 30], "amin": 3, "amax": 3, "3771": 3, "special": [3, 8, 9, 17, 27], "partial": [3, 18, 23, 24, 26], "adaptive_avgpool3d": 3, "3790": 3, "guid": [4, 8, 10, 14, 15, 17, 23, 24, 27], "interact": [4, 14], "start": [4, 13, 14, 15, 16, 17], "colab": [4, 16], "kaggl": 4, "preinstal": [4, 14], "ecosystem": [4, 25], "packag": [4, 9, 10, 15, 17, 19, 20], "date": 4, "list": [4, 5, 11, 17, 19, 22, 27], "readm": [4, 16, 17], "prerequisit": 4, "remot": 4, "quota": 4, "about": [4, 13, 14, 15, 17, 18, 26], "request": [4, 5, 11, 16, 17, 18, 19, 20, 26, 27], "offici": [4, 16], "ssh": [4, 14, 15, 17], "regist": [4, 5, 6, 14, 29], "agent": 4, "alreadi": [4, 7, 9, 11, 16, 17, 18, 20, 23, 26, 29], "befor": [4, 7, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 29], "begin": [4, 27], "zone": [4, 14, 15, 17], "tpu_typ": 4, "8": [4, 8, 9, 11, 13, 14, 15, 17, 18, 20, 21, 25, 26, 27, 28], "vm": [4, 14, 15, 16, 17, 20], "assum": [4, 6, 7, 11, 15, 18, 20, 24, 26, 27], "id_ed25519": 4, "ubuntu2204": 4, "base": [4, 11, 13, 14, 16, 17, 18, 23, 26, 27, 28], "metadata": [4, 16], "cat": [4, 19], "pub": 4, "ip": [4, 11, 14, 29, 30], "format": [4, 11, 16, 17, 21, 25], "valu": [4, 5, 8, 9, 11, 12, 14, 16, 17, 18, 22, 26, 27, 30], "networkendpoint": 4, "accessconfig": 4, "externalip": 4, "123": 4, "give": [4, 8, 16, 17, 25, 27, 28], "friendli": 4, "easier": [4, 13, 17, 18, 26], "echo": 4, "host": [4, 11, 14, 15, 16, 17, 19, 23, 29, 30], "n": [4, 11, 20, 25], "hostnam": 4, "test": [4, 6, 7, 8, 9, 12, 14, 20, 23, 30], "v": [4, 7, 8, 14, 18, 26], "palett": 4, "select": [4, 11, 14, 29], "visualstudio": 4, "doc": [4, 11, 13, 14, 15, 18, 24, 26, 27], "__": [4, 14], "just": [4, 7, 13, 14, 15, 18, 20, 23, 26, 29], "titl": [4, 14], "open": [4, 5, 6, 8, 14, 16], "window": 4, "termin": [4, 29], "mkdir": 4, "ptxla": 4, "Then": [4, 8, 17], "ui": 4, "venv": 4, "virtual": [4, 11], "latest": [4, 8], "releas": [4, 6, 7, 14, 15, 16, 17, 21, 23, 24, 25, 27], "pip": [4, 7, 8, 9, 17], "numpi": [4, 7, 8, 11, 17, 28], "f": [4, 7, 8, 11, 15, 20, 23, 25, 29], "googleapi": [4, 7, 17], "libtpu": [4, 6, 14], "html": [4, 7, 14, 23], "import": [4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29], "set_device_typ": 4, "print": [4, 8, 11, 12, 14, 15, 16, 17, 18, 20, 21, 26, 27, 29], "real_devic": 4, "run": [4, 5, 7, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 25, 26, 29], "2": [4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 21, 22, 23, 25, 27, 30], "3": [4, 5, 6, 7, 8, 9, 11, 13, 16, 17, 21, 22, 23, 25, 27], "4": [4, 6, 7, 8, 11, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28], "5": [4, 8, 11, 12, 16, 17, 18, 20, 23, 25, 26], "7": [4, 11, 16, 20, 21], "number": [4, 9, 11, 12, 13, 14, 16, 17, 23, 27, 28], "vari": [4, 14, 18, 24, 26], "That": [4, 18, 26], "now": [4, 8, 9, 13, 14, 15, 17, 18, 26, 27], "realist": 4, "librari": [5, 6, 17, 28, 29], "offer": [5, 8, 24, 25], "implement": [5, 7, 8, 13, 14, 16, 18, 21, 23, 24, 26], "xla": [5, 8, 9, 12, 13, 14, 18, 20, 22, 24, 29, 30], "its": [5, 8, 12, 14, 15, 16, 20, 21, 23, 27, 28], "convert": [5, 11, 15, 20], "higher": [5, 16, 29], "level": [5, 16, 17, 21, 25, 29], "represent": [5, 11, 15, 17, 28], "hlo": [5, 11, 15, 16, 17], "beyond": 5, "scope": 5, "forward": [5, 8, 13, 19, 20, 21, 24, 25], "haven": [5, 18, 26], "yet": 5, "caus": [5, 11, 13, 14, 15, 16, 17, 18, 19, 26], "signific": [5, 16, 17, 21], "slowdown": [5, 16, 20], "must": [5, 6, 11, 14, 15, 16, 24, 29, 30], "best": [5, 7, 21, 25], "perform": [5, 7, 8, 9, 11, 13, 15, 19, 20, 21, 23, 25, 27], "what": [5, 15, 17], "debug": [5, 13, 18, 25, 26], "pt": [5, 14, 15, 16, 17], "profil": [5, 14], "_ctc_loss": [5, 16], "_ctc_loss_backward": [5, 16], "contribut": 5, "definit": [5, 15, 18, 26], "native_funct": 5, "after": [5, 8, 11, 14, 15, 16, 17, 18, 22, 26, 27], "kernel": [5, 8, 10, 18, 25, 26], "aten_fallback": 5, "h": 5, "search": 5, "repo": [5, 15, 16, 17, 20], "sequenc": [5, 11], "explicitli": [5, 15, 16, 17, 18, 19, 26], "compos": 5, "match": [5, 8, 11, 15, 16], "serv": 5, "interfac": [5, 6, 15, 16, 24, 29], "machineri": 5, "registerxla": 5, "registerautogradxla": 5, "entri": [5, 6, 8], "pytorch_xla": 5, "world": [5, 7, 14, 18, 21, 26, 29], "written": [5, 17, 29], "paramet": [5, 11, 14, 15, 16, 19, 20, 24, 27, 29, 30], "result": [5, 11, 12, 14, 15, 16, 17, 20, 22, 27], "dispatch": [5, 29], "wrapper": [5, 15, 20, 23, 24], "inplac": [5, 11, 27], "ir": [5, 8, 11, 16, 17, 18, 26], "insid": [5, 8, 15, 17, 27], "stand": 5, "intermedi": [5, 14, 16, 17], "smaller": [5, 17, 18, 26], "inherit": 5, "dai": 5, "addit": [5, 6, 9, 14, 15, 16, 17, 19, 20], "unless": [5, 16, 18, 26], "want": [5, 11, 13, 14, 15, 16, 17, 18, 21, 26, 27, 30], "verifi": 5, "test_oper": 5, "test_aten_xla_tensor": 5, "yield": [5, 15, 16], "break": [5, 17, 18, 26], "grasp": 5, "capabl": 5, "how": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 26, 27, 30], "similar": [5, 14, 17, 20, 22, 25], "minim": [5, 17], "pr": [5, 16, 23], "vanilla": 5, "lerp": 5, "variant": [5, 11, 18, 19, 26], "lerp_": 5, "scalar_out": 5, "tensor_out": 5, "prototyp": [5, 8, 27], "weight": [5, 8, 11, 16, 24, 25], "lerp_out": 5, "howev": [5, 7, 8, 16, 17, 27], "namespac": [5, 16], "wrapper_scalar_lerp": 5, "No": [5, 12, 14, 18, 25, 26], "deviceguard": 5, "omit": [5, 14, 28, 30], "anonym": 5, "wrapper_scalar_lerp_": 5, "wrapper_scalar_lerp__tmp": 5, "_copy_from": 5, "m": [5, 8, 18, 23, 26], "impl": [5, 8], "torch_fn": 5, "automat": [5, 6, 10, 11, 14, 15, 16, 17, 18, 23, 26, 28, 29], "u": [5, 14, 16, 17, 18, 21, 26], "explicit": [5, 19, 23], "place": [5, 11, 17, 19, 27, 29], "ll": [5, 18, 26], "interned_str": 5, "symbol": [5, 18, 26], "submit": [5, 16, 17, 19], "team": [6, 21], "direclti": 6, "tf": [6, 16, 18, 26], "close": 6, "expos": [6, 14, 15, 17, 27], "deviceplugin": 6, "handl": [6, 13, 16, 18, 23, 24, 26, 27, 28], "short": [6, 16, 18, 26], "pjrtclient": 6, "mirror": 6, "pjrt_api": 6, "straightforward": [6, 11, 17], "detail": [6, 7, 8, 11, 12, 14, 15, 16, 17, 18, 26], "concret": [6, 18, 26], "placehold": 6, "pjrt_library_path": 6, "extra": [6, 20, 24], "multiprocess": [6, 11, 14, 15], "compon": 6, "least": [6, 17], "cpuplugin": 6, "def": [6, 7, 8, 9, 11, 13, 14, 15, 17, 20, 21, 22, 24, 25], "library_path": 6, "o": [6, 8, 14, 20], "join": [6, 11], "dirnam": 6, "__file__": 6, "pjrt_c_api_cpu_plugin": 6, "identifi": [6, 11, 29], "exmapl": 6, "pyproject": 6, "toml": 6, "torch_xla_cpu_plugin": 6, "With": [6, 7, 8, 12, 14, 18, 21, 26], "initi": [6, 8, 11, 14, 15, 17, 20, 22, 29], "experiment": [6, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 24, 27, 29], "state": [6, 11, 23], "becom": [6, 7, 8, 14, 16, 17, 18, 26], "stabl": [6, 14, 23], "rise": 7, "openai": [7, 9], "triton": [7, 10], "popular": 7, "commun": [7, 11, 14, 15, 17, 21, 28], "instanc": [7, 11, 23, 29], "order": [7, 11, 15, 16, 17, 27, 28], "pariti": 7, "continu": [7, 14, 21], "push": 7, "let": [7, 14, 15, 16, 17, 21, 28], "custom_kernel": 7, "jax_import_guard": 7, "pl": [7, 14, 15, 27], "jnp": 7, "add_vectors_kernel": 7, "x_ref": 7, "y_ref": 7, "o_ref": 7, "x": [7, 8, 9, 11, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28], "y": [7, 9, 11, 16, 17, 18, 23, 24, 25, 26, 27], "jit": [7, 9, 21], "add_vector": 7, "arrai": [7, 11, 17, 24, 28], "pallas_cal": 7, "out_shap": 7, "shapedtypestruct": 7, "dtype": [7, 8, 9, 14, 18, 19, 25, 26], "otherwis": [7, 11, 16, 17, 18, 24, 26], "program": [7, 8, 9, 11, 16, 17, 18, 21, 26, 27, 28], "hang": 7, "lock": 7, "q": [7, 8], "randn": [7, 8, 11, 13, 14, 15, 20, 21, 25, 27, 28], "128": [7, 8, 14, 23, 25, 30], "k": [7, 8, 16], "make_kernel_from_palla": 7, "pt_kernel": 7, "lambda": [7, 23], "liner": 7, "flash": [7, 9], "attent": [7, 9], "besid": 7, "op": [7, 8, 10, 11, 13, 16, 17, 18, 19, 26, 27, 28], "suppor": 7, "flash_attent": 7, "paged_attent": 7, "queri": [7, 14], "squeez": 7, "dim": [7, 11], "key_cach": 7, "value_cach": 7, "context_len": 7, "block_tabl": 7, "pages_per_compute_block": 7, "megacore_mod": 7, "none": [7, 8, 11, 16, 24, 27, 28], "vllm": 7, "util": [7, 10, 11, 15, 16, 20, 23, 24, 25, 29], "effect": [7, 11], "memori": [7, 10, 11, 12, 16, 17, 18, 23, 26], "kv": 7, "proper": [7, 28], "jax_nightly_releas": 7, "jaxlib_nightly_releas": 7, "exported_program_to_stablehlo": 8, "xla_model": [8, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 28], "xm": [8, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28], "torchvis": [8, 13, 21], "xla_devic": [8, 11, 14, 15, 16, 17, 19, 20, 21, 22, 25, 28], "resnet18": [8, 13, 21], "sampl": [8, 11, 14, 16], "tupl": [8, 11, 18, 22, 24, 26, 28], "sample_input": 8, "224": [8, 13], "stablehlo_program": 8, "callabl": [8, 11, 23], "get_stablehlo_text": 8, "get_stablehlo_bytecod": [8, 11], "sample_input_xla": 8, "output2": 8, "allclos": 8, "atol": 8, "1e": [8, 16, 21], "One": [8, 11, 12, 17, 23], "tmp": [8, 15, 16, 23], "stablehlo_dir": 8, "empti": [8, 11], "doesn": [8, 15, 16, 18, 24, 26], "load": [8, 9, 11, 14, 16, 20, 23, 25, 29], "stablehlographmodul": 8, "stablehlo_program2": 8, "output3": 8, "server": [8, 11, 14, 17], "env": [8, 11, 14, 27], "nightli": [8, 16, 17, 23, 27], "resnet_tf": 8, "p": [8, 14, 16, 18, 26], "8500": 8, "mount": [8, 15], "model_nam": 8, "accomplish": 8, "tf_saved_model_integr": 8, "save_torch_module_as_tf_saved_model": 8, "nn": [8, 11, 14, 15, 20, 21, 23, 25, 27], "trace": [8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 27], "exported_model": 8, "exportedprogram": 8, "pathlik": 8, "stablehloexportopt": 8, "alias": [8, 16, 19], "save_torch_model_as_stablehlo": 8, "torchmodel": 8, "arg": [8, 11, 15, 17, 22, 23], "constant": [8, 16, 17, 27], "ndarrai": [8, 11], "human": 8, "readabl": [8, 17], "mlir": 8, "form": [8, 14, 16, 18, 26, 30], "posit": [8, 11], "argument": [8, 9, 11, 17, 19, 21, 23], "meta": 8, "l__fn___layers_15_feed_forward_w2": 8, "l__fn___layers_13_feed_forward_w1": 8, "l__fn___layers_3_attention_wo": 8, "l__fn___layers_12_ffn_norm_weight": 8, "l__fn___layers_25_attention_wo": 8, "serial": [8, 14, 15], "stablehlofunc": 8, "stage": 8, "guarante": [8, 11], "plan": [8, 12, 14], "major": 8, "agre": [8, 17], "scaled_dot_product_attent": 8, "decompos": 8, "low": [8, 12, 16], "dure": [8, 11, 16, 17, 21, 23, 27], "lower": [8, 10, 16, 17, 18, 19, 26], "captur": [8, 11, 16, 17], "downstream": [8, 19], "ml": [8, 28], "crucial": 8, "geneart": 8, "while": [8, 11, 17, 18, 20, 26], "pattern": [8, 16, 18, 21, 26], "bunch": 8, "challeng": 8, "error": [8, 11, 15, 16], "prone": 8, "robust": 8, "outlin": [8, 25], "stablehlocompositebuild": 8, "arbitari": 8, "region": [8, 11, 13, 16, 19, 27], "non": [8, 11, 13, 18, 19, 26, 28], "hardcod": [8, 27], "store": [8, 9, 11, 16], "attribut": 8, "retriev": [8, 11, 15, 18, 21, 26, 27], "show": [8, 14, 15, 16, 20], "pratic": 8, "scaled_product_attent": 8, "mark_pattern_util": 8, "__init__": [8, 20, 25], "super": [8, 20, 21], "q_proj": 8, "linear": [8, 11, 14, 15, 19, 20, 25], "bia": 8, "fals": [8, 11, 15, 23, 27], "k_proj": 8, "v_proj": 8, "builder": 8, "b": [8, 11, 14, 17, 18, 19, 21, 26, 28], "sdpa": 8, "25": [8, 12], "other_attr": 8, "val": 8, "mark_input": 8, "attn_out": 8, "mark_output": 8, "input_arg": 8, "10": [8, 11, 14, 15, 16, 17, 18, 20, 21, 22, 25, 26, 29], "stablehlo_gm": 8, "shown": [8, 14, 18, 26], "irtohlo": 8, "56": 8, "mhlo": 8, "cross_program_prefetch": 8, "input_output_alia": 8, "is_dynam": 8, "use_auto_spmd_partit": 8, "func": 8, "arg0": 8, "10x8x128xf32": 8, "arg1": 8, "128x128xf32": 8, "arg2": 8, "arg3": 8, "9": [8, 17, 18, 20, 23, 26], "composite_attribut": 8, "500000e": 8, "01": [8, 9], "f32": 8, "decomposit": 8, "11": [8, 16, 18, 26], "privat": [8, 14], "actual": [8, 13, 17, 18, 20, 26, 27], "encapsul": 8, "propag": [8, 16], "high": [9, 12, 17, 20, 25], "deep": [9, 10, 16], "learn": [9, 14], "languag": 9, "empow": 9, "full": [9, 11, 15, 16, 23], "potenti": [9, 11, 14, 16, 24], "oper": [9, 10, 11, 14, 15, 16, 17, 29], "given": [9, 11, 16, 17, 18, 20, 23, 26, 28], "add_kernel": 9, "x_ptr": 9, "pointer": 9, "y_ptr": 9, "output_ptr": 9, "n_element": 9, "block_siz": 9, "tl": 9, "constexpr": 9, "element": [9, 11, 18, 24, 26, 27], "blob": [9, 11, 14, 27], "tutori": [9, 16, 17, 20, 27], "l28": 9, "pid": 9, "program_id": 9, "axi": [9, 11, 24], "block_start": 9, "offset": 9, "arang": 9, "mask": [9, 16, 18, 26], "xla_triton": 9, "16": [9, 15, 17, 23, 25, 28], "int64": 9, "empty_lik": 9, "grid": 9, "cdiv": 9, "triton_cal": 9, "itself": [9, 11, 23], "kwarg": [9, 11, 23, 27], "payload": [9, 11, 14], "regard": [9, 15, 21], "buffer": [9, 11], "_xla_gpu_custom_cal": 9, "dep": 9, "connect": [10, 11, 14, 27], "overview": [10, 28], "eager": [10, 11, 18, 20, 25, 26], "mode": [10, 11, 18, 20, 25, 26, 27, 29], "troubleshoot": 10, "palla": 10, "stablehlo": [10, 11], "mix": [10, 11, 28], "precis": 10, "spmd": [10, 15, 17, 29], "advanc": [10, 28], "topic": [10, 28], "distribut": [10, 15, 16, 20, 23, 24, 27, 28], "checkpoint": [10, 14, 17, 23, 28], "distributeddataparallel": [10, 14], "ddp": [10, 14], "torchdynamo": 10, "while_loop": 10, "shard": [10, 11, 28, 29], "quantiz": 10, "recompil": [10, 12, 13, 15, 16, 17], "hardwar": [10, 11, 16, 17, 19], "plugin": [10, 14], "bazel": 10, "int": [11, 14, 18, 26, 27], "device_count": [11, 27], "address": [11, 14, 27, 30], "wait": [11, 16, 17], "pend": [11, 13], "whether": [11, 15, 19], "block": [11, 17, 23, 27], "finish": [11, 17], "full_graph": 11, "num_different_graphs_allow": 11, "lazytensor": [11, 13, 17], "repres": [11, 14, 18, 26], "happen": [11, 13, 14, 15, 16, 17, 18, 26], "decid": [11, 16, 18, 26], "funciton": 11, "act": [11, 15], "context": [11, 14, 16, 18, 19, 26], "throw": [11, 15], "info": [11, 16, 18, 26, 28], "exit": [11, 16, 19, 20], "pt_xla_debug": 11, "messag": [11, 16], "dump": [11, 16], "allow": [11, 15, 16, 17, 19, 27, 28, 29], "rais": [11, 16], "limit": [11, 14, 15], "exceed": 11, "usag": [11, 16, 17, 18, 23, 24, 26, 29], "foo": 11, "sin": 11, "co": 11, "foo2": 11, "compiled_foo2": 11, "manual_se": [11, 14], "seed": 11, "random": [11, 13, 14, 17, 25], "integ": [11, 16], "rng": [11, 14], "device_typ": 11, "local_process_count": 11, "local_device_count": 11, "total": [11, 18, 26, 28], "addressable_device_count": 11, "visibl": [11, 18, 26], "global_device_count": 11, "across": [11, 14, 15, 16, 23, 28], "global_runtime_device_count": [11, 24, 27, 28], "especi": [11, 14, 17, 21, 27], "world_siz": [11, 14, 19, 20, 23, 27], "particip": [11, 14], "job": [11, 17, 21], "global_ordin": [11, 14, 15, 20, 23], "global": [11, 14, 15, 27, 29], "ordin": [11, 15], "thread": [11, 14, 15, 16, 29], "predict": 11, "relationship": [11, 15, 16], "worker": [11, 14, 15, 17, 23, 29], "id": [11, 14, 16, 17], "nor": 11, "contigu": [11, 15, 16], "local_ordin": 11, "get_master_ip": 11, "master": [11, 14, 15, 29], "discoveri": 11, "use_spmd": [11, 27, 28, 29], "forc": [11, 14, 16, 18, 22, 26], "mean": [11, 14, 15, 16, 17, 18, 20, 24, 26, 27], "replic": [11, 27, 28], "spmd_advanc": 11, "md": [11, 14], "is_spmd": 11, "initialize_cach": [11, 15], "readonli": [11, 15], "persist": [11, 15, 29], "devkind": 11, "cuda": [11, 14, 15, 17, 18, 19, 25, 26, 30], "deprec": 11, "xla_device_hw": 11, "union": 11, "real": [11, 21], "is_master_ordin": 11, "multi": [11, 12, 27, 30], "num_host": 11, "boolean": 11, "indic": [11, 16, 17, 18, 26], "all_reduc": [11, 19], "reduce_typ": 11, "float": [11, 18, 19, 26], "group": [11, 14, 20, 27], "pin_layout": 11, "reduc": [11, 12, 13, 14, 15, 16, 17, 23], "reduce_sum": 11, "reduce_mul": 11, "reduce_and": 11, "reduce_or": 11, "reduce_min": 11, "reduce_max": 11, "appli": [11, 19, 23, 24, 29], "replica": [11, 14], "layout": [11, 25], "pine": 11, "prevent": [11, 17, 19, 21, 27], "corrupt": 11, "unpin": 11, "hlomodul": 11, "constrain": [11, 14], "hold": [11, 27, 28], "all_gath": [11, 14], "gather": [11, 27], "along": [11, 23], "dimens": [11, 12, 27, 28], "all_to_al": 11, "split_dimens": 11, "concat_dimens": 11, "split_count": 11, "alltoal": 11, "www": 11, "org": [11, 14, 23], "operation_semant": 11, "upon": 11, "split": 11, "concat": 11, "count": [11, 16], "add_step_closur": 11, "closur": 11, "run_async": 11, "step": [11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 29], "mani": [11, 14, 16, 17, 18, 26, 30], "report": 11, "consol": 11, "post": [11, 16], "tensorboard": [11, 17], "etc": [11, 13, 16, 18, 26, 27], "intermediari": 11, "inspect": 11, "typic": 11, "barrier": [11, 14, 15, 17], "materi": [11, 16, 17, 18, 26, 27], "queu": 11, "though": [11, 15, 20], "advis": 11, "throttl": 11, "event": 11, "asynchron": [11, 27, 29], "wait_device_op": 11, "async": [11, 21], "whose": [11, 12], "optimizer_step": [11, 15, 17, 19, 20, 23], "optimizer_arg": 11, "dict": [11, 23], "gradid": 11, "parallelload": [11, 27], "dataparallel": 11, "loader": [11, 16, 17, 21], "dictionari": 11, "gradient": [11, 15, 19, 23, 29], "save": [11, 16, 23, 29], "file_or_path": 11, "textio": 11, "master_onli": [11, 23], "global_mast": 11, "transfer": [11, 14, 16, 17, 27], "care": [11, 15, 16, 18, 26], "taken": [11, 15, 16, 18, 20, 26, 29], "view": [11, 15, 16], "recreat": [11, 15], "destin": [11, 15], "nest": [11, 23], "locat": 11, "control": [11, 12, 15, 16, 27], "obj_to_sav": 11, "path_to_sav": 11, "rendezv": 11, "tag": [11, 14], "byte": 11, "mesh": [11, 14, 24], "reach": 11, "xla_rendezv": 11, "sent": [11, 16], "exchang": 11, "mesh_reduc": 11, "reduce_fn": 11, "toxlatensorarena": 11, "reduct": 11, "receiv": 11, "copi": [11, 14, 15, 16, 17], "np": [11, 24, 28], "accuraci": [11, 20, 23], "test_accuraci": 11, "set_rng_stat": 11, "get_rng_stat": 11, "get_memory_info": 11, "memoryinfo": 11, "bytes_us": 11, "290816": 11, "bytes_limit": 11, "34088157184": 11, "get_stablehlo": 11, "var": [11, 27], "xla_hlo_debug": [11, 16], "root": [11, 18, 26], "bytecod": [11, 21], "parallel_load": [11, 14, 15, 16], "mpdeviceload": [11, 15, 17, 27], "dataload": [11, 15, 17, 20, 27, 29], "background": [11, 29], "upload": [11, 17, 27], "per_device_load": [11, 27], "constructor": 11, "train_device_load": 11, "train_load": [11, 15, 27], "xla_multiprocess": 11, "spawn": [11, 14, 15, 17], "fn": 11, "nproc": [11, 14], "daemon": 11, "start_method": 11, "moment": 11, "maximum": [11, 12, 17, 25], "valueerror": 11, "mark_shard": [11, 24, 27, 28], "xlashardedtensor": [11, 29], "partition_spec": [11, 27, 28], "annot": [11, 27, 28], "partit": [11, 27], "spec": [11, 27], "intern": [11, 14, 15, 16, 18, 26, 27, 30], "spmdpartition": [11, 27], "topologi": [11, 15, 27, 28], "device_mesh": [11, 27], "rank": [11, 14, 20, 23, 28, 29], "mesh_shap": [11, 24, 27, 28], "ax": [11, 27, 28], "impact": [11, 14, 16, 18, 20, 26], "dynamo_custom_op": 11, "dynamo": [11, 17, 21, 25], "recogniz": 11, "traceabl": 11, "xr": [11, 14, 15, 19, 20, 23, 24, 27, 28, 29], "num_devic": [11, 24, 27, 28], "device_id": [11, 24, 27, 28], "32": [11, 16, 17], "clear_shard": 11, "clear": 11, "cast": [11, 19], "t1": [11, 15, 16, 28], "get_1d_mesh": 11, "set_global_mesh": 11, "get_global_mesh": 11, "axis_nam": [11, 27], "v4": [11, 13, 14, 15, 17, 21, 27], "ravel": 11, "reshap": 11, "fill": 11, "assign": [11, 15, 17], "Its": 11, "length": [11, 18, 26], "len": [11, 17], "get_xla_supported_devic": 11, "get_logical_mesh": 11, "ordereddict": [11, 27, 28], "hybridmesh": [11, 27], "ici_mesh_shap": [11, 27], "dcn_mesh_shap": [11, 27], "hybrid": 11, "ici": 11, "dcn": [11, 27], "increas": 11, "intens": 11, "mdl": 11, "inner": [11, 23, 27], "outer": [11, 23, 24, 27], "slice": [11, 17, 27], "fsdp": [11, 23, 24, 27, 28], "eager_mod": [11, 13], "wa": [11, 14, 16, 17, 18, 26, 29], "d": [11, 12, 18, 19, 26], "eagerli": [11, 13, 15, 16, 18, 26], "metric": [11, 20], "metrics_report": [11, 16], "short_metrics_report": [11, 16], "counter_nam": 11, "metric_nam": 11, "activ": [11, 15, 16, 20, 23, 24, 25], "counter_valu": 11, "metric_data": 11, "total_sampl": 11, "accumul": 11, "retain": 11, "circular": 11, "sum": [11, 19, 23, 24], "natur": 12, "in_tensor": 12, "randint": [12, 25], "out_tensor": 12, "nonzero": [12, 16, 17, 18, 26], "word": [12, 18, 26], "further": [12, 17, 20], "categor": 12, "unbound": 12, "alloc": 12, "infinit": [12, 24], "phase": 12, "layer": [12, 13, 23, 24, 27], "perceptron": 12, "mlp": 12, "xla_experiment": 12, "masked_select": 12, "masked_scatt": 12, "your_script": [12, 17], "100": [12, 16, 23], "29": [12, 20, 21], "49": [12, 21], "20": [12, 15, 16, 20, 25], "03": 12, "102": 12, "hit": [12, 18, 26], "198": 12, "1953": 12, "motiv": 12, "excess": 12, "between": [12, 14, 15, 16, 17, 18, 19, 20, 22, 26, 27], "figur": [12, 28], "half": 12, "drop": [12, 16], "try": [12, 16, 17, 18, 26], "python3": [12, 14, 15, 16, 17, 23], "test_dynamic_shape_model": 12, "testdynamicshapemodel": 12, "test_backward_pass_with_dynamic_input": 12, "expand": [12, 21], "feel": [12, 16, 20], "review": [12, 24], "rfc": [12, 27, 30], "align": 13, "64": [13, 21, 23], "mark_step": [13, 14, 15, 16, 17, 20], "drawback": 13, "approach": [13, 18, 20, 23, 26], "often": [13, 16, 18, 26], "confus": 13, "preprocess": [13, 25], "small": [13, 16, 17, 18, 20, 21, 26], "leak": 13, "expens": [13, 16, 18, 26], "hard": [13, 18, 20, 21, 26], "why": [13, 18, 26], "mitig": 13, "ux": 13, "mark": [13, 15], "compiled_model": 13, "right": [13, 18, 21, 26], "awai": 13, "pretti": [13, 15, 18, 20, 26], "straight": 13, "enter": 13, "reenabl": 13, "perfomr": 13, "compar": [13, 14, 15, 16, 20, 21, 22], "recommen": 13, "overhad": 13, "step_fn": 13, "loss_fn": [13, 14, 15, 19, 20, 21], "zero_grad": [13, 14, 15, 19, 20], "logit": [13, 24], "loss": [13, 14, 15, 19, 21, 23, 24], "ask": [13, 16, 18, 26], "refactor": 13, "decod": 13, "much": [13, 14, 15, 17, 18, 21, 26], "llama2": 13, "fake": [13, 29], "chip": [13, 14], "300": [13, 16], "observ": [13, 14, 20], "147": 13, "65": [13, 16], "45": 13, "train_decoder_only_bas": [13, 16], "perfomran": 13, "tri": [13, 17], "resnet50": [13, 14, 15, 21, 23], "exepct": 13, "loop": [13, 15, 16, 17, 18, 24, 26, 29], "meant": 13, "encount": [14, 16, 17], "bug": [14, 16, 20], "r2": [14, 16, 27], "init": [14, 15, 20, 21, 22], "renam": 14, "xla_backend": [14, 20, 29], "torchrun": [14, 15, 30], "init_method": [14, 29], "xpu": 14, "neuron": 14, "xrt_tpu_config": 14, "30": [14, 23], "thousand": 14, "preview": 14, "safe": 14, "section": [14, 15, 16, 17, 27], "broadcast": 14, "broadcast_master_param": 14, "pjrt_backend": 14, "diff": [14, 17], "dist": [14, 20, 29], "_mp_fn": [14, 15], "init_process_group": [14, 20, 29], "42": 14, "gradient_as_bucket_view": [14, 20], "mseloss": [14, 20], "sgd": [14, 15, 19, 20, 21], "lr": [14, 15, 20, 21, 23, 24], "001": [14, 20], "confirm": 14, "__name__": [14, 15, 20], "__main__": [14, 15, 20], "localservic": 14, "localhost": [14, 20], "51011": 14, "master_addr": [14, 20], "master_port": [14, 20], "12355": [14, 20, 30], "Or": [14, 15, 18, 26], "overhead": [14, 20, 21], "grpc": 14, "torchbench": 14, "35": [14, 16], "tpuvm": [14, 15, 17, 27], "2048": 14, "mnist": [14, 15, 16, 19], "test_train_mp_mnist": [14, 20], "fake_data": [14, 16, 20, 30], "alpha": [14, 15], "central2": [14, 17], "git": [14, 16, 17, 23], "depth": [14, 16], "branch": [14, 16, 18, 26], "test_train_mp_imagenet": [14, 16, 20], "batch_siz": [14, 23, 30], "256": 14, "num_epoch": [14, 20, 23], "By": [14, 18, 26], "tpu_process_bound": 14, "tpu_visible_chip": 14, "r1": 14, "13": [14, 15, 20, 22], "docker_imag": 14, "gcr": 14, "io": [14, 23], "sudo": [14, 17], "rm": 14, "privileg": 14, "net": [14, 17, 19], "gpu_num_devic": 14, "nnode": [14, 30], "num_gpu_devic": 14, "pjrt_distribut": 14, "physic": [14, 27, 28], "12": [14, 16, 21, 23], "number_gpu_vm": [14, 30], "node_rank": [14, 30], "current_node_rank": 14, "nproc_per_nod": [14, 30], "number_local_gpu_devic": 14, "rdzv_endpoint": [14, 30], "internal_ip_address": 14, "multinode_train": 14, "endpoint": [14, 30], "machine_0": 14, "machine_1": 14, "machine_0_internal_ip_address": [14, 30], "ident": 14, "page": 14, "although": [14, 18, 26], "mostli": [14, 23], "interchang": 14, "perspect": [14, 15], "subtl": 14, "importantli": 14, "architectur": [14, 23], "thu": [14, 16], "batch": [14, 15, 16, 17, 27], "latenc": 14, "deseri": 14, "send": [14, 15, 17, 27], "direct": [14, 16], "independ": [14, 15, 16], "constraint": [14, 16], "significantli": [14, 15, 17], "xla_dist": 14, "scp": [14, 15], "sdk": 14, "reimplement": 14, "collect": [14, 20, 21, 28, 29], "enhanc": 14, "stabil": [14, 16, 19], "xmp": [14, 15, 17], "substanti": 14, "practic": [14, 18, 24, 26], "unreli": 14, "due": [14, 16, 17, 30], "inbound": 14, "could": [14, 17, 18, 26, 27], "failur": 14, "entir": [14, 23], "restart": 14, "impos": 14, "middl": [14, 17, 18, 26], "unwant": 14, "permit": 14, "subset": 14, "old": 14, "alter": 14, "synchron": [14, 15, 17, 27, 29], "consid": [14, 17], "all_gather_object": 14, "gloo": [14, 20, 29], "subgroup": 14, "monitor": 14, "_": [14, 21, 22], "altern": [14, 18, 19, 25, 26], "less": [14, 18, 21, 26], "reliabl": 14, "than": [14, 16, 18, 20, 23, 26], "strongli": 14, "_all_gath": 14, "int32": 14, "zeros_lik": 14, "get_world_s": 14, "averag": 14, "task": 14, "175": 14, "chart": 14, "breakdown": 14, "tfrt": 14, "legaci": 14, "streamexecutor": 14, "tpu_legaci": 14, "comparison": [14, 28], "regular": [15, 16, 17, 25], "t0": 15, "matrix": 15, "multipli": [15, 28], "mm": [15, 19], "neural": 15, "l_in": 15, "l_out": 15, "floattensor": 15, "highlight": [15, 17], "nllloss": 15, "momentum": 15, "switch": [15, 16, 18, 20, 26], "acquir": 15, "mp_device_load": 15, "three": 15, "multithread": [15, 16], "own": [15, 23], "onto": 15, "preload": [15, 17], "overlap": [15, 17, 21, 27], "batches_per_execut": 15, "consolid": [15, 23], "all_reduce_gradi": 15, "remain": [15, 17, 18, 26, 30], "parent": 15, "talk": 15, "basi": 15, "howto": 15, "focu": [15, 18, 26], "train_mnist_xla": 15, "outsid": 15, "infrastructur": 15, "awar": 15, "fakedata": 15, "But": [15, 16, 18, 26], "immedi": [15, 27], "hand": 15, "record": [15, 16, 17], "defer": 15, "fuse": [15, 17], "invis": 15, "caller": 15, "insert": [15, 17], "paper": 15, "opaqu": [15, 16], "appear": [15, 16, 17], "unlik": [15, 17], "adjust": 15, "preserv": [15, 16], "appreci": 15, "accommod": 15, "previous": 15, "state_dict": [15, 23, 29], "footprint": 15, "xser": 15, "stream": 15, "amount": [15, 16, 17, 18, 26], "restor": 15, "load_state_dict": [15, 29], "unavail": [15, 16], "consum": [15, 18, 26], "disk": 15, "occur": 15, "opt": 15, "your_cache_path": 15, "mp_fn": 15, "xla_cache_": 15, "runnabl": [15, 20, 24], "subject": 16, "peculiar": 16, "detial": 16, "__version__": 16, "cu121": 16, "t2": [16, 28], "200": 16, "rx": 16, "conclud": 16, "diagnos": 16, "extrem": 16, "pt_xla_debug_level": 16, "slip": 16, "analyz": [16, 17], "summari": 16, "compiletim": 16, "frequent": 16, "21": 16, "transferfromdevicetim": 16, "23": 16, "hash": 16, "c74c3b91b855b2b123f833b0d5f86943": 16, "107": 16, "frame": 16, "trigger": [16, 17, 18, 26], "dk3": 16, "1055": 16, "44": 16, "__next__": 16, "train_loop_fn": 16, "48": [16, 20], "start_train": 16, "73": 16, "548000": 16, "gb": 16, "922460": 16, "547871": 16, "124478": 16, "028210": 16, "steptrac": 16, "frequenc": 16, "pair": 16, "met": 16, "spent": [16, 17], "destroi": 16, "percentil": 16, "totalsampl": 16, "202": 16, "06m09s401ms746": 16, "001u": 16, "valuer": 16, "778ms572": 16, "062u": 16, "rate": [16, 20], "425201": 16, "001ms32": 16, "778u": 16, "001ms61": 16, "283u": 16, "001ms79": 16, "236u": 16, "001ms110": 16, "973u": 16, "50": [16, 17, 22], "001ms228": 16, "773u": 16, "80": 16, "001ms339": 16, "183u": 16, "90": 16, "001ms434": 16, "305u": 16, "95": 16, "002ms921": 16, "063u": 16, "99": [16, 20], "21s102ms853": 16, "173u": 16, "cachedsynctensor": 16, "395": [16, 20], "area": 16, "rout": 16, "qualifi": 16, "33": [16, 20, 21], "_local_scalar_dens": 16, "epoch": [16, 17, 23], "clear_al": 16, "xla_dynamo_debug": 16, "bottleneck": [16, 17], "notebook": 16, "train_resnet_benchmark": 16, "behav": 16, "evalu": [16, 17, 18, 26], "suggest": 16, "certain": [16, 18, 19, 26], "bad": 16, "degrad": [16, 17], "speedup": [16, 21], "indirect": 16, "solut": [16, 18, 25, 26], "variat": 16, "pad": [16, 17, 18, 26], "fix": [16, 17, 21, 24], "translat": 16, "item": [16, 17], "substitut": 16, "flow": 16, "clip_grad_norm": 16, "problemat": 16, "clip_grad_norm_": 16, "dramat": 16, "total_norm": 16, "zero": [16, 23, 29], "param_norm": 16, "grad": 16, "norm": 16, "norm_typ": 16, "add_": 16, "clip_coef": 16, "max_norm": 16, "mul_": 16, "data_parallel": 16, "last": 16, "dataset": [16, 20, 23], "stride": 16, "reconstruct": 16, "shallow": 16, "ty": 16, "made": [16, 17, 18, 26, 27], "_get_xla_tensors_text": [16, 18, 26], "_get_xla_tensors_hlo": 16, "prior": [16, 29], "degre": 16, "xla_ir_debug": 16, "henc": [16, 21], "respons": [16, 17, 21, 29], "xla_save_tensors_fil": 16, "realli": [16, 18, 21, 26], "big": [16, 18, 26], "left": 16, "append": 16, "sheet": 16, "xla_save_tensors_fmt": 16, "text": 16, "dot": 16, "graphviz": 16, "xla_flag": 16, "xla_dump_to": 16, "dir_nam": 16, "unoptim": 16, "optimz": 16, "xla_metrics_fil": 16, "xla_save_hlo_fil": 16, "offend": 16, "xla_sync_wait": 16, "xla_use_eager_debug_mod": 16, "bypass": 16, "overal": [16, 17], "optimizaiton": 16, "tf_cpp_log_thread_id": 16, "tf_cpp_vmodul": 16, "vlog": 16, "tf_cpp_min_log_level": 16, "turn": 16, "warn": 16, "tf_vlog": 16, "xla_dump_hlo_graph": 16, "xla_util": 16, "cc": 16, "save1": 16, "xla_graph_executor": 16, "pjrt_computation_cli": 16, "dir": 16, "pytorch_test_with_slow": 16, "test_torch": 16, "test_put_xla_uint8": 16, "torch_test_devic": 16, "pytorch_test_bas": 16, "brief": 17, "basic": [17, 18, 20, 26], "reader": 17, "modif": 17, "fetch": 17, "discuss": [17, 28], "opcod": 17, "fed": 17, "four": 17, "attach": [17, 27], "callback": 17, "xla_tensor_z": 17, "cut": [17, 18, 26], "transferfromdevic": 17, "tell": [17, 18, 26], "properti": [17, 18, 26], "illustr": [17, 28], "suppos": 17, "tensors_on_devic": 17, "z": [17, 18, 26], "subgraph": [17, 18, 26], "signal": 17, "far": 17, "suitabl": 17, "trade": [17, 18, 26], "off": 17, "spend": 17, "fusion": 17, "worth": [17, 18, 26], "latter": [17, 23], "wheel": [17, 23], "runtime_vers": 17, "project_id": 17, "accelerator_typ": 17, "tpu_nam": 17, "your_tpu_nam": 17, "subnetwork": 17, "tpusubnet": 17, "pip3": 17, "cp38": 17, "linux_x86_64": 17, "whl": 17, "apt": 17, "libopenbla": 17, "dev": [17, 20], "libgl1": 17, "guidelin": 17, "progress": 17, "bar": 17, "rememb": 17, "txt2img": 17, "prompt": 17, "photograph": 17, "astronaut": 17, "ride": 17, "hors": 17, "relat": 17, "precision_scop": 17, "addition": [17, 19, 23], "particular": 17, "frozenclipembedd": 17, "simplic": [17, 18, 26], "ddim": 17, "top": 17, "attr": 17, "statement": [17, 18, 26], "stop": 17, "fall": [17, 24], "difficult": 17, "readi": 17, "investig": [17, 20], "cover": [17, 27], "huggingfac": 17, "sd": 17, "xl": 17, "cd": [17, 23], "text_to_imag": 17, "inference_tpu_single_devic": 17, "lora": 17, "model_id": 17, "stabilityai": 17, "pipelin": 17, "dpmsolvermultistepschedul": 17, "txt": 17, "invisible_watermark": 17, "transform": [17, 23, 28], "safetensor": 17, "licens": 17, "card": 17, "cli": 17, "_your_copied_token__": 17, "pipe": 17, "hour": 17, "wherea": 17, "likewis": 17, "gpt": 17, "15": 17, "min": 17, "subsequ": 17, "advantag": 17, "mayb": 17, "notic": 17, "piec": 17, "__call__": 17, "commit": 17, "caveat": 17, "rule": [17, 19], "thumb": 17, "durat": [17, 29], "constantli": 17, "idl": 17, "inference_tpu_": 17, "capture_profil": 17, "gap": 17, "xp": 17, "measur": 17, "portion": 17, "busi": 17, "scroll": 17, "occupi": 17, "demonstr": [17, 19, 24, 29], "displai": 17, "largest": 17, "zoom": 17, "timelin": 17, "period": 17, "examin": 17, "did": 17, "pipe_watermark": 17, "closer": 17, "preced": 17, "proceed": [17, 24], "watermark": 17, "cv2": 17, "pywt": 17, "leav": 17, "broken": 17, "rewrit": [17, 18, 26, 27], "rerun": 17, "scale_model_input": 17, "ran": 17, "my_funct": 17, "preocess": 17, "debug_single_process": 17, "magic": [17, 18, 26], "treat": 17, "xla_no_special_scalar": 17, "hurt": [18, 26], "perf": [18, 26], "pov": [18, 26], "sai": [18, 26], "assur": [18, 26], "gone": [18, 26], "coverag": [18, 26], "aim": [18, 24, 26], "explan": [18, 26], "mainli": [18, 26], "problem": [18, 26], "beginn": [18, 26], "propos": [18, 26], "reli": [18, 26], "impract": [18, 26], "assumpt": [18, 26], "ye": [18, 25, 26], "sentenc": [18, 26], "bucket": [18, 26, 29], "kinda": [18, 26], "anti": [18, 26], "frontend": [18, 26], "matter": [18, 26], "workaround": [18, 26], "okai": [18, 26], "teach": [18, 26], "produc": [18, 19, 20, 26], "theoret": [18, 26], "sort": [18, 26], "obviou": [18, 26], "s64": [18, 26], "inde": [18, 26], "_get_xla_tensor_dimension_s": [18, 26], "commonli": [18, 26], "wrong": [18, 26], "wors": [18, 26], "probabl": [18, 26], "know": [18, 20, 26], "upper": [18, 26], "nit": [18, 26], "rand": [18, 26], "solv": [18, 26], "kept": [18, 26], "earli": [18, 26], "accessor": [18, 26], "2d": [18, 24, 26], "implicitli": [18, 26], "doubl": [18, 26], "overload": [18, 26], "explod": [18, 26], "convers": [18, 26], "cheap": [18, 26], "ve": [18, 26], "hoc": [18, 26], "think": [18, 26], "verison": [18, 26], "bla": [18, 26], "blabla": [18, 26], "interpret": [18, 26], "proce": [18, 26], "adopt": [18, 26], "uglier": [18, 26], "win": [18, 26], "pars": [18, 26], "torchscript": [18, 26], "somehow": [18, 26], "merg": [18, 26], "lazili": [18, 26, 27, 29], "properli": [18, 26], "thought": [18, 26], "trivial": [18, 26], "effort": [18, 26, 27], "side": [18, 26], "bandwidth": [18, 26], "automag": [18, 26], "gold": [18, 26], "smart": [18, 26], "trick": [18, 26], "tbh": [18, 26], "longer": [18, 26], "unawar": [18, 26], "hope": [18, 26], "smash": [18, 26], "blocker": [18, 26], "ahead": [18, 26], "nnc": [18, 26], "exactli": [18, 26], "transpos": [18, 26], "brian": [18, 26], "hirsh": [18, 26], "bdhirsh": [18, 26], "question": [18, 26], "comment": [18, 26], "stick": [18, 26], "torch_warn": [18, 26], "yea": [18, 26], "hei": [18, 26], "won": [18, 19, 26], "blaze": [18, 26], "isn": [18, 26, 29], "abil": [18, 20, 26], "devirtu": [18, 26], "sound": [18, 26], "great": [18, 26], "carri": [18, 26, 27], "truth": [18, 26], "irvalu": [18, 26], "enforc": [18, 20, 26], "discrep": [18, 26], "followup": [18, 26], "1000": [18, 26], "my": [18, 26, 29], "presenc": [18, 26], "get_dimention_s": [18, 26], "didn": [18, 26], "exponenti": [18, 26], "blowup": [18, 26], "fewer": [18, 26], "opportun": [18, 26], "recogn": [18, 21, 26], "feasibl": [18, 26], "annoi": [18, 26], "wasn": [18, 26], "materiz": [18, 26], "combo": [18, 26], "extend": 19, "float32": 19, "datatyp": 19, "float16": 19, "bfloat16": [19, 25], "syncfre": 19, "autocast": 19, "summar": 19, "elig": 19, "suppli": 19, "addmm": 19, "addmm_": 19, "prefer": 19, "float64": 19, "respect": 19, "unlist": 19, "__matmul__": 19, "addbmm": 19, "addmv": 19, "addr": 19, "baddbmm": 19, "bmm": 19, "conv1d": 19, "conv2d": [19, 23], "conv3d": 19, "conv_transpose1d": 19, "conv_transpose2d": 19, "conv_transpose3d": 19, "matmul": 19, "relu": [19, 20], "prelu": 19, "max_pool2d": 19, "batch_norm": 19, "log_softmax": 19, "binary_cross_entropy_with_logit": 19, "prod": 19, "cdist": 19, "chloeski": 19, "invers": 19, "reflection_pad": 19, "replication_pad": 19, "mse_loss": 19, "cosine_embbeding_loss": 19, "nll_loss": 19, "multilabel_margin_loss": 19, "qr": 19, "svd": 19, "triangular_solv": 19, "linalg_svd": 19, "linalg_inv_ex": 19, "widest": 19, "index_copi": 19, "scaler": [19, 25], "gradscal": 19, "_fetch_gradi": 19, "xla_use_f16": 19, "underflow": 19, "imagenet": 19, "minimum": [20, 23, 24], "nccl": 20, "new_rank": 20, "ddp_model": 20, "final": [20, 27], "launcher": 20, "demo_fn": 20, "touch": [20, 29], "five": 20, "sy": 20, "tempfil": 20, "cleanup": 20, "destroy_process_group": 20, "toymodel": 20, "net1": 20, "1000000": 20, "net2": 20, "demo_bas": 20, "assert": 20, "graident_as_bucket_view": 20, "label": 20, "run_demo": 20, "tot": 20, "statist": 20, "unit": 20, "median": 20, "90th": 20, "deviat": 20, "cv": 20, "418": 20, "54": 20, "419": 20, "22": 20, "430": 20, "40": 20, "76": 20, "02": 20, "97": 20, "407": 20, "60": 20, "39": 20, "seem": 20, "17864": 20, "19": [20, 21], "20108": 20, "96": 20, "24351": 20, "74": 20, "5866": 20, "83": 20, "10701": 20, "11770": 20, "00": 20, "14313": 20, "78": 20, "3102": 20, "92": 20, "41": [20, 21], "round": 20, "heavili": [20, 21], "sens": 20, "amort": 20, "logdir": 20, "converg": 20, "caution": 20, "interest": 20, "known": 20, "crash": 20, "unmodifi": 21, "hook": 21, "biggest": [21, 23], "torchfx": 21, "technologi": 21, "fx": 21, "a_xla": 21, "b_xla": 21, "compiled_cod": 21, "eval_model": 21, "xla_resnet18": 21, "eval": 21, "dynamo_resnet18": 21, "no_grad": 21, "resent18": 21, "analysi": 21, "bench": 21, "59": 21, "resnext50_32x4d": 21, "91": 21, "alexnet": 21, "28": 21, "mobilenet_v2": 21, "18": 21, "62": 21, "mnasnet1_0": 21, "68": 21, "vgg16": 21, "bert_pytorch": 21, "squeezenet1_1": 21, "timm_vision_transform": 21, "52": 21, "geomean": 21, "04": 21, "train_model": 21, "crossentropyloss": 21, "pred": 21, "train_model_main": 21, "dynamo_train_model": 21, "xla_optim": 21, "weight_decai": 21, "extract": 21, "07": 21, "43": 21, "81": 21, "87": 21, "fwd": 21, "bwd": 21, "e2": 21, "hide": 21, "scenario": 21, "larger": [21, 23], "wit": 21, "promis": 21, "tradit": 21, "excit": 21, "upcom": [21, 27], "invest": 21, "matur": 21, "stori": 21, "_higher_order_op": 22, "fori_loop": 22, "cond_fn": 22, "body_fn": 22, "bodi": 22, "iteri": 22, "init_v": 22, "functionaltensor": 22, "lvl": 22, "cumul": 22, "ten": 22, "51": 22, "xlafullyshardeddataparallel": 23, "my_modul": [23, 24], "adam": [23, 24], "0001": [23, 24], "leftov": [23, 24], "arxiv": 23, "1910": 23, "02054": 23, "reshard_after_forward": 23, "test_train_mp_mnist_fsdp_with_ckpt": 23, "test_train_mp_imagenet_fsdp": 23, "interleav": 23, "submodul": 23, "fsdpvitmodel": 23, "checkpoint_modul": [23, 24], "3524": 23, "auto_wrap_polici": [23, 24], "size_based_auto_wrap_polici": 23, "polici": [23, 27], "100m": 23, "transformer_auto_wrap_polici": [23, 24], "transformer_layer_cl": [23, 24], "auto_wrapper_cal": 23, "remateri": 23, "resum": 23, "get_shard_metadata": 23, "consolidate_sharded_model_checkpoint": 23, "stitch": 23, "ckpt": 23, "shard_metadata": 23, "ckpt_path": 23, "pth": 23, "consolidate_sharded_ckpt": 23, "ckpt_prefix": 23, "your_sharded_checkpoint_fil": 23, "ckpt_suffix": 23, "_rank": 23, "inspir": 23, "structur": [23, 27], "fairscal": 23, "fullyshardeddataparallel": 23, "readthedoc": 23, "en": 23, "resort": 23, "train_resnet_fsdp_auto_wrap": 23, "newer": 23, "recurs": [23, 24], "98": 23, "drop_last": 23, "use_nested_fsdp": 23, "use_gradient_checkpoint": 23, "final_ckpt": 23, "75": 23, "download": 23, "1k": 23, "datadir": 23, "test_set_batch_s": 23, "eval_interv": 23, "num_warmup_epoch": 23, "lr_scheduler_divide_every_n_epoch": 23, "lr_scheduler_divisor": 23, "residu": 23, "algorithm": [23, 24], "ronghanghu": 23, "vit_10b_fsdp_exampl": 23, "vit": 23, "fsdpv2": 24, "famou": 24, "enjoi": 24, "tabl": 24, "spmd_fully_sharded_data_parallel": 24, "spmdfullyshardeddataparallel": 24, "autowrap": 24, "decoderlay": 24, "functool": 24, "decoder_only_model": 24, "shard_output": 24, "0th": 24, "children": 24, "fork": 24, "hf": 24, "abstract": [25, 27], "blockwis": 25, "int4": 25, "analog": 25, "classifi": 25, "flexibl": 25, "choos": [25, 29], "docstr": 25, "xla_quantized_matmul": 25, "n_input_featur": 25, "n_output_featur": 25, "w_int": 25, "127": 25, "int8": 25, "matmul_output": 25, "quantized_matmul": 25, "x_xla": 25, "w_int_xla": 25, "scaler_xla": 25, "matmul_output_xla": 25, "w": 25, "f_dynamo": 25, "dynamo_out_xla": 25, "myqlinearforxlabackend": 25, "load_weight": 25, "processed_w": 25, "processed_scal": 25, "stuff": 25, "orig_model": 25, "mymodel": 25, "q_weight": 25, "q_weights_for_xla": 25, "process_for_xla": 25, "q_linear": 25, "xlaquantizedlinear": 25, "in_featur": 25, "out_featur": 25, "load_quantized_weight": 25, "channel": 25, "sym": 25, "asym": 25, "w8a16": 25, "w8a8": 25, "w4a8": 25, "gspmd": [27, 28], "proced": 27, "src": [27, 29], "_input_sharding_": 27, "4d": 27, "input_shard": 27, "shardingspec": 27, "input_mesh": 27, "s2": 27, "s3": 27, "s4": 27, "_after": 27, "_the": 27, "unnecessari": 27, "forth": 27, "techniqu": 27, "decis": 27, "nice": 27, "arrang": 27, "center": 27, "multislic": 27, "accept": 27, "denot": 27, "delai": 27, "subclass": 27, "__torch_dispatch__": 27, "global_tensor": 27, "strictli": 27, "local_shard": 27, "xlashard": 27, "4e8e5511555073ce8b6d1a436bf808c9333dcac6": 27, "xla_sharded_tensor": 27, "l12": 27, "ongo": 27, "distributedtensor": 27, "proof": 27, "concept": [27, 28], "distribute_tensor": 27, "devicemesh": 27, "big_tensor": 27, "100000": 27, "88": 27, "my_dtensor": 27, "stai": 27, "dynamo_mark_shard": 27, "placement": 27, "visualize_tensor_shard": 27, "visualize_shard": 27, "rich": 27, "2x2": 27, "generated_t": 27, "use_color": 27, "style": 27, "tile": 27, "partial_repl": 27, "envvar": 27, "xla_auto_spmd": 27, "_tensor": 27, "distribute_modul": 27, "auto_polici": 27, "mymodul": 27, "sharded_model": 27, "behvaior": 27, "xla_auto_use_group_shard": 27, "reshard": 27, "xla_auto_spmd_mesh": 27, "unset": 27, "hint": 28, "strategi": 28, "th": 28, "cluster": 28, "interconnect": 28, "encourag": 28, "fist": 28, "paral": 28, "dedic": 29, "planner": 29, "spmdsaveplann": 29, "spmdloadplann": 29, "dist_cp": 29, "distributed_checkpoint": 29, "xc": 29, "storage_writ": 29, "filesystemwrit": 29, "checkpoint_dir": 29, "storage_read": 29, "filesystemread": 29, "all_step": 29, "save_async": 29, "unblock": 29, "preemption": 29, "detect": 29, "provis": 29, "queuedresourc": 29, "autocheckpoint": 29, "chkpt_on_preempt": 29, "fsspec": 29, "filesystem": 29, "prime_optim": 29, "chkpt_mgr": 29, "tracked_step": 29, "highest": 29, "best_step": 29, "prime": 29, "enumer": 29, "attempt": 29, "unprim": 29, "destruct": 29, "discov": 29, "nvidia": 30, "resnet": 30, "num_gpu_machin": 30, "rank_of_current_machin": 30, "machine_0_ip_address": 30, "training_or_inference_script_using_spmd": 30, "xla_use_spmd": 30, "test_train_spmd_imagenet": 30}, "objects": {"": [[11, 0, 0, "-", "torch_xla"]], "torch_xla": [[11, 1, 1, "", "compile"], [11, 1, 1, "", "device"], [11, 1, 1, "", "device_count"], [11, 1, 1, "", "devices"], [11, 0, 0, "-", "experimental"], [11, 1, 1, "", "manual_seed"], [11, 0, 0, "-", "runtime"], [11, 1, 1, "", "sync"]], "torch_xla.core": [[11, 0, 0, "-", "xla_model"]], "torch_xla.core.xla_model": [[11, 1, 1, "", "add_step_closure"], [11, 1, 1, "", "all_gather"], [11, 1, 1, "", "all_reduce"], [11, 1, 1, "", "all_to_all"], [11, 1, 1, "", "get_memory_info"], [11, 1, 1, "", "get_rng_state"], [11, 1, 1, "", "get_stablehlo"], [11, 1, 1, "", "get_stablehlo_bytecode"], [11, 1, 1, "", "is_master_ordinal"], [11, 1, 1, "", "mesh_reduce"], [11, 1, 1, "", "optimizer_step"], [11, 1, 1, "", "rendezvous"], [11, 1, 1, "", "save"], [11, 1, 1, "", "set_rng_state"], [11, 1, 1, "", "wait_device_ops"], [11, 1, 1, "", "xla_device"], [11, 1, 1, "", "xla_device_hw"]], "torch_xla.debug": [[11, 0, 0, "-", "metrics"]], "torch_xla.debug.metrics": [[11, 1, 1, "", "counter_names"], [11, 1, 1, "", "counter_value"], [11, 1, 1, "", "metric_data"], [11, 1, 1, "", "metric_names"], [11, 1, 1, "", "metrics_report"], [11, 1, 1, "", "short_metrics_report"]], "torch_xla.distributed": [[11, 0, 0, "-", "parallel_loader"], [11, 0, 0, "-", "spmd"], [11, 0, 0, "-", "xla_multiprocessing"]], "torch_xla.distributed.parallel_loader": [[11, 2, 1, "", "MpDeviceLoader"]], "torch_xla.distributed.spmd": [[11, 2, 1, "", "HybridMesh"], [11, 2, 1, "", "Mesh"], [11, 1, 1, "", "clear_sharding"], [11, 1, 1, "", "get_1d_mesh"], [11, 1, 1, "", "get_global_mesh"], [11, 1, 1, "", "mark_sharding"], [11, 1, 1, "", "set_global_mesh"]], "torch_xla.distributed.xla_multiprocessing": [[11, 1, 1, "", "spawn"]], "torch_xla.experimental": [[11, 1, 1, "", "eager_mode"]], "torch_xla.runtime": [[11, 1, 1, "", "addressable_device_count"], [11, 1, 1, "", "device_type"], [11, 1, 1, "", "get_master_ip"], [11, 1, 1, "", "global_device_count"], [11, 1, 1, "", "global_ordinal"], [11, 1, 1, "", "global_runtime_device_count"], [11, 1, 1, "", "initialize_cache"], [11, 1, 1, "", "is_spmd"], [11, 1, 1, "", "local_device_count"], [11, 1, 1, "", "local_ordinal"], [11, 1, 1, "", "local_process_count"], [11, 1, 1, "", "use_spmd"], [11, 1, 1, "", "world_size"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"]}, "titleterms": {"learn": [0, 1, 10], "about": [0, 1, 10], "gpu": [0, 9, 14, 19, 30], "tpu": [1, 4, 14, 15, 17, 19, 23, 27], "bazel": 2, "pytorch": [2, 3, 4, 6, 7, 8, 10, 11, 15, 16, 17, 21, 23, 26, 27, 28], "xla": [2, 3, 4, 6, 7, 10, 11, 15, 16, 17, 19, 21, 23, 25, 26, 27, 28], "depend": [2, 7, 9], "how": [2, 20, 25, 28], "build": 2, "librari": 2, "torch": [2, 8, 14, 27], "plugin": [2, 6], "remot": 2, "cach": [2, 15], "run": [2, 3, 8, 15, 16, 17, 27, 30], "test": [2, 3, 5, 16, 22], "code": [2, 4, 17, 25], "coverag": 2, "languag": 2, "server": 2, "codegen": 3, "migrat": 3, "guid": [3, 5, 28], "befor": [3, 5], "you": [3, 5, 18, 26], "start": [3, 5, 18, 26], "file": [3, 5, 8], "structur": [3, 5], "old": 3, "op": [3, 5, 25], "lower": [3, 5], "step": [3, 4], "1": [3, 17, 18, 26], "identifi": 3, "2": [3, 17, 18, 24, 26], "inspect": 3, "gener": [3, 8], "lazyir": 3, "h": 3, "3": [3, 18, 26], "implement": [3, 6], "miss": 3, "ir": 3, "function": 3, "torch_xla": [3, 11, 18], "csrc": 3, "ops_xla_shape_fn": 3, "cpp": 3, "4": 3, "ops_lower_fn": 3, "5": 3, "cleanup": 3, "verifi": 3, "result": 3, "sampl": 3, "pr": 3, "configur": 4, "develop": 4, "environ": [4, 16], "visual": 4, "studio": 4, "creat": [4, 15], "connect": 4, "your": 4, "set": 4, "up": 4, "workspac": 4, "next": 4, "understand": [5, 16], "oper": [5, 8, 18, 19, 25, 26], "unit": [5, 16], "tip": 5, "custom": [6, 7, 9], "hardwar": 6, "pjrt": [6, 14], "c": 6, "api": [6, 11, 13], "packag": 6, "kernel": [7, 9], "via": [7, 9], "palla": 7, "adopt": 7, "abov": 7, "compat": 7, "us": [7, 18, 20, 22, 24, 25, 26, 28], "built": 7, "flashattent": 7, "exampl": [7, 17, 19, 22, 23, 24], "usag": [7, 13, 22], "integr": [7, 21, 27], "pagedattent": 7, "export": 8, "stablehlo": 8, "save": [8, 15], "bytecod": 8, "disk": 8, "convert": [8, 17], "serv": 8, "common": [8, 16], "wrapper": 8, "i": [8, 18, 26, 28], "want": 8, "directli": 8, "tf": 8, "saved_model": 8, "format": 8, "without": [8, 18, 26], "need": 8, "an": [8, 15], "separ": 8, "command": 8, "other": 8, "produc": 8, "save_as_stablehlo": 8, "preserv": 8, "high": 8, "level": 8, "composit": 8, "triton": 9, "document": 10, "acceler": 10, "featur": [10, 21, 25], "improv": 10, "workload": 10, "perform": [10, 14, 16, 17], "contribut": 10, "runtim": [11, 14], "xla_model": 11, "distribut": [11, 14, 29], "spmd": [11, 24, 27, 28, 30], "experiment": [11, 25], "debug": [11, 16, 27], "dynam": [12, 18, 26], "shape": [12, 18, 26], "bound": [12, 18, 26], "eager": 13, "mode": [13, 28], "compil": [13, 15, 16, 27], "basic": 13, "infer": [13, 17, 21], "train": [13, 14, 21, 23], "benchmark": [13, 16, 20], "tl": 14, "dr": 14, "benefit": 14, "quickstart": 14, "cpu": [14, 15], "pod": [14, 15, 17, 23, 27], "docker": 14, "singl": [14, 15, 17], "node": 14, "multi": [14, 15], "differ": 14, "from": [14, 15, 18, 26], "xrt": 14, "multithread": 14, "v2": 14, "v3": [14, 23], "chang": 14, "xm": 14, "rendezv": 14, "new": 14, "devic": [15, 17, 27], "tensor": [15, 16, 18, 26], "ar": 15, "model": [15, 25], "multipl": [15, 17], "process": [15, 29], "deep": 15, "dive": 15, "lazi": 15, "memori": [15, 22], "layout": 15, "move": 15, "load": [15, 27], "further": [15, 28], "read": [15, 28], "troubleshoot": 16, "saniti": 16, "check": 16, "version": 16, "A": 16, "simpl": [16, 22], "calcul": 16, "resnet": [16, 23], "With": 16, "fake": [16, 20], "data": [16, 20, 23, 24, 27], "tool": [16, 27], "auto": [16, 27], "metric": 16, "analysi": [16, 17], "execut": 16, "get": 16, "report": 16, "The": 16, "clear": 16, "dynamo": 16, "profil": [16, 17], "known": 16, "caveat": 16, "quirk": 16, "more": 16, "variabl": 16, "combin": 16, "reproduc": 16, "ci": 16, "cd": 16, "failur": 16, "overview": 17, "setup": 17, "stabl": 17, "diffus": 17, "lightn": 17, "hf": 17, "sourc": [18, 26], "recompil": [18, 26], "let": [18, 26], "": [18, 26], "first": [18, 26], "some": [18, 26], "fact": [18, 26], "constraint": [18, 26], "input": [18, 26], "dataset": [18, 26], "output": [18, 24, 26], "can": [18, 26], "fix": [18, 26], "case": [18, 22, 26], "when": [18, 26], "queri": [18, 26], "its": [18, 26], "real": [18, 20, 26], "dimens": [18, 26], "what": [18, 26, 28], "control": [18, 22, 26], "flow": [18, 26], "conclus": [18, 26], "appendix": [18, 26], "automat": 19, "mix": 19, "precis": 19, "amp": 19, "best": 19, "practic": 19, "support": [19, 25], "do": 20, "distributeddataparallel": 20, "ddp": 20, "background": 20, "motiv": 20, "resnet50": 20, "mnist": [20, 23], "disclaim": 20, "torchdynamo": 21, "gap": 21, "take": 21, "awai": 21, "optim": [22, 27, 29], "util": 22, "while_loop": 22, "group": [22, 29], "pure": 22, "python": 22, "while": 22, "loop": 22, "fulli": [23, 24], "shard": [23, 24, 27], "parallel": [23, 24], "script": 23, "imagenet": 23, "instal": 23, "clone": 23, "repo": 23, "8": 23, "50": 23, "10": 23, "billion": 23, "paramet": 23, "gradient": 24, "checkpoint": [24, 29], "huggingfac": 24, "llama": 24, "quantiz": 25, "call": 25, "modul": 25, "swap": 25, "matrix": 25, "multipli": 25, "advanc": 27, "topic": 27, "awar": 27, "host": 27, "virtual": 27, "hybrid": 27, "mesh": [27, 28], "xlashardedtensor": 27, "dtensor": 27, "activ": 27, "user": 28, "partit": 28, "spec": 28, "checkpointmanag": 29, "restor": 29, "state": 29}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Learn about GPUs": [[0, "learn-about-gpus"]], "Learn about TPUs": [[1, "learn-about-tpus"]], "Bazel in Pytorch/XLA": [[2, "bazel-in-pytorch-xla"]], "Bazel dependencies": [[2, "bazel-dependencies"]], "How to build XLA libraries": [[2, "how-to-build-xla-libraries"]], "How to build the Torch/XLA plugin": [[2, "how-to-build-the-torch-xla-plugin"]], "Remote caching": [[2, "remote-caching"]], "Running tests": [[2, "running-tests"]], "Code coverage": [[2, "code-coverage"]], "Language Server": [[2, "language-server"]], "Building PyTorch/XLA": [[2, "building-pytorch-xla"]], "Codegen migration Guide": [[3, "codegen-migration-guide"]], "Before you start": [[3, "before-you-start"], [5, "before-you-start"]], "File structure": [[3, "file-structure"], [5, "file-structure"]], "PyTorch Codegen files": [[3, "pytorch-codegen-files"]], "PyTorch/XLA Codegen files": [[3, "pytorch-xla-codegen-files"]], "PyTorch/XLA Old Op Lowering files": [[3, "pytorch-xla-old-op-lowering-files"]], "Codegen step by step": [[3, "codegen-step-by-step"]], "1. Identify the op": [[3, "identify-the-op"]], "2. Codegen the op and inspect the generated file": [[3, "codegen-the-op-and-inspect-the-generated-file"]], "LazyIr.h": [[3, "lazyir-h"]], "3. Implement the missing IR function": [[3, "implement-the-missing-ir-function"]], "torch_xla/csrc/ops/ops_xla_shape_fn.h": [[3, "torch-xla-csrc-ops-ops-xla-shape-fn-h"]], "torch_xla/csrc/ops/ops_xla_shape_fn.cpp": [[3, "torch-xla-csrc-ops-ops-xla-shape-fn-cpp"]], "4. Implement the lowering function": [[3, "implement-the-lowering-function"]], "torch_xla/csrc/ops/ops_lower_fn.cpp": [[3, "torch-xla-csrc-ops-ops-lower-fn-cpp"]], "5. Cleanup": [[3, "cleanup"]], "Run the test and verify the result": [[3, "run-the-test-and-verify-the-result"]], "Sample PRs": [[3, "sample-prs"]], "Configure a development environment": [[4, "configure-a-development-environment"]], "Visual Studio Code": [[4, "visual-studio-code"]], "Creating and connecting to your TPU": [[4, "creating-and-connecting-to-your-tpu"]], "Setting up a Visual Studio Code workspace with PyTorch/XLA": [[4, "setting-up-a-visual-studio-code-workspace-with-pytorch-xla"]], "Next steps": [[4, "next-steps"]], "OP Lowering Guide": [[5, "op-lowering-guide"]], "Understanding the operation": [[5, "understanding-the-operation"]], "Unit Test": [[5, "unit-test"]], "Tips": [[5, "tips"]], "Custom Hardware Plugins": [[6, "custom-hardware-plugins"]], "Implementing a PJRT Plugin": [[6, "implementing-a-pjrt-plugin"]], "PJRT C API Implementation": [[6, "pjrt-c-api-implementation"]], "PyTorch/XLA Plugin Package": [[6, "pytorch-xla-plugin-package"]], "Custom Kernels via Pallas": [[7, "custom-kernels-via-pallas"]], "Adopt the above kernel to be compatible with PyTorch/XLA": [[7, "adopt-the-above-kernel-to-be-compatible-with-pytorch-xla"]], "Use built-in kernels": [[7, "use-built-in-kernels"]], "FlashAttention": [[7, "id1"]], "Example usage": [[7, "example-usage"], [7, "id3"]], "Integration Example": [[7, "integration-example"], [7, "id4"]], "PagedAttention": [[7, "id2"]], "Dependencies": [[7, "dependencies"], [9, "dependencies"]], "Torch Export to StableHLO": [[8, "torch-export-to-stablehlo"]], "Saving StableHLO bytecodes to disk": [[8, "saving-stablehlo-bytecodes-to-disk"]], "Convert saved StableHLO for serving": [[8, "convert-saved-stablehlo-for-serving"]], "Common wrappers": [[8, "common-wrappers"]], "I want to save directly tf.saved_model format without needing to run an separate command.": [[8, "i-want-to-save-directly-tf-saved-model-format-without-needing-to-run-an-separate-command"]], "Other common wrappers": [[8, "other-common-wrappers"]], "Files produced by save_as_stablehlo.": [[8, "files-produced-by-save-as-stablehlo"]], "Preserving High-Level PyTorch Operations in StableHLO by generating stablehlo.composite": [[8, "preserving-high-level-pytorch-operations-in-stablehlo-by-generating-stablehlo-composite"]], "Custom GPU Kernels via Triton": [[9, "custom-gpu-kernels-via-triton"]], "PyTorch/XLA documentation": [[10, "pytorch-xla-documentation"]], "Learn about Pytorch/XLA": [[10, null]], "Learn about accelerators": [[10, null]], "PyTorch/XLA features": [[10, null]], "Improve Pytorch/XLA workload performance": [[10, null]], "Contribute to Pytorch/XLA": [[10, null]], "PyTorch/XLA API": [[11, "pytorch-xla-api"]], "torch_xla": [[11, "module-torch_xla"]], "runtime": [[11, "module-torch_xla.runtime"]], "xla_model": [[11, "module-torch_xla.core.xla_model"]], "distributed": [[11, "module-torch_xla.distributed.parallel_loader"]], "spmd": [[11, "module-torch_xla.distributed.spmd"]], "experimental": [[11, "module-torch_xla.experimental"]], "debug": [[11, "module-torch_xla.debug.metrics"]], "Dynamic shape": [[12, "dynamic-shape"]], "Bounded dynamic shape": [[12, "bounded-dynamic-shape"]], "Eager Mode + Compile API": [[13, "eager-mode-compile-api"]], "Basic Usage": [[13, "basic-usage"]], "Inference": [[13, "inference"], [21, "inference"]], "Training": [[13, "training"], [21, "training"]], "Benchmark": [[13, "benchmark"]], "PJRT Runtime": [[14, "pjrt-runtime"]], "TL;DR": [[14, "tl-dr"]], "Benefits": [[14, "benefits"]], "Quickstart": [[14, "quickstart"]], "CPU": [[14, "cpu"]], "TPU": [[14, "tpu"]], "Pods": [[14, "pods"]], "Docker": [[14, "docker"]], "GPU": [[14, "gpu"]], "Single-node GPU training": [[14, "single-node-gpu-training"]], "Multi-node GPU training": [[14, "multi-node-gpu-training"]], "Differences from XRT": [[14, "differences-from-xrt"]], "Multithreading on TPU v2/v3": [[14, "id3"]], "Changes to xm.rendezvous": [[14, "changes-to-xm-rendezvous"]], "PJRT and torch.distributed": [[14, "pjrt-and-torch-distributed"]], "Performance": [[14, "performance"]], "New TPU runtime": [[14, "new-tpu-runtime"]], "PyTorch on XLA Devices": [[15, "pytorch-on-xla-devices"]], "Creating an XLA Tensor": [[15, "creating-an-xla-tensor"]], "XLA Tensors are PyTorch Tensors": [[15, "xla-tensors-are-pytorch-tensors"]], "Running Models on XLA Devices": [[15, "running-models-on-xla-devices"]], "Running on a Single XLA Device": [[15, "running-on-a-single-xla-device"]], "Running on Multiple XLA Devices with Multi-processing": [[15, "running-on-multiple-xla-devices-with-multi-processing"]], "Running on TPU Pods": [[15, "running-on-tpu-pods"]], "XLA Tensor Deep Dive": [[15, "id3"]], "XLA Tensors are Lazy": [[15, "xla-tensors-are-lazy"]], "Memory Layout": [[15, "memory-layout"]], "Moving XLA Tensors to and from the CPU": [[15, "moving-xla-tensors-to-and-from-the-cpu"]], "Saving and Loading XLA Tensors": [[15, "saving-and-loading-xla-tensors"]], "Compilation Caching": [[15, "compilation-caching"]], "Further Reading": [[15, "further-reading"], [28, "further-reading"]], "Troubleshoot": [[16, "troubleshoot"]], "Sanity Check": [[16, "sanity-check"]], "Check PyTorch/XLA Version": [[16, "check-pytorch-xla-version"]], "Perform A Simple Calculation": [[16, "perform-a-simple-calculation"]], "Run Resnet With Fake Data": [[16, "run-resnet-with-fake-data"]], "Performance Debugging": [[16, "performance-debugging"]], "PyTorch/XLA Debugging Tool": [[16, "pytorch-xla-debugging-tool"]], "Perform A Auto-Metrics Analysis": [[16, "perform-a-auto-metrics-analysis"]], "Compilation & Execution Analysis": [[16, "compilation-execution-analysis"]], "Get A Metrics Report": [[16, "get-a-metrics-report"]], "Understand The Metrics Report": [[16, "understand-the-metrics-report"]], "Clear The Metrics Report": [[16, "clear-the-metrics-report"]], "PyTorch/XLA + Dynamo Debugging Tool": [[16, "pytorch-xla-dynamo-debugging-tool"]], "Performance Profiling": [[16, "performance-profiling"]], "Simple Benchmarking": [[16, "simple-benchmarking"]], "Known Performance Caveats": [[16, "known-performance-caveats"]], "XLA Tensor Quirks": [[16, "xla-tensor-quirks"]], "More Debugging Tools": [[16, "more-debugging-tools"]], "Environment Variables": [[16, "environment-variables"]], "Common Debugging Environment Variables Combinations": [[16, "common-debugging-environment-variables-combinations"]], "Reproducing PyTorch/XLA CI/CD unit test failures.": [[16, "reproducing-pytorch-xla-ci-cd-unit-test-failures"]], "Pytorch/XLA overview": [[17, "pytorch-xla-overview"]], "TPU Setup": [[17, "tpu-setup"]], "Converting code to PyTorch XLA": [[17, "converting-code-to-pytorch-xla"]], "Example 1. Stable Diffusion inference in PyTorch Lightning on a Single TPU Device": [[17, "example-1-stable-diffusion-inference-in-pytorch-lightning-on-a-single-tpu-device"]], "Example 2. HF Stable Diffusion Inference": [[17, "example-2-hf-stable-diffusion-inference"]], "Running on a Single TPU device": [[17, "running-on-a-single-tpu-device"]], "Profiling and performance analysis": [[17, "profiling-and-performance-analysis"]], "Running on Multiple TPU Devices": [[17, "running-on-multiple-tpu-devices"]], "Running on Pods": [[17, "running-on-pods"]], "Source of recompilations in torch_xla": [[18, "source-of-recompilations-in-torch-xla"]], "Let\u2019s first start with some facts/constraints:": [[18, "lets-first-start-with-some-facts-constraints"], [26, "lets-first-start-with-some-facts-constraints"]], "#1. From input dataset.": [[18, "from-input-dataset"], [26, "from-input-dataset"]], "#2. From operator output": [[18, "from-operator-output"], [26, "from-operator-output"]], "2.1 Bounded dynamic shape can fix the case when you use the tensor with dynamic shape as a Tensor, without querying its real dimension.": [[18, "bounded-dynamic-shape-can-fix-the-case-when-you-use-the-tensor-with-dynamic-shape-as-a-tensor-without-querying-its-real-dimension"], [26, "bounded-dynamic-shape-can-fix-the-case-when-you-use-the-tensor-with-dynamic-shape-as-a-tensor-without-querying-its-real-dimension"]], "2.2 what if real dimension is queried on a tensor with dynamic shape?": [[18, "what-if-real-dimension-is-queried-on-a-tensor-with-dynamic-shape"], [26, "what-if-real-dimension-is-queried-on-a-tensor-with-dynamic-shape"]], "#3. From control flow": [[18, "from-control-flow"], [26, "from-control-flow"]], "Conclusion:": [[18, "conclusion"], [26, "conclusion"]], "Appendix:": [[18, "appendix"], [26, "appendix"]], "Automatic Mixed Precision": [[19, "automatic-mixed-precision"]], "AMP for XLA:TPU": [[19, "amp-for-xla-tpu"]], "AMP for XLA:TPU Best Practices": [[19, "amp-for-xla-tpu-best-practices"]], "Supported Operators": [[19, "supported-operators"]], "AMP for XLA:GPU": [[19, "amp-for-xla-gpu"]], "AMP for XLA:GPU Best Practices": [[19, "amp-for-xla-gpu-best-practices"]], "Examples": [[19, "examples"]], "How to do DistributedDataParallel(DDP)": [[20, "how-to-do-distributeddataparallel-ddp"]], "Background / Motivation": [[20, "background-motivation"]], "How to use DistributedDataParallel": [[20, "how-to-use-distributeddataparallel"]], "Benchmarking": [[20, "benchmarking"]], "Resnet50 with fake data": [[20, "resnet50-with-fake-data"]], "MNIST with fake data": [[20, "mnist-with-fake-data"]], "MNIST with real data": [[20, "mnist-with-real-data"]], "Disclaimer": [[20, "disclaimer"]], "TorchDynamo integration in PyTorch XLA": [[21, "torchdynamo-integration-in-pytorch-xla"]], "Integration": [[21, "integration"]], "Feature gaps": [[21, "feature-gaps"]], "Take away": [[21, "take-away"]], "Optimize memory utilization using while_loop": [[22, "optimize-memory-utilization-using-while-loop"]], "while_loop": [[22, "while-loop"]], "Usage:": [[22, "usage"]], "simple example with while_loop:": [[22, "simple-example-with-while-loop"]], "Control group test case": [[22, "control-group-test-case"]], "Control group example with pure python while loop": [[22, "control-group-example-with-pure-python-while-loop"]], "Fully Sharded Data Parallel in PyTorch XLA": [[23, "fully-sharded-data-parallel-in-pytorch-xla"]], "Example training scripts on MNIST and ImageNet": [[23, "example-training-scripts-on-mnist-and-imagenet"]], "Installation": [[23, "installation"]], "Clone PyTorch/XLA repo": [[23, "clone-pytorch-xla-repo"]], "Train MNIST on v3-8 TPU": [[23, "train-mnist-on-v3-8-tpu"]], "Train ImageNet with ResNet-50 on v3-8 TPU": [[23, "train-imagenet-with-resnet-50-on-v3-8-tpu"]], "Example training scripts on TPU pod (with 10 billion parameters)": [[23, "example-training-scripts-on-tpu-pod-with-10-billion-parameters"]], "Fully Sharded Data Parallel using SPMD": [[24, "fully-sharded-data-parallel-using-spmd"]], "Sharding output": [[24, "sharding-output"]], "Gradient checkpointing": [[24, "gradient-checkpointing"]], "HuggingFace Llama 2 Example": [[24, "huggingface-llama-2-example"]], "Quantized Operations for XLA (Experimental feature)": [[25, "quantized-operations-for-xla-experimental-feature"]], "How to use:": [[25, "how-to-use"]], "Call XLA quantized op in model code": [[25, "call-xla-quantized-op-in-model-code"]], "Module Swap": [[25, "module-swap"]], "Supported Quantized Operations:": [[25, "supported-quantized-operations"]], "Matrix Multiply": [[25, "matrix-multiply"]], "Source of recompilations in Pytorch/XLA": [[26, "source-of-recompilations-in-pytorch-xla"]], "PyTorch/XLA SPMD advanced topics": [[27, "pytorch-xla-spmd-advanced-topics"]], "Sharding-Aware Host-to-Device Data Loading": [[27, "sharding-aware-host-to-device-data-loading"]], "Virtual Device Optimization": [[27, "virtual-device-optimization"]], "Hybrid Mesh": [[27, "hybrid-mesh"]], "Running SPMD on TPU Pod": [[27, "running-spmd-on-tpu-pod"]], "XLAShardedTensor": [[27, "xlashardedtensor"]], "DTensor Integration": [[27, "dtensor-integration"]], "Activation Sharding for torch.compile": [[27, "activation-sharding-for-torch-compile"]], "SPMD Debugging Tool": [[27, "spmd-debugging-tool"]], "Auto-Sharding": [[27, "auto-sharding"]], "PyTorch/XLA SPMD User Guide": [[28, "pytorch-xla-spmd-user-guide"]], "What is PyTorch/XLA SPMD?": [[28, "what-is-pytorch-xla-spmd"]], "How to use PyTorch/XLA SPMD?": [[28, "how-to-use-pytorch-xla-spmd"]], "SPMD Mode": [[28, "spmd-mode"]], "Mesh": [[28, "mesh"]], "Partition Spec": [[28, "partition-spec"]], "Distributed Checkpointing": [[29, "distributed-checkpointing"]], "CheckpointManager": [[29, "checkpointmanager"]], "Restoring Optimizer State": [[29, "restoring-optimizer-state"]], "Process Groups": [[29, "process-groups"]], "Running SPMD on GPU": [[30, "running-spmd-on-gpu"]]}, "indexentries": {"hybridmesh (class in torch_xla.distributed.spmd)": [[11, "torch_xla.distributed.spmd.HybridMesh"]], "mesh (class in torch_xla.distributed.spmd)": [[11, "torch_xla.distributed.spmd.Mesh"]], "mpdeviceloader (class in torch_xla.distributed.parallel_loader)": [[11, "torch_xla.distributed.parallel_loader.MpDeviceLoader"]], "add_step_closure() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.add_step_closure"]], "addressable_device_count() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.addressable_device_count"]], "all_gather() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.all_gather"]], "all_reduce() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.all_reduce"]], "all_to_all() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.all_to_all"]], "clear_sharding() (in module torch_xla.distributed.spmd)": [[11, "torch_xla.distributed.spmd.clear_sharding"]], "compile() (in module torch_xla)": [[11, "torch_xla.compile"]], "counter_names() (in module torch_xla.debug.metrics)": [[11, "torch_xla.debug.metrics.counter_names"]], "counter_value() (in module torch_xla.debug.metrics)": [[11, "torch_xla.debug.metrics.counter_value"]], "device() (in module torch_xla)": [[11, "torch_xla.device"]], "device_count() (in module torch_xla)": [[11, "torch_xla.device_count"]], "device_type() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.device_type"]], "devices() (in module torch_xla)": [[11, "torch_xla.devices"]], "eager_mode() (in module torch_xla.experimental)": [[11, "torch_xla.experimental.eager_mode"]], "get_1d_mesh() (in module torch_xla.distributed.spmd)": [[11, "torch_xla.distributed.spmd.get_1d_mesh"]], "get_global_mesh() (in module torch_xla.distributed.spmd)": [[11, "torch_xla.distributed.spmd.get_global_mesh"]], "get_master_ip() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.get_master_ip"]], "get_memory_info() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.get_memory_info"]], "get_rng_state() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.get_rng_state"]], "get_stablehlo() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.get_stablehlo"]], "get_stablehlo_bytecode() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.get_stablehlo_bytecode"]], "global_device_count() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.global_device_count"]], "global_ordinal() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.global_ordinal"]], "global_runtime_device_count() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.global_runtime_device_count"]], "initialize_cache() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.initialize_cache"]], "is_master_ordinal() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.is_master_ordinal"]], "is_spmd() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.is_spmd"]], "local_device_count() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.local_device_count"]], "local_ordinal() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.local_ordinal"]], "local_process_count() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.local_process_count"]], "manual_seed() (in module torch_xla)": [[11, "torch_xla.manual_seed"]], "mark_sharding() (in module torch_xla.distributed.spmd)": [[11, "torch_xla.distributed.spmd.mark_sharding"]], "mesh_reduce() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.mesh_reduce"]], "metric_data() (in module torch_xla.debug.metrics)": [[11, "torch_xla.debug.metrics.metric_data"]], "metric_names() (in module torch_xla.debug.metrics)": [[11, "torch_xla.debug.metrics.metric_names"]], "metrics_report() (in module torch_xla.debug.metrics)": [[11, "torch_xla.debug.metrics.metrics_report"]], "module": [[11, "module-torch_xla"], [11, "module-torch_xla.core.xla_model"], [11, "module-torch_xla.debug.metrics"], [11, "module-torch_xla.distributed.parallel_loader"], [11, "module-torch_xla.distributed.spmd"], [11, "module-torch_xla.distributed.xla_multiprocessing"], [11, "module-torch_xla.experimental"], [11, "module-torch_xla.runtime"]], "optimizer_step() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.optimizer_step"]], "rendezvous() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.rendezvous"]], "save() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.save"]], "set_global_mesh() (in module torch_xla.distributed.spmd)": [[11, "torch_xla.distributed.spmd.set_global_mesh"]], "set_rng_state() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.set_rng_state"]], "short_metrics_report() (in module torch_xla.debug.metrics)": [[11, "torch_xla.debug.metrics.short_metrics_report"]], "spawn() (in module torch_xla.distributed.xla_multiprocessing)": [[11, "torch_xla.distributed.xla_multiprocessing.spawn"]], "sync() (in module torch_xla)": [[11, "torch_xla.sync"]], "torch_xla": [[11, "module-torch_xla"]], "torch_xla.core.xla_model": [[11, "module-torch_xla.core.xla_model"]], "torch_xla.debug.metrics": [[11, "module-torch_xla.debug.metrics"]], "torch_xla.distributed.parallel_loader": [[11, "module-torch_xla.distributed.parallel_loader"]], "torch_xla.distributed.spmd": [[11, "module-torch_xla.distributed.spmd"]], "torch_xla.distributed.xla_multiprocessing": [[11, "module-torch_xla.distributed.xla_multiprocessing"]], "torch_xla.experimental": [[11, "module-torch_xla.experimental"]], "torch_xla.runtime": [[11, "module-torch_xla.runtime"]], "use_spmd() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.use_spmd"]], "wait_device_ops() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.wait_device_ops"]], "world_size() (in module torch_xla.runtime)": [[11, "torch_xla.runtime.world_size"]], "xla_device() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.xla_device"]], "xla_device_hw() (in module torch_xla.core.xla_model)": [[11, "torch_xla.core.xla_model.xla_device_hw"]]}})