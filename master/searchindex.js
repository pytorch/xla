Search.setIndex({"docnames": ["accelerators/gpu", "accelerators/tpu", "contribute/bazel", "contribute/codegen_migration", "contribute/configure-environment", "contribute/op_lowering", "contribute/plugins", "features/distop", "features/pallas", "features/scan", "features/stablehlo", "features/triton", "index", "learn/api-guide", "learn/dynamic_shape", "learn/eager", "learn/pjrt", "learn/pytorch-on-xla-devices", "learn/troubleshoot", "learn/xla-overview", "notes/source_of_recompilation", "perf/amp", "perf/assume_pure", "perf/ddp", "perf/dynamo", "perf/fori_loop", "perf/fsdp", "perf/fsdpv2", "perf/quantized_ops", "perf/recompilation", "perf/spmd_advanced", "perf/spmd_basic", "perf/spmd_distributed_checkpoint", "perf/spmd_gpu"], "filenames": ["accelerators/gpu.md", "accelerators/tpu.md", "contribute/bazel.md", "contribute/codegen_migration.md", "contribute/configure-environment.md", "contribute/op_lowering.md", "contribute/plugins.md", "features/distop.md", "features/pallas.md", "features/scan.md", "features/stablehlo.md", "features/triton.md", "index.rst", "learn/api-guide.rst", "learn/dynamic_shape.md", "learn/eager.md", "learn/pjrt.md", "learn/pytorch-on-xla-devices.md", "learn/troubleshoot.md", "learn/xla-overview.md", "notes/source_of_recompilation.md", "perf/amp.md", "perf/assume_pure.md", "perf/ddp.md", "perf/dynamo.md", "perf/fori_loop.md", "perf/fsdp.md", "perf/fsdpv2.md", "perf/quantized_ops.md", "perf/recompilation.md", "perf/spmd_advanced.md", "perf/spmd_basic.md", "perf/spmd_distributed_checkpoint.md", "perf/spmd_gpu.md"], "titles": ["Learn about GPUs", "Learn about TPUs", "Bazel in Pytorch/XLA", "Codegen migration Guide", "Configure a development environment", "OP Lowering Guide", "Custom Hardware Plugins", "Support of Torch Distributed API in PyTorch/XLA", "Custom Kernels via Pallas", "Guide for using <code class=\"docutils literal notranslate\"><span class=\"pre\">scan</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">scan_layers</span></code>", "Torch Export to StableHLO", "Custom GPU Kernels via Triton", "PyTorch/XLA documentation", "PyTorch/XLA API", "Dynamic shape", "Eager Mode + Compile API", "PJRT Runtime", "PyTorch on XLA Devices", "Troubleshoot", "Pytorch/XLA overview", "Source of recompilations in torch_xla", "Automatic Mixed Precision", "Use <code class=\"docutils literal notranslate\"><span class=\"pre\">&#64;assume_pure</span></code> to speed up lazy tensor tracing", "How to do DistributedDataParallel(DDP)", "TorchDynamo integration in PyTorch XLA", "Optimize memory utilization using <code class=\"docutils literal notranslate\"><span class=\"pre\">while_loop</span></code>", "Fully Sharded Data Parallel in PyTorch XLA", "Fully Sharded Data Parallel using SPMD", "Quantized Operations for XLA (Experimental feature)", "Source of recompilations in Pytorch/XLA", "PyTorch/XLA SPMD advanced topics", "PyTorch/XLA SPMD User Guide", "Distributed Checkpointing", "Running SPMD on GPU"], "terms": {"For": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33], "inform": [0, 1, 3, 4, 11, 13, 15, 16, 17, 18, 19, 20, 29, 33], "googl": [0, 1, 8, 16, 17], "cloud": [0, 1, 2, 4, 6, 12, 16, 17, 24, 32], "see": [0, 1, 2, 3, 4, 5, 6, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 29], "machin": [0, 2, 4, 16, 18, 19, 33], "type": [0, 4, 6, 10, 13, 16, 17, 18, 19, 21, 23], "ar": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32], "custom": [1, 3, 4, 7, 9, 10, 12, 13, 20, 23, 26, 28, 29, 30, 31], "design": [1, 9, 16, 17, 24, 27, 31], "ai": [1, 19], "acceler": [1, 4, 13, 14, 16, 17, 19, 21], "which": [1, 2, 3, 5, 6, 7, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 24, 26, 27, 29, 30, 32], "optim": [1, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 29], "train": [1, 8, 9, 13, 14, 17, 18, 19, 21, 22, 30, 32, 33], "infer": [1, 3, 13, 16, 21, 30, 33], "larg": [1, 9, 14, 16, 19, 20, 26, 29, 31], "model": [1, 3, 5, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33], "thei": [1, 2, 5, 6, 7, 13, 16, 17, 18, 19, 20, 21, 29, 30, 31], "ideal": [1, 2, 3, 20, 24, 29], "varieti": 1, "us": [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 18, 19, 21, 24, 26, 30, 32, 33], "case": [1, 2, 3, 5, 9, 10, 13, 16, 17, 18, 19, 22, 24, 27, 30], "chatbot": 1, "code": [1, 3, 5, 9, 10, 11, 13, 15, 16, 17, 18, 20, 22, 23, 24, 29, 30], "gener": [1, 5, 13, 15, 16, 17, 18, 19, 20, 29], "media": 1, "content": [1, 13], "synthet": 1, "speech": 1, "vision": [1, 26], "servic": [1, 2, 16], "recommend": [1, 2, 3, 4, 5, 13, 15, 16, 17, 21, 30], "engin": [1, 18], "person": 1, "among": 1, "other": [1, 2, 3, 5, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 31], "scale": [1, 10, 13, 16, 21, 22, 24, 31], "cost": [1, 22, 24], "effici": [1, 9, 10, 18, 19, 24, 31], "wide": [1, 5, 20, 29], "rang": [1, 5, 9, 13, 16, 22, 27, 30, 31], "workload": [1, 16, 17, 18, 30, 31], "span": [1, 3], "fine": 1, "tune": [1, 30, 31], "provid": [1, 2, 3, 5, 6, 8, 13, 17, 18, 19, 20, 21, 24, 25, 26, 28, 29, 30, 31, 32], "versatil": 1, "lead": [1, 9, 18, 19, 22], "framework": [1, 12, 15, 20, 28, 29], "includ": [1, 2, 5, 13, 16, 18, 19, 20, 21, 25, 29, 31, 32], "pytorch": [1, 5, 9, 11, 14, 15, 16, 20, 21, 22, 23, 25, 28, 32, 33], "jax": [1, 6, 8, 9, 10, 16], "tensorflow": [1, 2, 6, 13, 16, 18, 20, 29], "seamlessli": 1, "orchestr": 1, "through": [1, 3, 5, 6, 7, 8, 9, 17, 19, 20, 21, 29, 32], "integr": [1, 11, 12, 27, 28, 31], "kubernet": 1, "gke": 1, "leverag": [1, 11, 33], "dynam": [1, 3, 5, 12, 18, 19, 24], "schedul": [1, 19], "improv": [1, 9, 16, 17, 18, 19, 21, 24, 30, 31], "scalabl": 1, "all": [1, 2, 3, 5, 7, 9, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 32], "need": [1, 2, 3, 5, 10, 13, 16, 17, 18, 19, 20, 23, 26, 27, 29, 30, 31], "simultan": [1, 31], "look": [1, 3, 5, 9, 17, 18, 19, 30], "simplest": [1, 31], "wai": [1, 2, 5, 7, 8, 10, 13, 16, 17, 19, 20, 23, 24, 28, 29, 30, 31], "develop": [1, 2, 11, 12, 15, 17, 23, 24, 28, 31], "can": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33], "also": [1, 2, 3, 5, 6, 7, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 28, 29, 30, 31], "vertex": 1, "fulli": [1, 12, 15, 16, 18, 31], "manag": [1, 8, 13, 21, 32], "platform": 1, "more": [1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 22, 29, 30, 31, 33], "introduct": [1, 8], "set": [1, 2, 7, 13, 16, 18, 19, 20, 21, 24, 26, 29, 30, 31, 32], "up": [1, 2, 3, 16, 17, 19, 20, 24, 27, 29], "environ": [1, 2, 12, 16, 17, 19, 23, 30, 31, 32], "resourc": [1, 13, 18], "i": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32], "free": [2, 5, 10, 14, 18, 21, 23, 26], "softwar": [2, 18], "tool": [2, 5, 19, 26, 31], "autom": 2, "openxla": [2, 6, 10, 15, 24, 28], "both": [2, 4, 5, 7, 16, 19, 20, 21, 24, 26, 27, 28, 29, 31, 32], "make": [2, 4, 10, 11, 15, 16, 17, 18, 19, 20, 23, 24, 29, 30], "good": [2, 3, 5, 19, 20, 29, 30], "fit": [2, 3, 19, 26], "well": [2, 3, 6, 13, 16, 19, 20, 29, 31], "extern": [2, 4, 8], "seen": [2, 19, 24], "workspac": [2, 18], "file": [2, 4, 9, 13, 16, 18, 19, 21, 22, 23], "http_archiv": 2, "name": [2, 4, 5, 13, 16, 18, 20, 27, 29, 30, 31], "org_tensorflow": 2, "strip_prefix": 2, "f7759359f8420d3ca7b9fd19493f2a01bd47b4ef": 2, "url": 2, "http": [2, 3, 4, 8, 9, 10, 11, 13, 16, 18, 19, 26, 30], "github": [2, 3, 4, 5, 9, 11, 13, 16, 18, 19, 23, 26, 30], "com": [2, 3, 4, 8, 9, 11, 13, 16, 18, 19, 26, 30], "archiv": 2, "tar": 2, "gz": 2, "pin": [2, 13], "updat": [2, 3, 7, 10, 17, 19, 20, 21, 29, 30], "point": [2, 3, 4, 5, 6, 13, 19, 20, 21, 29], "thi": [2, 3, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33], "repositori": [2, 16], "differ": [2, 3, 6, 13, 17, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31], "revis": 2, "patch": [2, 18], "mai": [2, 3, 6, 9, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31], "ad": [2, 5, 10, 13, 17, 19, 20, 22, 24, 25, 29, 30], "resolv": 2, "prepar": 2, "hermet": 2, "mechan": 2, "deploi": 2, "becaus": [2, 3, 9, 15, 16, 17, 19, 21, 22, 30], "local": [2, 4, 13, 16, 17, 18, 30], "checkout": [2, 9, 18], "ha": [2, 3, 4, 5, 8, 9, 10, 13, 15, 16, 17, 19, 20, 29, 30, 31], "built": [2, 4, 31], "from": [2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32], "sourc": [2, 3, 5, 6, 9, 12, 13, 18], "instal": [2, 3, 4, 5, 6, 8, 11, 16, 18, 19], "system": [2, 31], "version": [2, 3, 4, 8, 16, 19, 21, 22, 30], "compat": [2, 16, 28, 32], "e": [2, 4, 6, 7, 10, 13, 14, 16, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31], "g": [2, 4, 6, 7, 10, 13, 14, 16, 18, 19, 20, 22, 28, 29, 30, 31, 32], "codegen": [2, 5, 12], "torchgen": [2, 3], "python": [2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 23, 24, 29, 30], "modul": [2, 8, 9, 10, 13, 17, 18, 23, 26, 27, 30], "should": [2, 3, 4, 5, 6, 11, 13, 15, 16, 17, 18, 19, 20, 21, 25, 26, 29, 30, 31, 32], "The": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33], "directori": [2, 3, 5, 9], "either": [2, 5, 7, 13, 16, 18, 20, 21, 29], "bzl": 2, "overriden": 2, "command": [2, 3, 4, 9, 16, 17, 18, 19, 23, 26], "line": [2, 3, 10, 13, 15, 17, 18, 19, 20, 26, 29], "override_repositori": 2, "path": [2, 6, 13, 17, 18, 20, 26, 29], "export": [2, 3, 4, 5, 12, 16, 18, 19], "tf_repo": 2, "torch_repo": 2, "pleas": [2, 3, 5, 7, 13, 16, 17, 18, 19, 21, 26, 27, 28, 30, 33], "sure": [2, 17, 18], "overridden": [2, 3], "appropri": [2, 19], "been": [2, 5, 13, 16, 17, 19, 20, 29, 30], "use_cuda": 2, "0": [2, 3, 4, 6, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33], "setup": [2, 3, 6, 10, 17, 23], "py": [2, 3, 4, 5, 7, 9, 11, 14, 15, 16, 17, 18, 19, 22, 23, 26, 30, 33], "bdist_wheel": 2, "expect": [2, 3, 6, 11, 15, 16, 18, 20, 24, 28, 29], "object": [2, 10, 13, 30], "present": [2, 32], "new_local_repositori": 2, "build_fil": 2, "pytorch_local_dir": 2, "header": 2, "directli": [2, 3, 5, 6, 13, 16, 17, 18, 19, 20, 21, 26, 29, 30, 32], "share": [2, 3, 6, 16, 17, 18, 30], "libtorch": 2, "so": [2, 3, 6, 10, 11, 13, 14, 16, 17, 18, 19, 20, 26, 29, 32], "same": [2, 3, 5, 6, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 25, 28, 29, 30, 31, 33], "where": [2, 4, 7, 8, 9, 13, 14, 16, 17, 18, 19, 20, 26, 27, 29, 31], "lib": [2, 6], "contain": [2, 3, 5, 6, 9, 10, 11, 13, 16, 18, 19, 20, 22, 29, 31], "work": [2, 3, 7, 9, 10, 13, 14, 16, 17, 18, 19, 20, 22, 24, 28, 29, 30, 31], "": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 30, 31, 32], "requir": [2, 3, 5, 10, 13, 14, 16, 17, 18, 19, 20, 21, 29, 30, 32, 33], "pass": [2, 5, 9, 10, 11, 13, 16, 19, 21, 22, 30, 31], "isystemextern": 2, "compil": [2, 5, 6, 10, 11, 12, 13, 14, 16, 19, 20, 21, 24, 27, 28, 29, 31, 32], "find": [2, 3, 5, 8, 9, 16, 18, 19, 23, 27], "satisfi": [2, 30], "them": [2, 3, 5, 9, 13, 16, 17, 18, 19, 20, 29, 31], "some": [2, 3, 5, 9, 13, 14, 15, 16, 17, 18, 22, 23, 28, 30, 31], "user": [2, 4, 6, 12, 15, 16, 17, 18, 19, 20, 24, 25, 27, 28, 29, 30, 32], "bring": [2, 3, 27], "pybind11": 2, "embed": [2, 9], "link": [2, 3], "against": [2, 23], "libpython": 2, "instead": [2, 7, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 29, 30, 32], "These": [2, 3, 5, 8, 9, 16, 19, 28, 32], "pybind11_emb": 2, "option": [2, 3, 4, 6, 13, 16, 18, 19, 28, 30, 32], "transit": [2, 17], "simpl": [2, 3, 8, 9, 16, 19, 21, 26, 31], "torch_xla": [2, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "csrc": [2, 5], "runtim": [2, 3, 4, 6, 12, 17, 18, 23, 26, 30, 31, 32], "configr": 2, "via": [2, 4, 12, 16, 25, 26, 27, 30, 31], "bazelrc": 2, "take": [2, 3, 9, 11, 13, 17, 18, 19, 20, 29, 30], "flag": [2, 3, 10, 13, 14, 21], "config": [2, 3, 4, 10], "remote_cach": 2, "configur": [2, 3, 5, 12, 13, 16, 18, 19, 32], "gcloud": [2, 4, 16, 17, 19], "usual": [2, 3, 5, 15, 17, 18], "faster": [2, 16, 19, 20, 22, 24, 29], "authent": [2, 16], "easi": [2, 9, 16, 17, 20, 29], "express": [2, 22, 27, 31], "complex": [2, 11, 22, 24], "lot": [2, 17, 18, 19, 20, 29], "gain": [2, 16], "have": [2, 3, 4, 5, 6, 8, 9, 10, 13, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 29, 30, 32], "singl": [2, 9, 13, 15, 20, 23, 24, 26, 27, 29, 30, 31, 33], "graph": [2, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 29, 30], "everyth": [2, 20, 23, 29], "therefor": [2, 18, 19], "separ": [2, 3, 5, 17, 19, 24, 26, 27], "rest": [2, 16, 18, 20, 29], "plu": [2, 23, 25], "whole": [2, 13, 15, 20, 24, 29], "everythin": 2, "els": [2, 18, 20, 29], "enough": [2, 19, 20, 29], "normal": [2, 3, 16, 20, 27, 29, 30], "achiev": [2, 5, 15, 23, 31], "invok": [2, 3, 24, 30], "standard": 2, "c": [2, 3, 5, 16, 18, 20, 21, 22, 29], "bind": 2, "simpli": [2, 16], "_xlac": [2, 11, 18, 20, 29], "client": [2, 6, 13, 16], "togeth": [2, 15, 16, 17, 23, 26, 30, 31], "when": [2, 3, 5, 7, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 26, 30, 31, 32], "chang": [2, 5, 14, 17, 18, 19, 20, 21, 23, 28, 29, 30], "abl": [2, 17, 20, 29, 32], "without": [2, 5, 10, 13, 16, 18, 19, 30, 31, 32], "iter": [2, 9, 13, 14, 17, 18, 19, 24, 30], "cycl": 2, "come": [2, 13, 20, 29], "There": [2, 3, 10, 15, 17, 18, 19, 20, 23, 24, 29, 30], "plenti": 2, "backend": [2, 3, 7, 13, 15, 16, 20, 24, 25, 28, 29, 30, 32], "we": [2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33], "our": [2, 3, 4, 5, 6, 7, 8, 14, 16, 17, 18, 20, 21, 23, 24, 29, 30, 31], "gc": [2, 32], "storag": [2, 4, 8, 17, 18, 19, 26, 32], "you": [2, 4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 26, 27, 30, 31, 33], "under": [2, 3, 5, 9, 13, 16, 17, 23], "disabl": [2, 13, 15, 18, 19], "default": [2, 5, 10, 13, 15, 16, 17, 18, 19, 21, 26, 30, 32], "speed": [2, 9, 19, 20, 24, 29], "increment": [2, 3], "huge": [2, 18, 19, 20, 23, 29], "margin": 2, "almost": 2, "alwai": [2, 16, 17, 18, 20, 29, 31], "enabl": [2, 11, 13, 14, 15, 18, 19, 21, 23, 28, 30, 31, 32], "ci": [2, 5], "To": [2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 15, 16, 18, 19, 20, 26, 27, 29, 30, 32, 33], "ensur": [2, 9, 13, 20, 22, 27, 29, 30, 32], "credenti": 2, "auth": [2, 16], "applic": [2, 18, 28, 32], "login": [2, 19], "launch": [2, 13, 16, 17, 19, 23, 24, 26], "browser": 2, "gcp": [2, 4, 16], "variou": [2, 11], "individu": [2, 26, 27, 31], "who": [2, 23], "access": [2, 3, 5, 8, 13, 16, 17, 18, 19, 20, 29, 32], "project": [2, 4, 6, 16, 17, 19], "one": [2, 3, 5, 8, 9, 13, 16, 17, 18, 19, 20, 24, 25, 26, 27, 29, 30, 31, 33], "onli": [2, 3, 5, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 29, 31, 32], "specifi": [2, 7, 10, 13, 17, 19, 26, 30, 31], "google_default_credenti": 2, "token": [2, 15, 19, 28], "out": [2, 5, 9, 13, 14, 15, 16, 17, 18, 19, 21, 24, 30], "box": [2, 5, 30], "log": [2, 18, 19], "permiss": 2, "add": [2, 3, 5, 11, 13, 17, 18, 19, 20, 24, 25, 26, 29], "new": [2, 3, 4, 5, 7, 15, 17, 18, 19, 20, 24, 29, 30], "role": 2, "In": [2, 3, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 29, 30, 31, 32], "account": [2, 19], "kei": [2, 4, 6, 9, 16, 18, 19, 32], "google_credenti": 2, "On": [2, 16, 32], "docker": 2, "network": [2, 13, 16, 17, 18, 21, 30, 31], "cloudbuild": 2, "down": [2, 5, 19], "imag": [2, 16, 19, 20, 23, 26, 29], "do": [2, 3, 5, 10, 12, 14, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30], "doe": [2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31], "read": [2, 4, 5, 13, 16, 30], "write": [2, 5, 11, 13, 17, 31], "silo": 2, "each": [2, 3, 5, 7, 11, 13, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 30, 31, 32], "uniqu": [2, 17, 19, 20, 22, 29], "benefit": [2, 19, 27, 28, 32], "consist": [2, 7, 16], "remote_default_exec_properti": 2, "some_silo_kei": 2, "bazel_remote_cach": 2, "1": [2, 4, 6, 7, 8, 9, 10, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33], "silo_nam": 2, "your": [2, 3, 6, 9, 16, 17, 18, 19, 20, 22, 23, 27, 29, 30, 31, 32], "tpuvm_mod": 2, "gcloud_service_key_fil": 2, "application_default_credenti": 2, "json": 2, "might": [2, 3, 5, 13, 17, 18, 19, 20, 29], "help": [2, 9, 18, 19, 20, 29], "too": [2, 18, 20, 29], "cannot": [2, 8, 9, 19, 20, 21, 26, 29], "here": [2, 3, 5, 8, 10, 14, 17, 19, 20, 23, 24, 26, 27, 29, 30, 31, 32], "author": 2, "usernam": 2, "behavior": [2, 3, 5, 16, 17, 18, 21, 22], "function": [2, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 18, 19, 24, 25, 27, 28, 32], "intend": 2, "first": [2, 3, 4, 9, 10, 11, 13, 14, 16, 18, 19, 23, 30, 31, 32, 33], "time": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 22, 24, 25, 29, 30], "slow": [2, 9, 18, 19], "scratch": [2, 3], "veri": [2, 6, 8, 9, 15, 17, 19, 20, 29], "fast": [2, 20, 29], "onc": [2, 7, 13, 17, 18, 19, 20, 22, 24, 29, 30], "again": [2, 3, 17, 19], "bit": [2, 17, 28], "slower": [2, 9, 18, 19, 23], "per": [2, 13, 16, 17, 18, 21, 23, 24, 28], "until": [2, 13, 17, 19, 32], "next": [2, 9, 13, 18, 19, 20, 28, 29, 30], "quit": 2, "current": [2, 6, 8, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 27, 28, 29, 30, 33], "migrat": [2, 12, 16], "futur": [2, 3, 4, 6, 14, 16, 17, 18, 19, 20, 22, 27, 29], "plafrom": 2, "cpp": [2, 5], "main": [2, 3, 4, 7, 10, 11, 15, 16, 30], "Of": 2, "cours": 2, "pjrt": [2, 12, 13, 17, 30], "Not": 2, "environment": 2, "variabl": [2, 4, 14, 16, 19, 20, 29], "miss": [2, 5, 13, 18], "common": [2, 16, 20, 27, 28, 29, 31, 32], "part": [2, 3, 6, 11, 13, 15, 16, 18, 19, 30], "ones": [2, 13, 20, 29], "helper": [2, 3, 13], "script": [2, 3, 4, 8, 16, 17, 18, 19, 21, 23, 33], "run_test": 2, "sh": 2, "r": [2, 19], "xla_client": 2, "pure": [2, 3, 22], "easili": [2, 5, 20, 24, 29], "execut": [2, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 29, 30, 31, 33], "parallel": [2, 12, 13, 16, 18, 23, 30, 31], "sinc": [2, 3, 5, 16, 17, 18, 19, 20, 21, 23, 24, 27, 29, 32], "xrt": [2, 13], "port": [2, 16, 33], "gpu": [2, 5, 6, 8, 12, 14, 18, 19, 30], "tpu": [2, 3, 5, 6, 8, 9, 12, 13, 14, 18, 23, 24, 25, 31, 32, 33], "devic": [2, 3, 4, 5, 6, 7, 9, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 28, 29, 32], "avail": [2, 13, 16, 17, 18, 19, 20, 26, 29, 33], "reason": [2, 3, 5, 15, 16, 19, 23], "bundl": 2, "target": [2, 15, 16, 17, 19, 20, 21, 24, 29], "sequenti": [2, 13], "calcul": 2, "visual": [2, 30, 31], "lcov": 2, "describ": [2, 3, 4, 10, 13, 17, 19, 21, 23, 31], "document": [2, 3, 4, 5, 6, 10, 16, 17, 21, 22, 23, 28], "editor": 2, "choic": [2, 20, 29], "gutter": 2, "vscode": 2, "power": 2, "like": [2, 3, 4, 5, 8, 9, 10, 13, 16, 17, 18, 19, 20, 21, 26, 29, 30], "clangd": 2, "refer": [2, 3, 5, 7, 8, 11, 13, 14, 16, 17, 26, 28, 30, 31, 33], "autocomplet": 2, "semant": [2, 5, 18, 20, 29], "understand": [2, 10, 19, 20, 29], "underli": [2, 13, 17, 31], "stack": [2, 9, 17, 18, 20, 21, 29, 30], "combin": [2, 5, 9, 13, 20, 22, 29], "studio": 2, "extens": [2, 4, 5, 6], "featur": [2, 8, 10, 14, 16, 18, 23, 27, 30, 31, 32], "assist": 2, "edit": 2, "As": [2, 3, 10, 19, 20, 22, 27, 29], "distutil": 2, "ltc": 3, "lazi": [3, 18, 19, 20, 24, 29, 30], "tensor": [3, 5, 7, 9, 10, 13, 14, 16, 19, 21, 24, 25, 27, 28, 30, 31], "core": [3, 5, 7, 13, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 31], "clean": [3, 18, 24], "exist": [3, 13, 15, 16, 17, 18, 24, 30], "stub": 3, "over": [3, 9, 13, 15, 16, 17, 19, 26, 31, 32], "6": [3, 4, 5, 9, 13, 18, 19, 20, 29, 31], "were": [3, 17, 18, 19, 20, 29], "complet": [3, 13, 17, 18], "process": [3, 5, 6, 7, 11, 13, 15, 16, 18, 19, 23, 26, 28], "found": [3, 16, 19], "ref": [3, 4, 16], "oper": [3, 7, 9, 11, 12, 13, 16, 17, 19, 22, 31, 32], "xla_native_funct": [3, 5], "yaml": [3, 5], "blob": [3, 7, 9, 11, 13, 16, 30], "master": [3, 9, 13, 16, 17, 32], "_": [3, 9, 16, 24, 25], "replac": [3, 9, 19, 25], "support": [3, 6, 8, 9, 10, 11, 13, 14, 16, 20, 22, 24, 25, 26, 29, 30, 32, 33], "an": [3, 4, 5, 6, 7, 8, 9, 10, 13, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32], "equival": 3, "full_codegen": 3, "NOT": 3, "introduc": [3, 7, 8, 15, 16, 18, 19, 22, 23, 30], "ani": [3, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33], "purpos": [3, 5, 9, 28], "info": [3, 13, 18, 20, 29, 31], "about": [3, 4, 15, 16, 17, 19, 20, 29, 31], "dispatch": [3, 5, 32], "exyang": 3, "blog": [3, 22], "post": [3, 13, 18, 22], "follow": [3, 5, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 23, 26, 27, 29, 30, 31, 33], "instruct": [3, 5, 19], "depend": [3, 4, 5, 14, 15, 17, 19, 20, 21, 22, 29, 31], "build": [3, 5, 17, 19, 26], "It": [3, 4, 5, 7, 13, 14, 15, 17, 19, 20, 24, 26, 27, 28, 29, 30, 31], "experi": [3, 5, 15, 16, 23, 32], "workstat": [3, 5], "cpu": [3, 5, 7, 13, 18, 19, 20, 26, 28, 29, 30, 32], "pjrt_devic": [3, 5, 6, 14, 16, 17, 18, 23, 25, 33], "re": [3, 13, 15, 16, 18, 19, 20, 21, 22, 25, 27, 29], "familiar": [3, 17, 27], "issu": [3, 5, 9, 13, 15, 16, 17, 18, 19, 21, 23, 27], "3560": 3, "track": [3, 18, 32], "statu": [3, 18], "put": [3, 5, 17, 18, 23], "alia": [3, 7, 13], "avoid": [3, 18, 19, 21], "duplic": 3, "mention": [3, 5, 20, 24, 29], "below": [3, 5, 7, 10, 15, 16, 19, 20, 21, 29, 32, 33], "live": [3, 5, 13, 20, 29], "folder": [3, 4, 5], "except": [3, 5, 19, 30], "torch": [3, 4, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "shape_infer": 3, "shape": [3, 5, 8, 9, 10, 11, 12, 13, 18, 19, 22, 25, 30, 31], "defin": [3, 5, 8, 10, 11, 13, 19, 21, 25, 27, 30, 31], "input": [3, 5, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 27, 30, 31, 32], "return": [3, 5, 6, 7, 8, 9, 10, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 28, 29, 30, 32], "output": [3, 4, 7, 8, 9, 10, 11, 13, 16, 17, 18, 21, 22, 23, 24, 25, 26, 30], "manual": [3, 5, 8, 15, 18, 26], "gen_lazy_tensor": 3, "data": [3, 7, 12, 13, 15, 16, 17, 19, 20, 21, 24, 29, 31, 32], "aten": [3, 5, 10, 18, 20, 29], "specif": [3, 9, 13, 17, 19, 21, 23, 28, 31], "run_gen_lazy_tensor": 3, "dest": 3, "lazy_ir": 3, "class": [3, 6, 7, 9, 10, 13, 22, 23, 26, 28, 31, 32], "genlazyir": 3, "back": [3, 5, 13, 17, 18, 19, 30], "todai": [3, 14], "most": [3, 6, 13, 16, 18, 24], "categori": [3, 27], "goal": [3, 4, 5, 7, 15], "move": [3, 13, 16, 18, 20, 22, 23, 29, 32], "necessari": [3, 13, 18, 21], "call": [3, 5, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 29, 30, 32], "upstream": [3, 7, 14, 22, 24], "api": [3, 5, 10, 12, 16, 17, 20, 23, 24, 26, 28, 29, 30, 31, 32], "xlanativefunct": [3, 5], "column": 3, "declar": [3, 5], "anoth": [3, 14, 17, 18, 19, 20, 29], "wrap": [3, 5, 6, 8, 13, 15, 17, 19, 21, 22, 23, 26, 27, 28, 30], "around": [3, 16, 20, 26, 29, 31], "xlatensor": [3, 5, 13, 30], "construct": [3, 5, 17, 19, 26, 30, 31, 32], "aten_xla_typ": [3, 5], "Will": 3, "method": [3, 10, 13, 16, 21, 27, 30, 32], "map": [3, 5, 7, 13], "node": [3, 5, 7, 11, 18, 20, 29, 33], "remov": [3, 16, 18, 19], "tensor_method": [3, 5], "possibl": [3, 16, 17, 18, 19, 26, 27, 30], "multipl": [3, 7, 13, 15, 20, 24, 28, 29, 31], "few": [3, 17, 18, 19, 20, 23, 29, 32], "simpler": [3, 16], "go": [3, 15, 17, 19, 21, 30], "unari": 3, "binari": [3, 6, 24], "exampl": [3, 4, 5, 6, 7, 10, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 28, 29, 30, 31, 32, 33], "characterist": 3, "fallback": [3, 5], "_adaptive_avg_pool3d": 3, "condit": [3, 20, 25, 29], "issupportedadaptivepool": 3, "xlahelp": 3, "i64list": 3, "self": [3, 5, 6, 7, 9, 10, 13, 19, 22, 23, 28, 30], "size": [3, 7, 9, 11, 14, 16, 17, 18, 19, 20, 29, 31, 32], "output_size_list": 3, "pool_dim": 3, "nativ": [3, 5, 15, 16, 18, 21, 23, 30], "call_fallback_fn": 3, "xla_fallback": 3, "aten_op": 3, "output_s": 3, "wip": 3, "evolv": 3, "At": [3, 6, 13], "self_tensor": 3, "static": [3, 14, 20, 29], "bool": [3, 13], "sync_upd": 3, "sys_util": 3, "getenvbool": 3, "xla_tensor_update_sync": 3, "true": [3, 13, 15, 16, 19, 20, 23, 26, 29, 30, 32], "xla_check": 3, "dst_tensor": 3, "updatefromtensor": 3, "sync": [3, 13, 15, 18, 19, 21], "complic": [3, 5, 8], "would": [3, 4, 5, 9, 13, 16, 17, 18, 19, 20, 25, 29], "someth": [3, 9, 19], "ab": [3, 26], "const": [3, 5, 7], "torch_lazy_fn_count": 3, "bridg": [3, 24], "atenfromxlatensor": 3, "getxlatensor": 3, "fail": [3, 13, 17, 18, 32], "explain": [3, 6, 17, 18, 19, 20, 22, 29, 31], "later": [3, 19, 22], "still": [3, 7, 16, 17, 20, 21, 23, 29, 32], "If": [3, 4, 5, 9, 13, 16, 17, 18, 19, 20, 22, 28, 29, 30, 31], "while": [3, 7, 9, 10, 13, 19, 20, 23, 29], "error": [3, 10, 13, 17, 18], "involv": [3, 20, 29, 30], "problem": [3, 9, 20, 29], "yet": [3, 5, 7], "attempt": [3, 32], "unblock": [3, 32], "snippet": [3, 17, 30, 31], "auto": [3, 5, 13, 26, 32], "common_devic": 3, "getxladevic": 3, "torch_internal_assert": 3, "xlatensorptr": 3, "lazy_self": 3, "getxlatensororcreateforwrappednumb": 3, "nodeptr": 3, "reusenod": 3, "getirvalu": 3, "makenod": 3, "cachenod": 3, "creat": [3, 10, 11, 13, 16, 18, 19, 21, 22, 23, 30, 31, 32], "std": [3, 7, 23], "get": [3, 5, 13, 14, 15, 16, 19, 20, 23, 26, 28, 29], "check": [3, 4, 5, 10, 13, 17, 28, 31], "reus": [3, 9, 17, 19, 21, 22], "previou": [3, 16, 17, 19, 20, 29, 31], "creation": [3, 13], "correspond": [3, 5, 7, 13, 19, 21, 26, 30, 31], "cach": [3, 8, 13, 14, 19, 22], "newli": 3, "And": [3, 20, 23, 29, 30], "within": [3, 13, 17, 18, 19, 28, 31, 32], "note": [3, 4, 7, 8, 11, 13, 15, 16, 17, 18, 19, 20, 24, 26, 27, 28, 29, 31], "done": [3, 4, 8, 17, 18, 19, 20, 29], "public": [3, 16], "xlanod": 3, "xlavalu": 3, "opkind": [3, 5], "absoutputshap": 3, "num_output": [3, 20, 29], "mhash": 3, "string": [3, 7, 13, 30], "tostr": 3, "overrid": [3, 13, 21], "stringstream": 3, "ss": 3, "str": [3, 6, 10, 13], "xlaopvector": 3, "loweringcontext": 3, "loctx": 3, "A": [3, 4, 6, 13, 16, 17, 19, 20, 21, 27, 28, 29, 30, 31], "coupl": [3, 17, 18], "thing": [3, 18, 19, 22], "keep": [3, 4, 14, 16, 18, 20, 29], "mind": [3, 16, 18], "clone": [3, 16, 18, 19], "even": [3, 13, 16, 17, 18, 20, 22, 23, 29], "everi": [3, 5, 8, 9, 13, 16, 17, 18, 20, 22, 24, 29, 30, 32], "outputshap": 3, "xla_shap": 3, "overli": 3, "simplifi": 3, "buildxxxop": 3, "slightli": [3, 5, 13], "better": [3, 5, 15, 16, 17, 18, 19, 20, 24, 25, 29], "maximumoutputshap": 3, "lower_for_shape_fn": 3, "absl": 3, "xlaop": [3, 5], "operand": 3, "promot": 3, "max": [3, 20, 29, 32], "second": [3, 9, 10, 11, 14, 16, 18, 19, 23, 31, 33], "inferoutputshap": 3, "comput": [3, 4, 13, 16, 17, 18, 19, 20, 21, 22, 29, 30, 31], "logic": [3, 9, 13, 15, 20, 25, 29, 30, 31], "two": [3, 6, 13, 16, 18, 19, 20, 29, 30, 31], "xla_input": 3, "getoutputop": 3, "returnop": 3, "buildab": 3, "origin": [3, 19], "genericop": 3, "modifi": [3, 19, 21, 24, 30], "abov": [3, 5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 29, 31], "delet": 3, "sometim": [3, 19, 20, 29], "being": [3, 13, 17, 19, 23, 31], "tensor_op": 3, "cross": [3, 13, 17, 30], "s1": [3, 30], "sub": 3, "mul": [3, 20, 29], "u2": 3, "v3": [3, 17, 23], "u3": 3, "v2": [3, 4, 17], "irnod": 3, "those": [3, 5, 13, 18, 19, 23], "long": [3, 9, 15, 18, 19, 20, 23, 29], "term": [3, 11, 15, 18, 20, 29], "rid": [3, 20, 29], "composit": [3, 5], "end": [3, 5, 11, 13, 14, 16, 17, 18, 19, 23, 26, 27], "exp": 3, "pow": 3, "norm_exp": 3, "vector": [3, 11], "don": [3, 5, 14, 15, 16, 17, 18, 20, 26, 29], "t": [3, 5, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 29, 30, 31, 32], "build_cpp_test": 3, "skip": [3, 5, 18, 24], "desir": [3, 19, 31, 32], "test_ptxla": 3, "gtest_filt": 3, "atenxlatensortest": 3, "testab": 3, "correct": [3, 20, 22, 29], "counter": [3, 5, 13, 18], "correctli": [3, 18, 27], "bitwise_left_shift": 3, "pull": [3, 21, 23, 26], "8865": 3, "gt": [3, 4, 10, 16, 19], "erf": 3, "erfc": 3, "erfinv": 3, "3659": 3, "binary_cross_entropi": [3, 21], "backward": [3, 5, 9, 15, 16, 17, 21, 23, 24, 26, 27], "3809": 3, "scalar": [3, 5, 18, 20, 29], "addcdiv": 3, "addcmul": 3, "3768": 3, "neg": 3, "index": [3, 4, 6, 8, 13, 16, 17, 18, 19, 31, 33], "amin": 3, "amax": 3, "3771": 3, "special": [3, 10, 11, 19, 30], "partial": [3, 20, 26, 27, 29], "adaptive_avgpool3d": 3, "3790": 3, "guid": [4, 8, 12, 16, 17, 19, 26, 27, 30], "interact": [4, 16], "start": [4, 15, 16, 17, 18, 19], "colab": [4, 18], "kaggl": 4, "preinstal": [4, 16], "ecosystem": [4, 28], "packag": [4, 11, 12, 17, 19, 21, 23], "date": 4, "list": [4, 5, 9, 13, 19, 21, 22, 25, 30, 31], "readm": [4, 18, 19], "prerequisit": 4, "remot": 4, "quota": 4, "request": [4, 5, 13, 18, 19, 20, 21, 23, 29, 30, 31], "offici": [4, 18], "ssh": [4, 16, 17, 19], "regist": [4, 5, 6, 7, 10, 16, 32], "agent": 4, "alreadi": [4, 8, 11, 13, 18, 19, 20, 23, 26, 29, 32], "befor": [4, 7, 8, 13, 16, 17, 18, 19, 20, 21, 23, 24, 27, 29, 30, 32], "begin": [4, 17, 30], "zone": [4, 16, 17, 19], "tpu_typ": 4, "8": [4, 10, 11, 13, 15, 16, 17, 19, 20, 23, 24, 28, 29, 30, 31], "vm": [4, 16, 17, 18, 19, 23], "assum": [4, 6, 8, 13, 17, 20, 23, 27, 29, 30, 31], "id_ed25519": 4, "ubuntu2204": 4, "base": [4, 7, 13, 15, 16, 18, 19, 20, 22, 26, 29, 30, 31], "metadata": [4, 18], "cat": [4, 21], "pub": 4, "ip": [4, 13, 16, 32, 33], "format": [4, 10, 13, 18, 19, 24, 28], "valu": [4, 5, 9, 11, 13, 14, 16, 18, 19, 20, 22, 25, 29, 30, 33], "networkendpoint": 4, "accessconfig": 4, "externalip": 4, "123": 4, "give": [4, 18, 19, 28, 30, 31], "friendli": 4, "easier": [4, 15, 19, 20, 29], "echo": 4, "host": [4, 13, 16, 17, 18, 19, 21, 26, 32, 33], "n": [4, 13, 23, 28, 31], "hostnam": 4, "test": [4, 6, 8, 11, 14, 16, 22, 23, 26, 33], "v": [4, 8, 9, 10, 16, 20, 22, 29], "palett": 4, "select": [4, 13, 16, 32], "visualstudio": 4, "doc": [4, 8, 9, 13, 15, 16, 17, 20, 27, 29, 30], "__": [4, 16], "just": [4, 8, 15, 16, 17, 20, 23, 26, 29, 32], "titl": [4, 16], "open": [4, 5, 6, 16, 18], "window": 4, "termin": [4, 32], "mkdir": 4, "ptxla": 4, "Then": [4, 10, 19], "ui": 4, "venv": 4, "virtual": [4, 13], "latest": [4, 8, 9], "releas": [4, 6, 7, 8, 9, 16, 17, 18, 19, 24, 26, 27, 28, 30], "pip": [4, 8, 11, 19], "numpi": [4, 8, 10, 13, 19, 31], "f": [4, 8, 10, 13, 17, 23, 26, 28, 32], "googleapi": [4, 8, 19], "libtpu": [4, 6, 16], "wheel": [4, 19, 26], "html": [4, 8, 9, 16, 26], "import": [4, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32], "set_device_typ": 4, "print": [4, 9, 10, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 29, 30, 32], "real_devic": 4, "run": [4, 5, 8, 9, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 28, 29, 31, 32], "2": [4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 22, 24, 25, 26, 28, 30, 31, 33], "3": [4, 5, 6, 8, 9, 10, 11, 13, 15, 18, 19, 24, 25, 26, 28, 30, 31], "4": [4, 6, 8, 9, 10, 13, 16, 17, 18, 19, 20, 24, 25, 26, 28, 29, 30, 31], "5": [4, 7, 9, 13, 14, 18, 19, 20, 22, 23, 26, 28, 29, 31], "7": [4, 13, 18, 23, 24, 31], "number": [4, 11, 13, 14, 15, 16, 18, 19, 22, 26, 30, 31], "vari": [4, 16, 20, 27, 29], "That": [4, 9, 20, 22, 29], "now": [4, 7, 10, 11, 15, 16, 17, 19, 20, 29, 30], "realist": 4, "librari": [5, 6, 10, 19, 31, 32], "offer": [5, 10, 27, 28], "implement": [5, 7, 8, 9, 15, 16, 18, 20, 24, 26, 27, 29], "xla": [5, 9, 10, 11, 14, 15, 16, 20, 22, 23, 25, 27, 32, 33], "its": [5, 7, 14, 16, 17, 18, 22, 23, 24, 26, 30, 31], "convert": [5, 10, 13, 17, 22, 23], "higher": [5, 9, 18, 32], "level": [5, 9, 18, 19, 24, 28, 32], "represent": [5, 9, 13, 17, 19], "hlo": [5, 9, 13, 17, 18, 19], "beyond": 5, "scope": 5, "forward": [5, 10, 15, 21, 22, 23, 24, 27, 28], "haven": [5, 20, 29], "caus": [5, 13, 15, 16, 17, 18, 19, 20, 21, 29], "signific": [5, 18, 19, 24], "slowdown": [5, 18, 23], "must": [5, 6, 7, 9, 13, 16, 17, 18, 22, 27, 32, 33], "best": [5, 8, 24, 28, 31], "perform": [5, 7, 8, 10, 11, 13, 15, 17, 21, 22, 23, 24, 26, 28, 30], "what": [5, 17, 19, 22], "debug": [5, 15, 20, 28, 29, 31], "pt": [5, 16, 17, 18, 19], "profil": [5, 16], "_ctc_loss": [5, 18], "_ctc_loss_backward": [5, 18], "contribut": 5, "definit": [5, 17, 20, 29], "native_funct": 5, "after": [5, 7, 9, 13, 16, 17, 18, 19, 20, 25, 29, 30], "kernel": [5, 9, 10, 12, 20, 28, 29], "aten_fallback": 5, "h": 5, "search": 5, "repo": [5, 17, 18, 19, 23], "sequenc": [5, 9, 13], "explicitli": [5, 17, 18, 19, 20, 21, 29], "compos": 5, "match": [5, 10, 13, 17, 18], "serv": [5, 19], "interfac": [5, 6, 17, 18, 27, 32], "machineri": [5, 10], "registerxla": 5, "registerautogradxla": 5, "entri": [5, 6], "pytorch_xla": 5, "world": [5, 8, 16, 20, 24, 29, 32], "written": [5, 19, 32], "paramet": [5, 13, 16, 17, 18, 21, 22, 23, 27, 30, 32, 33], "result": [5, 7, 9, 13, 14, 16, 17, 18, 19, 23, 25, 30], "wrapper": [5, 17, 23, 26, 27], "inplac": [5, 13, 30], "ir": [5, 13, 18, 19, 20, 22, 29], "insid": [5, 17, 19, 22, 30], "stand": 5, "intermedi": [5, 9, 16, 18, 19], "smaller": [5, 19, 20, 29], "inherit": 5, "dai": 5, "addit": [5, 6, 11, 16, 17, 18, 19, 21, 23], "unless": [5, 18, 20, 29], "want": [5, 9, 10, 13, 15, 16, 17, 18, 19, 20, 24, 29, 30, 31, 33], "verifi": 5, "test_oper": 5, "test_aten_xla_tensor": 5, "yield": [5, 17, 18], "break": [5, 19, 20, 29], "grasp": 5, "capabl": 5, "how": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 29, 30, 33], "similar": [5, 16, 19, 23, 25, 28], "minim": [5, 19], "pr": [5, 18, 26], "vanilla": 5, "lerp": 5, "variant": [5, 20, 21, 29], "lerp_": 5, "scalar_out": 5, "tensor_out": 5, "prototyp": [5, 30], "weight": [5, 10, 13, 18, 27, 28], "lerp_out": 5, "howev": [5, 8, 9, 10, 18, 19, 30], "namespac": [5, 18], "wrapper_scalar_lerp": 5, "No": [5, 14, 16, 20, 22, 28, 29], "deviceguard": 5, "omit": [5, 16, 31, 33], "anonym": 5, "wrapper_scalar_lerp_": 5, "wrapper_scalar_lerp__tmp": 5, "_copy_from": 5, "m": [5, 7, 10, 20, 22, 26, 29, 31], "impl": [5, 7, 10], "torch_fn": 5, "automat": [5, 6, 12, 13, 16, 17, 18, 19, 20, 26, 29, 31, 32], "u": [5, 16, 18, 19, 20, 24, 29], "explicit": [5, 21, 26], "place": [5, 7, 13, 19, 21, 30, 32], "ll": [5, 9, 20, 29], "interned_str": 5, "symbol": [5, 20, 29], "submit": [5, 18, 19, 21], "team": [6, 24], "direclti": 6, "tf": [6, 18, 20, 29], "close": 6, "expos": [6, 16, 17, 19, 30], "deviceplugin": 6, "handl": [6, 15, 18, 20, 26, 27, 29, 30, 31], "short": [6, 18, 20, 29], "pjrtclient": 6, "mirror": 6, "pjrt_api": 6, "straightforward": [6, 13, 19], "detail": [6, 7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 29, 31], "concret": [6, 20, 29], "placehold": 6, "pjrt_library_path": 6, "extra": [6, 23, 27], "multiprocess": [6, 13, 16, 17], "compon": 6, "least": [6, 19], "cpuplugin": 6, "def": [6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 22, 23, 24, 25, 27, 28], "library_path": 6, "o": [6, 16, 23], "join": [6, 13], "dirnam": 6, "__file__": 6, "pjrt_c_api_cpu_plugin": 6, "identifi": [6, 13, 31, 32], "exmapl": 6, "pyproject": 6, "toml": 6, "torch_xla_cpu_plugin": 6, "With": [6, 8, 14, 16, 20, 24, 29], "initi": [6, 7, 13, 16, 17, 19, 23, 25, 32], "experiment": [6, 8, 9, 11, 12, 14, 15, 16, 17, 22, 23, 24, 25, 27, 30, 32], "state": [6, 9, 13, 26], "becom": [6, 8, 9, 16, 18, 19, 20, 29], "stabl": [6, 16, 26], "xla_model": [7, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 31], "adopt": [7, 20, 29], "traceabl": [7, 9], "commun": [7, 8, 13, 16, 17, 19, 24, 31], "reimplement": [7, 16], "_c10d_function": 7, "figur": [7, 9, 14, 31], "show": [7, 9, 10, 16, 17, 18, 23], "all_reduc": [7, 13, 21], "between": [7, 14, 16, 17, 18, 19, 20, 21, 23, 25, 29, 30], "processgroupxla": 7, "deriv": 7, "processgroup": 7, "xla_backend": [7, 16, 23, 32], "_create_xla_process_group": 7, "prefix_stor": 7, "rank": [7, 13, 16, 23, 26, 31, 32], "timeout": 7, "assert": [7, 23], "xr": [7, 13, 16, 17, 21, 23, 26, 27, 30, 31, 32], "is_spmd": [7, 13], "spmd": [7, 12, 17, 19, 32], "group": [7, 13, 16, 23, 30], "_register_xla_backend": 7, "dist": [7, 16, 23, 32], "register_backend": 7, "allreduc": 7, "all_reduce_opt": 7, "allgath": 7, "output_tensors_list": 7, "input_tensor": 7, "opt": [7, 17], "none": [7, 8, 10, 13, 18, 27, 30, 31], "_mp_fn": [7, 16, 17], "init_process_group": [7, 16, 23, 32], "init_method": [7, 16, 32], "progress": [7, 19], "instanc": [7, 8, 13, 26, 32], "distributed_c10d": 7, "_exception_logg": 7, "all_gath": [7, 13, 16], "tensor_list": 7, "async_op": 7, "fals": [7, 10, 13, 17, 26, 30], "_get_default_group": 7, "certain": [7, 18, 20, 21, 29], "remap": 7, "_functional_collect": 7, "all_reduce_inplac": 7, "eventu": 7, "reach": [7, 13], "rewrit": [7, 19, 20, 29, 30], "reduceop": 7, "group_nam": 7, "torch_library_impl": 7, "four": [7, 19], "align": [7, 15], "signatur": 7, "remain": [7, 17, 19, 20, 29, 33], "restrict": 7, "appli": [7, 9, 13, 21, 26, 27, 32], "usag": [7, 13, 18, 19, 20, 26, 27, 29, 32], "test_collective_ops_tpu": 7, "demonstr": [7, 9, 19, 21, 27, 32], "scenario": [7, 24], "sum": [7, 9, 13, 21, 26, 27], "reduct": [7, 13], "aggreg": 7, "all_gather_into_tensor": 7, "gather": [7, 13, 18, 30], "reduce_scatter_tensor": 7, "reduc": [7, 9, 13, 14, 15, 16, 17, 18, 19, 26], "across": [7, 13, 16, 17, 18, 26, 31], "all_to_all_singl": 7, "output_split_s": 7, "input_split_s": 7, "although": [7, 16, 20, 29], "accept": [7, 30], "argument": [7, 11, 13, 19, 21, 22, 24, 26], "limit": [7, 13, 16, 17], "reflect": [7, 31], "compromis": 7, "maintain": 7, "constraint": [7, 16, 18], "alltoal": [7, 13], "rise": 8, "openai": [8, 11], "triton": [8, 12], "popular": 8, "order": [8, 9, 13, 17, 18, 19, 30, 31], "pariti": 8, "continu": [8, 16, 24], "push": 8, "let": [8, 16, 17, 18, 19, 24, 31], "custom_kernel": 8, "jax_import_guard": 8, "pl": [8, 16, 17, 30], "jnp": [8, 10], "add_vectors_kernel": 8, "x_ref": 8, "y_ref": 8, "o_ref": 8, "x": [8, 9, 10, 11, 13, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31], "y": [8, 9, 10, 11, 13, 18, 19, 20, 22, 26, 27, 28, 29, 30, 31], "jit": [8, 10, 11, 24], "add_vector": 8, "arrai": [8, 10, 13, 19, 27, 31], "pallas_cal": 8, "out_shap": 8, "shapedtypestruct": 8, "dtype": [8, 10, 11, 16, 20, 21, 22, 28, 29], "otherwis": [8, 13, 18, 19, 20, 27, 29], "program": [8, 9, 10, 11, 13, 18, 19, 20, 24, 29, 30, 31], "hang": 8, "lock": 8, "q": [8, 10], "randn": [8, 10, 13, 15, 16, 17, 22, 23, 24, 28, 30, 31], "128": [8, 10, 16, 26, 28, 33], "k": [8, 10, 18], "make_kernel_from_palla": 8, "pt_kernel": 8, "lambda": [8, 22, 26], "liner": 8, "flash": [8, 9, 11], "attent": [8, 9, 10, 11], "besid": 8, "op": [8, 9, 10, 12, 13, 15, 18, 19, 20, 21, 29, 30, 31], "suppor": 8, "flash_attent": 8, "paged_attent": 8, "queri": [8, 16], "squeez": 8, "dim": [8, 9, 13], "key_cach": 8, "value_cach": 8, "context_len": 8, "block_tabl": 8, "pages_per_compute_block": 8, "megacore_mod": 8, "vllm": 8, "util": [8, 10, 12, 13, 17, 18, 23, 26, 27, 28, 31, 32], "effect": [8, 13, 22], "memori": [8, 12, 13, 14, 18, 19, 20, 26, 29], "kv": 8, "proper": [8, 31], "jax_nightly_releas": 8, "jaxlib_nightly_releas": 8, "authorit": 8, "dev": [8, 19, 23], "en": [8, 9, 26], "consid": [9, 16, 19], "mani": [9, 13, 16, 18, 19, 20, 22, 29, 33], "homogen": 9, "layer": [9, 14, 15, 22, 26, 27, 30], "llm": [9, 19], "drop": [9, 14, 18], "loop": [9, 15, 17, 18, 19, 20, 22, 27, 29, 32], "bunch": [9, 10], "decod": [9, 15, 22], "trace": [9, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 29, 30], "subsequ": [9, 19], "significantli": [9, 16, 17, 19], "hand": [9, 17], "lower": [9, 10, 12, 18, 19, 20, 21, 29], "lax": 9, "readthedoc": [9, 26], "io": [9, 16, 26], "_autosummari": 9, "Its": [9, 13], "primari": 9, "hood": 9, "sort": [9, 20, 29], "itself": [9, 11, 13, 26], "typic": [9, 13], "transform": [9, 19, 26, 31], "run_decoder_lay": 9, "hidden_st": 9, "decoder_lay": 9, "unrol": 9, "flat": [9, 31], "shown": [9, 16, 20, 29], "decoder_with_scan": 9, "root": [9, 13, 20, 29], "python3": [9, 14, 16, 17, 18, 19, 22, 26], "train_decoder_only_bas": [9, 15, 18], "decoderwithscan": 9, "dimens": [9, 13, 14, 30, 31], "carri": [9, 20, 29, 30], "along": [9, 13, 26, 31], "fn": [9, 13], "callabl": [9, 13, 26], "tupl": [9, 10, 13, 20, 25, 27, 29, 31], "init": [9, 16, 17, 23, 24, 25], "roughli": 9, "equal": [9, 31], "len": [9, 13, 19], "append": [9, 18], "much": [9, 15, 16, 17, 19, 20, 22, 24, 29], "scan_exampl": 9, "scan_example_cumsum": 9, "cumul": [9, 25], "scan_example_pytre": 9, "pytre": 9, "final": [9, 23, 30], "histori": 9, "15": [9, 19], "count": [9, 13, 18], "mean": [9, 13, 16, 17, 18, 19, 20, 23, 27, 29, 30], "0000": 9, "5000": 9, "particular": [9, 19], "palla": [9, 12], "incompat": 9, "nightli": [9, 18, 19, 26, 30], "bound": 9, "compar": [9, 15, 16, 17, 18, 23, 24, 25], "fact": 9, "than": [9, 16, 18, 20, 23, 26, 29], "due": [9, 16, 18, 19, 33], "less": [9, 16, 20, 24, 29], "situat": 9, "anywai": 9, "save": [9, 13, 18, 22, 26, 32], "chip": [9, 15, 16], "hidden": 9, "256": [9, 16], "num": 9, "50": [9, 18, 19, 25], "head": 9, "2048": [9, 16], "step": [9, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32], "metric": [9, 13, 23], "compiletim": [9, 18], "totalsampl": [9, 18], "accumul": [9, 13], "02m57s694ms418": 9, "595u": 9, "valuer": [9, 18], "02s112ms586": 9, "097u": 9, "rate": [9, 18, 23], "054285": 9, "percentil": [9, 18], "023ms113": 9, "470u": 9, "10": [9, 13, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 29, 32], "20": [9, 14, 17, 18, 23, 28], "54s644ms733": 9, "284u": 9, "80": [9, 18], "01m03s028ms571": 9, "841u": 9, "90": [9, 18], "95": [9, 18], "99": [9, 18, 23], "29s996ms941": 9, "409u": 9, "02s529ms591": 9, "388u": 9, "158152": 9, "018ms636": 9, "571u": 9, "11s983ms003": 9, "171u": 9, "18s995ms301": 9, "667u": 9, "maximum": [9, 13, 14, 19, 28], "1m03": 9, "19": [9, 23, 24], "switch": [9, 17, 18, 20, 23, 29], "7253": 9, "comment": [9, 20, 29], "accomplish": 10, "exportedprogram": 10, "fx": [10, 24], "exported_program_to_stablehlo": 10, "mlir": 10, "torchvis": [10, 15, 24], "torch_xla2": 10, "tx": 10, "resnet18": [10, 15, 24], "sampl": [10, 13, 16, 18], "sample_input": 10, "224": [10, 15], "mlir_modul": 10, "store": [10, 11, 13, 18], "feel": [10, 14, 18, 23], "explor": 10, "org": [10, 13, 16, 26], "tutori": [10, 11, 18, 19, 23, 30], "jfunc": 10, "shapeddtypestruct": 10, "float32": [10, 21], "last": [10, 18, 31], "scaled_dot_product_attent": 10, "decompos": 10, "low": [10, 14, 18], "dure": [10, 13, 18, 19, 24, 26, 30], "captur": [10, 13, 18, 19], "downstream": [10, 21], "ml": [10, 31], "crucial": 10, "geneart": 10, "pattern": [10, 18, 20, 24, 29], "challeng": 10, "prone": 10, "robust": 10, "outlin": [10, 28], "pratic": 10, "scaled_product_attent": 10, "centric": 10, "unittest": 10, "nn": [10, 13, 16, 17, 23, 24, 26, 28, 30], "impl_abstract": 10, "jaten": 10, "jlibrari": 10, "mylib": 10, "basic": [10, 17, 19, 20, 23, 29], "sdpa": 10, "compositeexplicitautograd": 10, "_mylib_scaled_dot_product_attent": 10, "dot": [10, 18], "product": 10, "transpos": [10, 20, 29], "dropout_p": 10, "is_caus": 10, "_mylib_scaled_dot_product_attention_meta": 10, "empty_lik": [10, 11], "decomposit": 10, "register_torch_composit": 10, "softmax": 10, "register_jax_composit": 10, "_aten_softmax": 10, "_softmax": 10, "static_argnum": 10, "librarytest": 10, "testcas": 10, "manual_se": [10, 13, 16], "default_env": 10, "use_torch_native_for_cpu_tensor": 10, "test_basic_sdpa_librari": 10, "customopexampl": 10, "arg": [10, 13, 17, 19, 25, 26], "rand": [10, 20, 29], "32": [10, 13, 18, 19, 31], "64": [10, 15, 24, 26], "module_str": 10, "todo": 10, "produc": [10, 20, 21, 23, 29], "assertin": 10, "__name__": [10, 16, 17, 23], "__main__": [10, 16, 17, 23], "emit": 10, "repres": [10, 13, 16, 20, 29], "region": [10, 13, 15, 18, 21, 30], "th": [10, 31], "high": [11, 14, 19, 23, 28], "deep": [11, 12, 18], "learn": [11, 16], "languag": [11, 22], "empow": 11, "full": [11, 13, 17, 18, 26], "potenti": [11, 13, 16, 18, 27], "given": [11, 13, 18, 19, 20, 22, 23, 26, 29, 31], "add_kernel": 11, "x_ptr": 11, "pointer": 11, "y_ptr": 11, "output_ptr": 11, "n_element": 11, "block_siz": 11, "tl": 11, "constexpr": 11, "element": [11, 13, 20, 27, 29, 30, 31], "01": 11, "l28": 11, "pid": 11, "program_id": 11, "axi": [11, 13, 27, 31], "block_start": 11, "offset": 11, "arang": 11, "mask": [11, 18, 20, 29], "load": [11, 13, 16, 18, 23, 26, 28, 32], "xla_triton": 11, "16": [11, 17, 19, 26, 28, 31], "int64": 11, "grid": 11, "cdiv": 11, "triton_cal": 11, "kwarg": [11, 13, 26, 30], "payload": [11, 13, 16], "regard": [11, 17, 24], "buffer": [11, 13, 22], "_xla_gpu_custom_cal": 11, "dep": 11, "connect": [12, 13, 16, 30], "overview": [12, 31], "eager": [12, 13, 20, 23, 28, 29], "mode": [12, 13, 20, 23, 28, 29, 30, 32], "troubleshoot": 12, "stablehlo": [12, 13], "scan": 12, "scan_lay": 12, "mix": [12, 13, 31], "precis": 12, "advanc": [12, 31], "topic": [12, 31], "distribut": [12, 17, 18, 23, 26, 27, 30, 31], "checkpoint": [12, 16, 19, 26, 31], "distributeddataparallel": [12, 16], "ddp": [12, 16], "torchdynamo": 12, "while_loop": 12, "shard": [12, 13, 32], "quantiz": 12, "recompil": [12, 14, 15, 17, 18, 19], "hardwar": [12, 13, 18, 19, 21], "plugin": [12, 16], "bazel": 12, "int": [13, 16, 20, 22, 29, 30], "device_count": [13, 30], "address": [13, 16, 30, 33], "wait": [13, 18, 19], "pend": [13, 15], "whether": [13, 17, 21], "block": [13, 19, 26, 30], "finish": [13, 19], "full_graph": 13, "num_different_graphs_allow": 13, "lazytensor": [13, 15, 19], "happen": [13, 15, 16, 17, 18, 19, 20, 29], "decid": [13, 18, 20, 22, 29], "funciton": 13, "act": [13, 17], "context": [13, 16, 18, 20, 21, 29], "throw": [13, 17], "exit": [13, 18, 21, 23], "pt_xla_debug": 13, "messag": [13, 18], "dump": [13, 18], "allow": [13, 17, 18, 19, 21, 30, 31, 32], "rais": [13, 18], "exceed": 13, "foo": 13, "sin": [13, 22], "co": 13, "foo2": 13, "compiled_foo2": 13, "seed": 13, "random": [13, 15, 16, 19, 22, 28], "integ": [13, 18, 31], "rng": [13, 16], "device_typ": 13, "local_process_count": 13, "local_device_count": 13, "total": [13, 20, 29, 31], "addressable_device_count": 13, "visibl": [13, 20, 29], "global_device_count": 13, "global_runtime_device_count": [13, 27, 30, 31], "especi": [13, 16, 19, 24, 30], "world_siz": [13, 16, 21, 23, 26, 30], "particip": [13, 16], "job": [13, 19, 24], "global_ordin": [13, 16, 17, 23, 26], "global": [13, 16, 17, 22, 30, 32], "ordin": [13, 17], "thread": [13, 16, 17, 18, 32], "guarante": [13, 22], "predict": 13, "relationship": [13, 17, 18], "worker": [13, 16, 17, 19, 26, 32], "id": [13, 16, 18, 19, 31], "nor": 13, "contigu": [13, 17, 18], "local_ordin": 13, "get_master_ip": 13, "retriev": [13, 17, 20, 24, 29, 30], "discoveri": 13, "use_spmd": [13, 30, 31, 32], "forc": [13, 16, 18, 20, 25, 29], "non": [13, 15, 20, 21, 22, 29, 31], "replic": [13, 30, 31], "spmd_advanc": 13, "md": [13, 16], "initialize_cach": [13, 17], "readonli": [13, 17], "persist": [13, 17, 32], "xla_devic": [13, 16, 17, 18, 19, 21, 23, 24, 25, 28, 31], "devkind": 13, "cuda": [13, 16, 17, 19, 20, 21, 28, 29, 33], "deprec": 13, "xla_device_hw": 13, "union": 13, "real": [13, 24], "is_master_ordin": 13, "multi": [13, 14, 30, 33], "num_host": 13, "boolean": 13, "indic": [13, 18, 19, 20, 29, 31], "reduce_typ": 13, "float": [13, 20, 21, 29], "pin_layout": 13, "One": [13, 14, 19, 26], "xm": [13, 15, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 31], "reduce_sum": 13, "reduce_mul": 13, "reduce_and": 13, "reduce_or": 13, "reduce_min": 13, "reduce_max": 13, "replica": [13, 16], "layout": [13, 28, 31], "pine": 13, "prevent": [13, 19, 21, 24, 30], "corrupt": 13, "unpin": 13, "hlomodul": 13, "constrain": [13, 16], "hold": [13, 30], "channel_id": 13, "use_global_device_id": 13, "channel": [13, 28], "interpret": [13, 20, 29], "replicagroup": 13, "all_to_al": 13, "split_dimens": 13, "concat_dimens": 13, "split_count": 13, "www": 13, "operation_semant": 13, "upon": 13, "split": [13, 31], "concat": 13, "add_step_closur": 13, "closur": 13, "run_async": 13, "report": 13, "consol": 13, "tensorboard": [13, 19], "etc": [13, 15, 18, 20, 29, 30], "intermediari": 13, "inspect": 13, "barrier": [13, 16, 17, 19], "materi": [13, 18, 19, 20, 29, 30], "queu": 13, "though": [13, 17, 23], "advis": 13, "throttl": 13, "event": 13, "asynchron": [13, 30, 32], "wait_device_op": 13, "async": [13, 24], "whose": [13, 14, 31], "empti": 13, "optimizer_step": [13, 17, 19, 21, 23, 26], "optimizer_arg": 13, "dict": [13, 22, 26], "gradid": 13, "parallelload": [13, 30], "dataparallel": 13, "loader": [13, 18, 19, 24], "dictionari": 13, "gradient": [13, 17, 21, 26, 32], "file_or_path": 13, "textio": 13, "master_onli": [13, 26], "global_mast": 13, "transfer": [13, 16, 18, 19, 30], "care": [13, 17, 18, 20, 29], "taken": [13, 17, 18, 20, 23, 29, 32], "view": [13, 17, 18], "recreat": [13, 17], "destin": [13, 17], "nest": [13, 26], "locat": 13, "control": [13, 14, 17, 18, 30], "obj_to_sav": 13, "path_to_sav": 13, "rendezv": 13, "tag": [13, 16], "byte": 13, "b": [13, 16, 19, 20, 21, 22, 24, 29, 31], "mesh": [13, 16, 27], "server": [13, 16, 19], "xla_rendezv": 13, "sent": [13, 18], "exchang": 13, "posit": 13, "mesh_reduc": 13, "reduce_fn": 13, "toxlatensorarena": 13, "receiv": 13, "copi": [13, 16, 17, 18, 19], "np": [13, 27, 31], "accuraci": [13, 23, 26], "test_accuraci": 13, "set_rng_stat": 13, "get_rng_stat": 13, "get_memory_info": 13, "memoryinfo": 13, "bytes_us": 13, "290816": 13, "bytes_limit": 13, "34088157184": 13, "peak_bytes_us": 13, "500816": 13, "get_stablehlo": 13, "env": [13, 16, 30], "var": [13, 30], "xla_hlo_debug": [13, 18], "get_stablehlo_bytecod": 13, "bytecod": [13, 24], "parallel_load": [13, 16, 17, 18], "mpdeviceload": [13, 17, 19, 30], "dataload": [13, 17, 19, 23, 30, 32], "background": [13, 32], "upload": [13, 19, 30], "per_device_load": [13, 30], "constructor": 13, "train_device_load": 13, "train_load": [13, 17, 30], "xla_multiprocess": 13, "spawn": [13, 16, 17, 19], "nproc": [13, 16], "daemon": 13, "start_method": 13, "moment": 13, "valueerror": 13, "mark_shard": [13, 22, 27, 30, 31], "xlashardedtensor": [13, 32], "partition_spec": [13, 30, 31], "nonetyp": 13, "annot": [13, 30, 31], "partit": [13, 30], "spec": [13, 30], "intern": [13, 16, 17, 18, 20, 29, 30, 33], "spmdpartition": [13, 30], "topologi": [13, 17, 30], "partitionspec": 13, "ax": [13, 30, 31], "mesh_shap": [13, 27, 30, 31], "impact": [13, 16, 18, 20, 23, 29], "num_devic": [13, 27, 30, 31], "device_id": [13, 27, 30, 31], "linear": [13, 16, 17, 21, 22, 23, 28], "clear_shard": 13, "clear": 13, "cast": [13, 21], "t1": [13, 17, 18, 31], "get_1d_mesh": 13, "set_global_mesh": 13, "get_global_mesh": 13, "axis_nam": [13, 30], "v4": [13, 15, 16, 17, 19, 24, 30], "ndarrai": 13, "flatten": 13, "reshap": 13, "fill": 13, "row": [13, 31], "major": [13, 31], "global_runtime_device_attribut": [13, 31], "length": [13, 20, 29], "get_xla_supported_devic": 13, "get_logical_mesh": [13, 31], "ordereddict": [13, 30, 31], "hybridmesh": [13, 30], "ici_mesh_shap": [13, 30], "dcn_mesh_shap": [13, 30], "hybrid": 13, "ici": 13, "dcn": [13, 30], "increas": [13, 22], "intens": 13, "mdl": 13, "inner": [13, 26, 30], "outer": [13, 26, 27, 30], "slice": [13, 19, 30, 31], "fsdp": [13, 26, 27, 30, 31], "eager_mod": [13, 15], "wa": [13, 16, 18, 19, 20, 29, 32], "d": [13, 14, 20, 21, 29], "eagerli": [13, 15, 17, 18, 20, 29], "metrics_report": [13, 18], "short_metrics_report": [13, 18], "counter_nam": 13, "metric_nam": 13, "activ": [13, 17, 18, 23, 26, 27, 28], "counter_valu": 13, "metric_data": 13, "total_sampl": 13, "retain": 13, "circular": 13, "natur": 14, "in_tensor": 14, "randint": [14, 28], "out_tensor": 14, "nonzero": [14, 18, 19, 20, 29], "word": [14, 20, 22, 29], "25": 14, "further": [14, 19, 23], "categor": 14, "unbound": 14, "alloc": [14, 31], "infinit": [14, 27], "phase": 14, "perceptron": 14, "mlp": 14, "xla_experiment": 14, "masked_select": 14, "masked_scatt": 14, "your_script": [14, 19], "100": [14, 18, 22, 26], "29": [14, 23, 24], "49": [14, 24], "03": 14, "102": 14, "hit": [14, 20, 29], "198": 14, "1953": 14, "motiv": 14, "excess": 14, "half": 14, "try": [14, 18, 19, 20, 29], "test_dynamic_shape_model": 14, "testdynamicshapemodel": 14, "test_backward_pass_with_dynamic_input": 14, "plan": [14, 16], "expand": [14, 24], "review": [14, 27], "rfc": [14, 30, 33], "mark_step": [15, 16, 17, 18, 19, 23], "actual": [15, 19, 20, 23, 29, 30], "drawback": 15, "approach": [15, 20, 23, 26, 29], "often": [15, 18, 20, 22, 29], "confus": 15, "preprocess": [15, 28], "small": [15, 18, 19, 20, 23, 24, 29], "leak": 15, "expens": [15, 18, 20, 29], "hard": [15, 20, 23, 24, 29], "why": [15, 20, 29], "mitig": 15, "ux": 15, "mark": [15, 17], "compiled_model": 15, "right": [15, 20, 24, 29], "awai": 15, "pretti": [15, 17, 20, 23, 29], "straight": 15, "enter": 15, "reenabl": 15, "perfomr": 15, "recommen": 15, "overhad": 15, "step_fn": 15, "loss_fn": [15, 16, 17, 21, 23, 24], "zero_grad": [15, 16, 17, 21, 23], "logit": [15, 27], "loss": [15, 16, 17, 21, 24, 26, 27], "ask": [15, 18, 20, 29], "refactor": 15, "llama2": 15, "fake": [15, 32], "300": [15, 18], "observ": [15, 16, 23], "147": 15, "65": [15, 18], "45": 15, "perfomran": 15, "tri": [15, 19], "resnet50": [15, 16, 17, 24, 26], "exepct": 15, "meant": 15, "encount": [16, 18, 19], "bug": [16, 18, 23], "r2": [16, 18, 30], "renam": 16, "torchrun": [16, 17, 33], "xpu": 16, "neuron": 16, "xrt_tpu_config": 16, "30": [16, 26], "thousand": 16, "preview": 16, "safe": 16, "section": [16, 17, 18, 19, 30, 31], "broadcast": 16, "broadcast_master_param": 16, "pjrt_backend": 16, "diff": [16, 19], "42": [16, 22], "gradient_as_bucket_view": [16, 23], "mseloss": [16, 23], "sgd": [16, 17, 21, 23, 24], "lr": [16, 17, 23, 24, 26, 27], "001": [16, 23], "confirm": 16, "p": [16, 18, 20, 29], "localservic": 16, "localhost": 16, "51011": 16, "master_addr": 16, "master_port": 16, "12355": [16, 33], "Or": [16, 17, 20, 29], "overhead": [16, 22, 23, 24], "grpc": 16, "torchbench": 16, "35": [16, 18], "tpuvm": [16, 17, 19, 30], "mnist": [16, 17, 18, 21], "test_train_mp_mnist": [16, 23], "fake_data": [16, 18, 23, 33], "alpha": [16, 17], "central2": [16, 19], "git": [16, 18, 19, 26], "depth": [16, 18], "branch": [16, 18, 20, 29], "test_train_mp_imagenet": [16, 18, 23], "batch_siz": [16, 26, 33], "num_epoch": [16, 23, 26], "By": [16, 20, 29], "tpu_process_bound": 16, "tpu_visible_chip": 16, "r1": 16, "13": [16, 17, 23, 25], "docker_imag": 16, "gcr": 16, "privat": 16, "sudo": [16, 19], "rm": 16, "privileg": 16, "net": [16, 19, 21], "gpu_num_devic": 16, "nnode": [16, 33], "num_gpu_devic": 16, "pjrt_distribut": 16, "physic": [16, 30, 31], "12": [16, 18, 24, 26], "number_gpu_vm": [16, 33], "node_rank": [16, 33], "current_node_rank": 16, "nproc_per_nod": [16, 33], "number_local_gpu_devic": 16, "rdzv_endpoint": [16, 33], "internal_ip_address": 16, "multinode_train": 16, "endpoint": [16, 33], "form": [16, 18, 20, 29, 33], "machine_0": 16, "machine_1": 16, "machine_0_internal_ip_address": [16, 33], "ident": 16, "page": 16, "mostli": [16, 26], "interchang": 16, "perspect": [16, 17], "subtl": 16, "importantli": [16, 22], "architectur": [16, 26], "thu": [16, 18], "batch": [16, 17, 18, 19, 30], "latenc": 16, "serial": [16, 17], "deseri": 16, "send": [16, 17, 19, 30], "direct": [16, 18], "independ": [16, 17, 18], "xla_dist": 16, "scp": [16, 17], "sdk": 16, "collect": [16, 23, 24, 31, 32], "enhanc": 16, "stabil": [16, 18, 21], "xmp": [16, 17, 19], "substanti": 16, "practic": [16, 20, 27, 29, 31], "unreli": 16, "inbound": 16, "could": [16, 19, 20, 29, 30, 31], "failur": 16, "entir": [16, 26], "restart": 16, "impos": 16, "middl": [16, 19, 20, 29], "unwant": 16, "permit": 16, "subset": [16, 31], "old": 16, "alter": 16, "synchron": [16, 17, 19, 30, 32], "all_gather_object": 16, "gloo": [16, 23, 32], "subgroup": 16, "monitor": 16, "altern": [16, 20, 21, 28, 29], "reliabl": 16, "strongli": 16, "_all_gath": 16, "int32": 16, "zeros_lik": 16, "get_world_s": 16, "averag": 16, "task": 16, "175": 16, "chart": 16, "breakdown": 16, "tfrt": 16, "legaci": 16, "streamexecutor": 16, "tpu_legaci": 16, "comparison": [16, 31], "regular": [17, 18, 19, 28], "t0": 17, "matrix": 17, "multipli": [17, 31], "mm": [17, 21], "neural": 17, "l_in": 17, "l_out": 17, "floattensor": 17, "highlight": [17, 19], "nllloss": 17, "momentum": 17, "acquir": 17, "mp_device_load": 17, "three": 17, "multithread": [17, 18], "assign": [17, 19], "own": [17, 26], "onto": 17, "preload": [17, 19], "overlap": [17, 19, 24, 30], "batches_per_execut": 17, "consolid": [17, 26], "all_reduce_gradi": 17, "parent": 17, "talk": 17, "howto": 17, "focu": [17, 20, 29], "train_mnist_xla": 17, "outsid": 17, "infrastructur": 17, "awar": 17, "fakedata": 17, "But": [17, 18, 20, 29], "immedi": [17, 30], "record": [17, 18, 19, 22], "defer": 17, "fuse": [17, 19], "invis": 17, "caller": 17, "insert": [17, 19], "paper": 17, "opaqu": [17, 18], "appear": [17, 18, 19], "unlik": [17, 19], "adjust": 17, "preserv": [17, 18], "appreci": 17, "accommod": 17, "previous": 17, "state_dict": [17, 26, 32], "footprint": 17, "xser": 17, "stream": 17, "amount": [17, 18, 19, 20, 29], "restor": 17, "load_state_dict": [17, 32], "unavail": [17, 18], "consum": [17, 20, 29], "doesn": [17, 18, 20, 27, 29], "disk": 17, "occur": 17, "your_cache_path": 17, "mount": 17, "mp_fn": 17, "tmp": [17, 18, 26], "xla_cache_": 17, "runnabl": [17, 23, 27], "subject": 18, "peculiar": 18, "detial": 18, "__version__": 18, "cu121": 18, "t2": [18, 31], "200": 18, "rx": 18, "conclud": 18, "diagnos": 18, "extrem": [18, 22], "pt_xla_debug_level": 18, "slip": 18, "analyz": [18, 19], "summari": 18, "frequent": 18, "21": 18, "11": [18, 20, 29], "transferfromdevicetim": 18, "23": 18, "hash": 18, "c74c3b91b855b2b123f833b0d5f86943": 18, "107": 18, "frame": 18, "trigger": [18, 19, 20, 22, 29], "dk3": 18, "1055": 18, "44": 18, "__next__": 18, "train_loop_fn": 18, "48": [18, 23], "start_train": 18, "73": 18, "548000": 18, "gb": 18, "922460": 18, "alias": [18, 21], "547871": 18, "124478": 18, "028210": 18, "steptrac": 18, "frequenc": 18, "pair": 18, "met": 18, "spent": [18, 19], "destroi": 18, "202": 18, "06m09s401ms746": 18, "001u": 18, "778ms572": 18, "062u": 18, "425201": 18, "001ms32": 18, "778u": 18, "001ms61": 18, "283u": 18, "001ms79": 18, "236u": 18, "001ms110": 18, "973u": 18, "001ms228": 18, "773u": 18, "001ms339": 18, "183u": 18, "001ms434": 18, "305u": 18, "002ms921": 18, "063u": 18, "21s102ms853": 18, "173u": 18, "cachedsynctensor": 18, "395": [18, 23], "area": 18, "rout": 18, "qualifi": 18, "33": [18, 23, 24], "_local_scalar_dens": 18, "epoch": [18, 19, 26], "clear_al": 18, "xla_dynamo_debug": 18, "bottleneck": [18, 19, 22], "notebook": 18, "train_resnet_benchmark": 18, "behav": 18, "evalu": [18, 19, 20, 22, 29], "suggest": 18, "bad": 18, "degrad": [18, 19], "speedup": [18, 24], "constant": [18, 19, 30], "indirect": 18, "solut": [18, 20, 28, 29], "variat": 18, "pad": [18, 19, 20, 29, 31], "fix": [18, 19, 22, 24, 27], "translat": 18, "item": [18, 19], "substitut": 18, "flow": 18, "clip_grad_norm": 18, "problemat": 18, "clip_grad_norm_": 18, "dramat": 18, "total_norm": 18, "zero": [18, 26, 32], "param_norm": 18, "grad": 18, "norm": 18, "norm_typ": 18, "add_": 18, "clip_coef": 18, "max_norm": 18, "1e": [18, 24], "mul_": 18, "data_parallel": 18, "dataset": [18, 23, 26], "stride": 18, "reconstruct": 18, "shallow": 18, "ty": 18, "made": [18, 19, 20, 29, 30], "_get_xla_tensors_text": [18, 20, 29], "_get_xla_tensors_hlo": 18, "prior": [18, 32], "degre": 18, "xla_ir_debug": 18, "henc": [18, 24], "respons": [18, 19, 24, 32], "propag": 18, "xla_save_tensors_fil": 18, "realli": [18, 20, 24, 29], "big": [18, 20, 29], "left": 18, "sheet": 18, "xla_save_tensors_fmt": 18, "text": 18, "graphviz": 18, "xla_flag": 18, "xla_dump_to": 18, "dir_nam": 18, "unoptim": 18, "optimz": 18, "xla_metrics_fil": 18, "xla_save_hlo_fil": 18, "offend": 18, "xla_sync_wait": 18, "xla_use_eager_debug_mod": 18, "bypass": 18, "overal": [18, 19], "optimizaiton": 18, "tf_cpp_log_thread_id": 18, "tf_cpp_vmodul": 18, "vlog": 18, "tf_cpp_min_log_level": 18, "turn": 18, "warn": 18, "tf_vlog": 18, "xla_dump_hlo_graph": 18, "xla_util": 18, "cc": 18, "save1": 18, "xla_graph_executor": 18, "pjrt_computation_cli": 18, "dir": 18, "pytorch_test_with_slow": 18, "test_torch": 18, "test_put_xla_uint8": 18, "torch_test_devic": 18, "pytorch_test_bas": 18, "brief": 19, "reader": 19, "modif": 19, "fetch": 19, "discuss": [19, 31], "readabl": 19, "opcod": 19, "fed": 19, "attach": [19, 30], "callback": 19, "xla_tensor_z": 19, "cut": [19, 20, 29], "transferfromdevic": 19, "tell": [19, 20, 29], "properti": [19, 20, 29], "illustr": [19, 31], "suppos": 19, "tensors_on_devic": 19, "z": [19, 20, 29], "subgraph": [19, 20, 29], "signal": 19, "far": 19, "suitabl": 19, "trade": [19, 20, 29], "off": 19, "spend": 19, "fusion": 19, "worth": [19, 20, 29], "latter": [19, 26], "runtime_vers": 19, "project_id": 19, "accelerator_typ": 19, "tpu_nam": 19, "your_tpu_nam": 19, "subnetwork": 19, "tpusubnet": 19, "pip3": 19, "cp38": 19, "linux_x86_64": 19, "whl": 19, "apt": 19, "libopenbla": 19, "libgl1": 19, "hypercomput": 19, "recipi": 19, "guidelin": 19, "bar": 19, "rememb": 19, "txt2img": 19, "prompt": 19, "photograph": 19, "astronaut": 19, "ride": 19, "hors": 19, "relat": 19, "precision_scop": 19, "addition": [19, 21, 26], "frozenclipembedd": 19, "simplic": [19, 20, 29], "ddim": 19, "top": 19, "attr": 19, "statement": [19, 20, 29], "stop": 19, "fall": [19, 27], "difficult": 19, "readi": 19, "investig": [19, 23], "cover": [19, 30], "huggingfac": 19, "sd": 19, "xl": 19, "cd": [19, 26], "text_to_imag": 19, "inference_tpu_single_devic": 19, "lora": 19, "model_id": 19, "stabilityai": 19, "9": [19, 20, 23, 26, 29], "pipelin": 19, "dpmsolvermultistepschedul": 19, "txt": 19, "invisible_watermark": 19, "safetensor": 19, "agre": 19, "licens": 19, "card": 19, "cli": 19, "_your_copied_token__": 19, "pipe": 19, "hour": 19, "wherea": 19, "likewis": 19, "gpt": 19, "min": 19, "advantag": 19, "mayb": 19, "notic": 19, "piec": 19, "__call__": 19, "commit": 19, "caveat": 19, "rule": [19, 21], "thumb": 19, "durat": [19, 32], "constantli": 19, "idl": 19, "inference_tpu_": 19, "capture_profil": 19, "gap": 19, "xp": 19, "measur": 19, "portion": 19, "busi": 19, "scroll": 19, "occupi": 19, "displai": 19, "largest": 19, "zoom": 19, "timelin": 19, "period": 19, "examin": 19, "did": 19, "pipe_watermark": 19, "closer": 19, "preced": 19, "proceed": [19, 27], "watermark": 19, "cv2": 19, "pywt": 19, "leav": 19, "broken": 19, "rerun": 19, "scale_model_input": 19, "dynamo": [19, 24, 28], "ran": 19, "my_funct": 19, "preocess": 19, "debug_single_process": 19, "magic": [19, 20, 29], "treat": [19, 31], "xla_no_special_scalar": 19, "hurt": [20, 29], "perf": [20, 29], "pov": [20, 29], "sai": [20, 29], "assur": [20, 29], "gone": [20, 29], "coverag": [20, 29], "aim": [20, 27, 29], "explan": [20, 29], "mainli": [20, 29], "beginn": [20, 29], "propos": [20, 29], "reli": [20, 29], "impract": [20, 29], "assumpt": [20, 29], "ye": [20, 28, 29], "sentenc": [20, 29], "bucket": [20, 29, 32], "kinda": [20, 29], "anti": [20, 29], "frontend": [20, 29], "matter": [20, 29], "workaround": [20, 29], "okai": [20, 29], "teach": [20, 29], "theoret": [20, 29], "obviou": [20, 29], "s64": [20, 29], "inde": [20, 29], "_get_xla_tensor_dimension_s": [20, 29], "commonli": [20, 29, 31], "wrong": [20, 29], "wors": [20, 29], "probabl": [20, 29], "know": [20, 22, 23, 29], "upper": [20, 29], "nit": [20, 29], "solv": [20, 29], "kept": [20, 29], "earli": [20, 29], "accessor": [20, 29], "2d": [20, 27, 29, 31], "implicitli": [20, 29], "doubl": [20, 29], "overload": [20, 29], "explod": [20, 29], "convers": [20, 29], "cheap": [20, 29], "ve": [20, 29], "hoc": [20, 29], "think": [20, 29], "verison": [20, 29], "bla": [20, 29], "blabla": [20, 29], "proce": [20, 29], "uglier": [20, 29], "win": [20, 29], "pars": [20, 29], "torchscript": [20, 29], "somehow": [20, 29], "merg": [20, 29], "lazili": [20, 29, 30, 32], "properli": [20, 29], "thought": [20, 29], "trivial": [20, 29], "effort": [20, 29, 30], "side": [20, 22, 29], "bandwidth": [20, 29], "automag": [20, 29], "gold": [20, 29], "smart": [20, 29], "trick": [20, 29], "tbh": [20, 29], "longer": [20, 29], "unawar": [20, 29], "hope": [20, 29], "smash": [20, 29], "blocker": [20, 29], "ahead": [20, 29], "nnc": [20, 29], "exactli": [20, 22, 29], "brian": [20, 29], "hirsh": [20, 29], "bdhirsh": [20, 29], "question": [20, 29], "stick": [20, 29], "torch_warn": [20, 29], "yea": [20, 29], "hei": [20, 29], "won": [20, 21, 29], "blaze": [20, 29], "isn": [20, 29, 32], "abil": [20, 23, 29], "devirtu": [20, 29], "sound": [20, 29], "great": [20, 29], "truth": [20, 29], "irvalu": [20, 29], "enforc": [20, 29], "discrep": [20, 29], "followup": [20, 29], "1000": [20, 29], "my": [20, 29, 32], "presenc": [20, 29], "get_dimention_s": [20, 29], "didn": [20, 29], "exponenti": [20, 29], "blowup": [20, 29], "fewer": [20, 29], "opportun": [20, 29], "recogn": [20, 24, 29], "feasibl": [20, 29], "annoi": [20, 29], "wasn": [20, 29], "materiz": [20, 29], "combo": [20, 29], "extend": 21, "datatyp": 21, "float16": 21, "bfloat16": [21, 28], "syncfre": 21, "autocast": 21, "summar": 21, "elig": 21, "suppli": 21, "addmm": 21, "addmm_": 21, "prefer": 21, "float64": 21, "respect": [21, 31], "unlist": 21, "__matmul__": 21, "addbmm": 21, "addmv": 21, "addr": 21, "baddbmm": 21, "bmm": 21, "conv1d": 21, "conv2d": [21, 26], "conv3d": 21, "conv_transpose1d": 21, "conv_transpose2d": 21, "conv_transpose3d": 21, "matmul": 21, "relu": [21, 23], "prelu": 21, "max_pool2d": 21, "batch_norm": 21, "log_softmax": 21, "binary_cross_entropy_with_logit": 21, "prod": 21, "cdist": 21, "chloeski": 21, "invers": 21, "reflection_pad": 21, "replication_pad": 21, "mse_loss": 21, "cosine_embbeding_loss": 21, "nll_loss": 21, "multilabel_margin_loss": 21, "qr": 21, "svd": 21, "triangular_solv": 21, "linalg_svd": 21, "linalg_inv_ex": 21, "widest": 21, "index_copi": 21, "scaler": [21, 28], "gradscal": 21, "_fetch_gradi": 21, "xla_use_f16": 21, "underflow": 21, "imagenet": 21, "elimin": 22, "primer": 22, "exce": 22, "math": 22, "pseudo": 22, "unnecessari": [22, 30], "Such": 22, "decor": 22, "repeatedli": 22, "do_some_math": 22, "simul": 22, "ten": [22, 25], "func": 22, "functional_cal": 22, "mymodul": [22, 30], "__init__": [22, 23, 28], "super": [22, 23, 24], "pure_forward": 22, "param": 22, "cached_forward": 22, "named_paramet": 22, "named_buff": 22, "unit": [22, 23], "testbridge_test_onli": 22, "test_trace_transformer_with_spda_attent": 22, "test_assume_pur": 22, "benchmark_iter": 22, "140": 22, "1342": 22, "24": 22, "1658": 22, "pai": 22, "front": 22, "einsum": 22, "minimum": [23, 26, 27], "nccl": 23, "new_rank": 23, "ddp_model": 23, "launcher": 23, "demo_fn": 23, "touch": [23, 32], "five": 23, "sy": 23, "tempfil": 23, "cleanup": 23, "destroy_process_group": 23, "toymodel": 23, "net1": 23, "1000000": 23, "net2": 23, "demo_bas": 23, "label": 23, "run_demo": 23, "tot": 23, "statist": 23, "median": 23, "90th": 23, "deviat": 23, "cv": 23, "418": 23, "54": 23, "419": 23, "22": 23, "430": 23, "40": 23, "76": 23, "02": 23, "97": 23, "407": 23, "60": 23, "39": 23, "seem": 23, "17864": 23, "20108": 23, "96": 23, "24351": 23, "74": 23, "5866": 23, "83": 23, "10701": 23, "11770": 23, "00": 23, "14313": 23, "78": 23, "3102": 23, "92": 23, "41": [23, 24], "round": 23, "heavili": [23, 24], "sens": 23, "amort": 23, "logdir": 23, "converg": 23, "caution": 23, "interest": 23, "known": 23, "crash": 23, "unmodifi": 24, "hook": 24, "biggest": [24, 26], "torchfx": 24, "technologi": 24, "a_xla": 24, "b_xla": 24, "compiled_cod": 24, "eval_model": 24, "xla_resnet18": 24, "eval": 24, "dynamo_resnet18": 24, "no_grad": 24, "resent18": 24, "analysi": 24, "bench": 24, "59": 24, "resnext50_32x4d": 24, "91": 24, "alexnet": 24, "28": 24, "mobilenet_v2": 24, "18": 24, "62": 24, "mnasnet1_0": 24, "68": 24, "vgg16": 24, "bert_pytorch": 24, "squeezenet1_1": 24, "timm_vision_transform": 24, "52": 24, "geomean": 24, "04": 24, "train_model": 24, "crossentropyloss": 24, "pred": 24, "train_model_main": 24, "dynamo_train_model": 24, "xla_optim": 24, "weight_decai": 24, "extract": 24, "07": 24, "43": 24, "81": 24, "87": 24, "fwd": 24, "bwd": 24, "e2": 24, "hide": 24, "larger": [24, 26], "wit": 24, "promis": 24, "tradit": 24, "excit": 24, "upcom": [24, 30], "invest": 24, "matur": 24, "stori": 24, "_higher_order_op": 25, "fori_loop": 25, "cond_fn": 25, "body_fn": 25, "bodi": 25, "iteri": 25, "init_v": 25, "functionaltensor": 25, "lvl": 25, "51": 25, "xlafullyshardeddataparallel": 26, "my_modul": [26, 27], "adam": [26, 27], "0001": [26, 27], "leftov": [26, 27], "arxiv": 26, "1910": 26, "02054": 26, "reshard_after_forward": 26, "test_train_mp_mnist_fsdp_with_ckpt": 26, "test_train_mp_imagenet_fsdp": 26, "interleav": 26, "submodul": 26, "fsdpvitmodel": 26, "checkpoint_modul": [26, 27], "3524": 26, "auto_wrap_polici": [26, 27], "size_based_auto_wrap_polici": 26, "polici": [26, 30], "100m": 26, "transformer_auto_wrap_polici": [26, 27], "transformer_layer_cl": [26, 27], "auto_wrapper_cal": 26, "remateri": 26, "resum": 26, "get_shard_metadata": 26, "consolidate_sharded_model_checkpoint": 26, "stitch": 26, "ckpt": 26, "shard_metadata": 26, "ckpt_path": 26, "pth": 26, "consolidate_sharded_ckpt": 26, "ckpt_prefix": 26, "your_sharded_checkpoint_fil": 26, "ckpt_suffix": 26, "_rank": 26, "inspir": 26, "structur": [26, 30], "fairscal": 26, "fullyshardeddataparallel": 26, "resort": 26, "train_resnet_fsdp_auto_wrap": 26, "newer": 26, "recurs": [26, 27], "98": 26, "drop_last": 26, "use_nested_fsdp": 26, "use_gradient_checkpoint": 26, "final_ckpt": 26, "75": 26, "download": 26, "1k": 26, "datadir": 26, "test_set_batch_s": 26, "eval_interv": 26, "num_warmup_epoch": 26, "lr_scheduler_divide_every_n_epoch": 26, "lr_scheduler_divisor": 26, "residu": 26, "algorithm": [26, 27], "ronghanghu": 26, "vit_10b_fsdp_exampl": 26, "vit": 26, "fsdpv2": 27, "famou": 27, "enjoi": 27, "tabl": 27, "spmd_fully_sharded_data_parallel": 27, "spmdfullyshardeddataparallel": 27, "autowrap": 27, "decoderlay": 27, "functool": 27, "decoder_only_model": 27, "shard_output": 27, "0th": 27, "children": 27, "fork": 27, "hf": 27, "abstract": [28, 30], "blockwis": 28, "int4": 28, "analog": 28, "classifi": 28, "flexibl": 28, "choos": [28, 32], "docstr": 28, "xla_quantized_matmul": 28, "n_input_featur": 28, "n_output_featur": 28, "w_int": 28, "127": 28, "int8": 28, "matmul_output": 28, "quantized_matmul": 28, "x_xla": 28, "w_int_xla": 28, "scaler_xla": 28, "matmul_output_xla": 28, "w": 28, "f_dynamo": 28, "dynamo_out_xla": 28, "myqlinearforxlabackend": 28, "load_weight": 28, "processed_w": 28, "processed_scal": 28, "stuff": 28, "orig_model": 28, "mymodel": 28, "q_weight": 28, "q_weights_for_xla": 28, "process_for_xla": 28, "q_linear": 28, "xlaquantizedlinear": 28, "in_featur": 28, "out_featur": 28, "load_quantized_weight": 28, "sym": 28, "asym": 28, "w8a16": 28, "w8a8": 28, "w4a8": 28, "gspmd": [30, 31], "proced": 30, "src": [30, 32], "_input_sharding_": 30, "4d": 30, "input_shard": 30, "shardingspec": 30, "input_mesh": 30, "s2": 30, "s3": 30, "s4": 30, "_after": 30, "_the": 30, "forth": 30, "techniqu": 30, "decis": 30, "nice": 30, "arrang": [30, 31], "center": 30, "multislic": 30, "denot": 30, "hardcod": 30, "delai": 30, "subclass": 30, "__torch_dispatch__": 30, "global_tensor": 30, "strictli": 30, "local_shard": 30, "xlashard": 30, "4e8e5511555073ce8b6d1a436bf808c9333dcac6": 30, "xla_sharded_tensor": 30, "l12": 30, "ongo": 30, "distributedtensor": 30, "proof": 30, "concept": [30, 31], "distribute_tensor": 30, "devicemesh": 30, "big_tensor": 30, "100000": 30, "88": 30, "my_dtensor": 30, "stai": 30, "dynamo_mark_shard": 30, "placement": 30, "visualize_tensor_shard": 30, "visualize_shard": 30, "rich": 30, "2x2": 30, "generated_t": 30, "use_color": 30, "style": [30, 31], "tile": 30, "partial_repl": 30, "envvar": 30, "xla_auto_spmd": 30, "_tensor": 30, "distribute_modul": 30, "auto_polici": 30, "device_mesh": 30, "sharded_model": 30, "behvaior": 30, "xla_auto_use_group_shard": 30, "reshard": 30, "xla_auto_spmd_mesh": 30, "unset": 30, "conceptu": 31, "matric": 31, "book": 31, "hint": 31, "strategi": 31, "dimension": 31, "mpi": 31, "necessarili": 31, "512": 31, "3d": 31, "1d": 31, "interconnect": 31, "core_on_chip": 31, "num_cor": 31, "coord": 31, "attribut": 31, "slice_index": 31, "coordin": 31, "divis": 31, "dedic": 32, "planner": 32, "spmdsaveplann": 32, "spmdloadplann": 32, "dist_cp": 32, "distributed_checkpoint": 32, "xc": 32, "storage_writ": 32, "filesystemwrit": 32, "checkpoint_dir": 32, "storage_read": 32, "filesystemread": 32, "all_step": 32, "save_async": 32, "preemption": 32, "detect": 32, "provis": 32, "queuedresourc": 32, "autocheckpoint": 32, "chkpt_on_preempt": 32, "fsspec": 32, "filesystem": 32, "prime_optim": 32, "chkpt_mgr": 32, "tracked_step": 32, "highest": 32, "best_step": 32, "prime": 32, "enumer": 32, "unprim": 32, "destruct": 32, "discov": 32, "nvidia": 33, "resnet": 33, "num_gpu_machin": 33, "rank_of_current_machin": 33, "machine_0_ip_address": 33, "training_or_inference_script_using_spmd": 33, "xla_use_spmd": 33, "test_train_spmd_imagenet": 33}, "objects": {"": [[13, 0, 0, "-", "torch_xla"]], "torch_xla": [[13, 1, 1, "", "compile"], [13, 1, 1, "", "device"], [13, 1, 1, "", "device_count"], [13, 1, 1, "", "devices"], [13, 0, 0, "-", "experimental"], [13, 1, 1, "", "manual_seed"], [13, 0, 0, "-", "runtime"], [13, 1, 1, "", "sync"]], "torch_xla.core": [[13, 0, 0, "-", "xla_model"]], "torch_xla.core.xla_model": [[13, 1, 1, "", "add_step_closure"], [13, 1, 1, "", "all_gather"], [13, 1, 1, "", "all_reduce"], [13, 1, 1, "", "all_to_all"], [13, 1, 1, "", "get_memory_info"], [13, 1, 1, "", "get_rng_state"], [13, 1, 1, "", "get_stablehlo"], [13, 1, 1, "", "get_stablehlo_bytecode"], [13, 1, 1, "", "is_master_ordinal"], [13, 1, 1, "", "mesh_reduce"], [13, 1, 1, "", "optimizer_step"], [13, 1, 1, "", "rendezvous"], [13, 1, 1, "", "save"], [13, 1, 1, "", "set_rng_state"], [13, 1, 1, "", "wait_device_ops"], [13, 1, 1, "", "xla_device"], [13, 1, 1, "", "xla_device_hw"]], "torch_xla.debug": [[13, 0, 0, "-", "metrics"]], "torch_xla.debug.metrics": [[13, 1, 1, "", "counter_names"], [13, 1, 1, "", "counter_value"], [13, 1, 1, "", "metric_data"], [13, 1, 1, "", "metric_names"], [13, 1, 1, "", "metrics_report"], [13, 1, 1, "", "short_metrics_report"]], "torch_xla.distributed": [[13, 0, 0, "-", "parallel_loader"], [13, 0, 0, "-", "spmd"], [13, 0, 0, "-", "xla_multiprocessing"]], "torch_xla.distributed.parallel_loader": [[13, 2, 1, "", "MpDeviceLoader"]], "torch_xla.distributed.spmd": [[13, 2, 1, "", "HybridMesh"], [13, 2, 1, "", "Mesh"], [13, 1, 1, "", "clear_sharding"], [13, 1, 1, "", "get_1d_mesh"], [13, 1, 1, "", "get_global_mesh"], [13, 1, 1, "", "mark_sharding"], [13, 1, 1, "", "set_global_mesh"]], "torch_xla.distributed.xla_multiprocessing": [[13, 1, 1, "", "spawn"]], "torch_xla.experimental": [[13, 1, 1, "", "eager_mode"]], "torch_xla.runtime": [[13, 1, 1, "", "addressable_device_count"], [13, 1, 1, "", "device_type"], [13, 1, 1, "", "get_master_ip"], [13, 1, 1, "", "global_device_count"], [13, 1, 1, "", "global_ordinal"], [13, 1, 1, "", "global_runtime_device_count"], [13, 1, 1, "", "initialize_cache"], [13, 1, 1, "", "is_spmd"], [13, 1, 1, "", "local_device_count"], [13, 1, 1, "", "local_ordinal"], [13, 1, 1, "", "local_process_count"], [13, 1, 1, "", "use_spmd"], [13, 1, 1, "", "world_size"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"]}, "titleterms": {"learn": [0, 1, 12], "about": [0, 1, 12], "gpu": [0, 11, 16, 21, 33], "tpu": [1, 4, 16, 17, 19, 21, 26, 30], "bazel": 2, "pytorch": [2, 3, 4, 6, 7, 8, 10, 12, 13, 17, 18, 19, 24, 26, 29, 30, 31], "xla": [2, 3, 4, 6, 7, 8, 12, 13, 17, 18, 19, 21, 24, 26, 28, 29, 30, 31], "depend": [2, 8, 11], "how": [2, 22, 23, 28, 31], "build": 2, "librari": 2, "torch": [2, 7, 10, 16, 30], "plugin": [2, 6], "remot": 2, "cach": [2, 17], "run": [2, 3, 17, 18, 19, 30, 33], "test": [2, 3, 5, 18, 25], "code": [2, 4, 19, 28], "coverag": 2, "languag": 2, "server": 2, "codegen": 3, "migrat": 3, "guid": [3, 5, 9, 31], "befor": [3, 5], "you": [3, 5, 9, 20, 29], "start": [3, 5, 20, 29], "file": [3, 5], "structur": [3, 5], "old": 3, "op": [3, 5, 7, 28], "lower": [3, 5, 7], "step": [3, 4], "1": [3, 19, 20, 29], "identifi": 3, "2": [3, 19, 20, 27, 29], "inspect": 3, "gener": [3, 10], "lazyir": 3, "h": 3, "3": [3, 20, 29], "implement": [3, 6, 19], "miss": 3, "ir": 3, "function": [3, 22], "torch_xla": [3, 13, 20], "csrc": 3, "ops_xla_shape_fn": 3, "cpp": 3, "4": 3, "ops_lower_fn": 3, "5": 3, "cleanup": 3, "verifi": 3, "result": 3, "sampl": 3, "pr": 3, "configur": 4, "develop": 4, "environ": [4, 18], "visual": 4, "studio": 4, "creat": [4, 17], "connect": 4, "your": [4, 8], "set": 4, "up": [4, 22], "workspac": 4, "next": 4, "understand": [5, 18], "oper": [5, 10, 18, 20, 21, 28, 29], "unit": [5, 18], "tip": 5, "custom": [6, 8, 11], "hardwar": 6, "pjrt": [6, 16], "c": 6, "api": [6, 7, 13, 15], "packag": 6, "support": [7, 21, 28], "distribut": [7, 13, 16, 32], "collect": 7, "stack": 7, "non": 7, "dynamo": [7, 18], "case": [7, 20, 25, 29], "descript": 7, "kernel": [8, 11], "via": [8, 11], "palla": 8, "adopt": 8, "abov": 8, "compat": [8, 9], "us": [8, 9, 10, 20, 22, 23, 25, 27, 28, 29, 31], "built": 8, "flashattent": 8, "exampl": [8, 9, 19, 21, 25, 26, 27], "usag": [8, 15, 25], "integr": [8, 24, 30], "pagedattent": 8, "write": 8, "own": 8, "scan": 9, "scan_lay": 9, "when": [9, 20, 29], "should": 9, "thi": 9, "limit": [9, 22], "aotautograd": 9, "requir": 9, "overhead": 9, "compil": [9, 15, 17, 18, 30], "time": 9, "experi": 9, "refer": [9, 19], "export": 10, "stablehlo": 10, "extract_jax": 10, "preserv": 10, "high": 10, "level": 10, "composit": 10, "triton": 11, "document": 12, "acceler": 12, "featur": [12, 24, 28], "improv": 12, "workload": 12, "perform": [12, 16, 18, 19], "contribut": 12, "runtim": [13, 16], "xla_model": 13, "spmd": [13, 27, 30, 31, 33], "experiment": [13, 28], "debug": [13, 18, 30], "dynam": [14, 20, 29], "shape": [14, 20, 29], "bound": [14, 20, 29], "eager": 15, "mode": [15, 31], "basic": 15, "infer": [15, 19, 24], "train": [15, 16, 24, 26], "benchmark": [15, 18, 22, 23], "tl": 16, "dr": 16, "benefit": 16, "quickstart": 16, "cpu": [16, 17], "pod": [16, 17, 19, 26, 30], "docker": 16, "singl": [16, 17, 19], "node": 16, "multi": [16, 17], "differ": 16, "from": [16, 17, 20, 29], "xrt": 16, "multithread": 16, "v2": 16, "v3": [16, 26], "chang": 16, "xm": 16, "rendezv": 16, "new": 16, "devic": [17, 19, 30, 31], "an": 17, "tensor": [17, 18, 20, 22, 29], "ar": 17, "model": [17, 28], "multipl": [17, 19], "process": [17, 32], "deep": 17, "dive": 17, "lazi": [17, 22], "memori": [17, 25], "layout": 17, "move": 17, "save": 17, "load": [17, 30], "further": [17, 31], "read": [17, 31], "troubleshoot": 18, "saniti": 18, "check": 18, "version": 18, "A": 18, "simpl": [18, 25], "calcul": 18, "resnet": [18, 26], "With": 18, "fake": [18, 23], "data": [18, 23, 26, 27, 30], "tool": [18, 30], "auto": [18, 30], "metric": 18, "analysi": [18, 19], "execut": 18, "get": 18, "report": 18, "The": 18, "clear": 18, "profil": [18, 19], "known": 18, "caveat": 18, "quirk": 18, "more": 18, "variabl": 18, "common": 18, "combin": 18, "reproduc": 18, "ci": 18, "cd": 18, "failur": 18, "overview": 19, "setup": 19, "convert": 19, "stabl": 19, "diffus": 19, "lightn": 19, "hf": 19, "sourc": [20, 29], "recompil": [20, 29], "let": [20, 29], "": [20, 29], "first": [20, 29], "some": [20, 29], "fact": [20, 29], "constraint": [20, 29], "input": [20, 29], "dataset": [20, 29], "output": [20, 27, 29], "can": [20, 29], "fix": [20, 29], "without": [20, 29], "queri": [20, 29], "its": [20, 29], "real": [20, 23, 29], "dimens": [20, 29], "what": [20, 29, 31], "i": [20, 29, 31], "control": [20, 25, 29], "flow": [20, 29], "conclus": [20, 29], "appendix": [20, 29], "automat": 21, "mix": 21, "precis": 21, "amp": 21, "best": 21, "practic": 21, "assume_pur": 22, "speed": 22, "trace": 22, "background": [22, 23], "motiv": [22, 23], "nn": 22, "modul": [22, 28], "do": 23, "distributeddataparallel": 23, "ddp": 23, "resnet50": 23, "mnist": [23, 26], "disclaim": 23, "torchdynamo": 24, "gap": 24, "take": 24, "awai": 24, "optim": [25, 30, 32], "util": 25, "while_loop": 25, "group": [25, 32], "pure": 25, "python": 25, "while": 25, "loop": 25, "fulli": [26, 27], "shard": [26, 27, 30, 31], "parallel": [26, 27], "script": 26, "imagenet": 26, "instal": 26, "clone": 26, "repo": 26, "8": 26, "50": 26, "10": 26, "billion": 26, "paramet": 26, "gradient": 27, "checkpoint": [27, 32], "huggingfac": 27, "llama": 27, "quantiz": 28, "call": 28, "swap": 28, "matrix": 28, "multipli": 28, "advanc": 30, "topic": 30, "awar": 30, "host": 30, "virtual": 30, "hybrid": 30, "mesh": [30, 31], "xlashardedtensor": 30, "dtensor": 30, "activ": 30, "user": 31, "partit": 31, "spec": 31, "which": 31, "hold": 31, "checkpointmanag": 32, "restor": 32, "state": 32}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Learn about GPUs": [[0, "learn-about-gpus"]], "Learn about TPUs": [[1, "learn-about-tpus"]], "Bazel in Pytorch/XLA": [[2, "bazel-in-pytorch-xla"]], "Bazel dependencies": [[2, "bazel-dependencies"]], "How to build XLA libraries": [[2, "how-to-build-xla-libraries"]], "How to build the Torch/XLA plugin": [[2, "how-to-build-the-torch-xla-plugin"]], "Remote caching": [[2, "remote-caching"]], "Running tests": [[2, "running-tests"]], "Code coverage": [[2, "code-coverage"]], "Language Server": [[2, "language-server"]], "Building PyTorch/XLA": [[2, "building-pytorch-xla"]], "Codegen migration Guide": [[3, "codegen-migration-guide"]], "Before you start": [[3, "before-you-start"], [5, "before-you-start"]], "File structure": [[3, "file-structure"], [5, "file-structure"]], "PyTorch Codegen files": [[3, "pytorch-codegen-files"]], "PyTorch/XLA Codegen files": [[3, "pytorch-xla-codegen-files"]], "PyTorch/XLA Old Op Lowering files": [[3, "pytorch-xla-old-op-lowering-files"]], "Codegen step by step": [[3, "codegen-step-by-step"]], "1. Identify the op": [[3, "identify-the-op"]], "2. Codegen the op and inspect the generated file": [[3, "codegen-the-op-and-inspect-the-generated-file"]], "LazyIr.h": [[3, "lazyir-h"]], "3. Implement the missing IR function": [[3, "implement-the-missing-ir-function"]], "torch_xla/csrc/ops/ops_xla_shape_fn.h": [[3, "torch-xla-csrc-ops-ops-xla-shape-fn-h"]], "torch_xla/csrc/ops/ops_xla_shape_fn.cpp": [[3, "torch-xla-csrc-ops-ops-xla-shape-fn-cpp"]], "4. Implement the lowering function": [[3, "implement-the-lowering-function"]], "torch_xla/csrc/ops/ops_lower_fn.cpp": [[3, "torch-xla-csrc-ops-ops-lower-fn-cpp"]], "5. Cleanup": [[3, "cleanup"]], "Run the test and verify the result": [[3, "run-the-test-and-verify-the-result"]], "Sample PRs": [[3, "sample-prs"]], "Configure a development environment": [[4, "configure-a-development-environment"]], "Visual Studio Code": [[4, "visual-studio-code"]], "Creating and connecting to your TPU": [[4, "creating-and-connecting-to-your-tpu"]], "Setting up a Visual Studio Code workspace with PyTorch/XLA": [[4, "setting-up-a-visual-studio-code-workspace-with-pytorch-xla"]], "Next steps": [[4, "next-steps"]], "OP Lowering Guide": [[5, "op-lowering-guide"]], "Understanding the operation": [[5, "understanding-the-operation"]], "Unit Test": [[5, "unit-test"]], "Tips": [[5, "tips"]], "Custom Hardware Plugins": [[6, "custom-hardware-plugins"]], "Implementing a PJRT Plugin": [[6, "implementing-a-pjrt-plugin"]], "PJRT C API Implementation": [[6, "pjrt-c-api-implementation"]], "PyTorch/XLA Plugin Package": [[6, "pytorch-xla-plugin-package"]], "Support of Torch Distributed API in PyTorch/XLA": [[7, "support-of-torch-distributed-api-in-pytorch-xla"]], "Collective ops lowering": [[7, "collective-ops-lowering"]], "Collective ops lowering stack": [[7, "collective-ops-lowering-stack"]], "non-Dynamo case": [[7, "non-dynamo-case"]], "Dynamo case": [[7, "dynamo-case"]], "API description": [[7, "api-description"]], "Custom Kernels via Pallas": [[8, "custom-kernels-via-pallas"]], "Adopt the above kernel to be compatible with PyTorch/XLA": [[8, "adopt-the-above-kernel-to-be-compatible-with-pytorch-xla"]], "Use built-in kernels": [[8, "use-built-in-kernels"]], "FlashAttention": [[8, "id1"]], "Example usage": [[8, "example-usage"], [8, "id3"]], "Integration Example": [[8, "integration-example"], [8, "id4"]], "PagedAttention": [[8, "id2"]], "Dependencies": [[8, "dependencies"], [11, "dependencies"]], "Write your own Pallas kernels": [[8, "write-your-own-pallas-kernels"]], "Guide for using scan and scan_layers": [[9, "guide-for-using-scan-and-scan-layers"]], "When should you use this": [[9, "when-should-you-use-this"]], "scan_layers example": [[9, "scan-layers-example"]], "scan example": [[9, "scan-example"]], "Limitations": [[9, "limitations"], [22, "limitations"]], "AOTAutograd compatibility requirement": [[9, "aotautograd-compatibility-requirement"]], "AOTAutograd overhead": [[9, "aotautograd-overhead"]], "Compile time experiments": [[9, "compile-time-experiments"]], "References": [[9, "references"]], "Torch Export to StableHLO": [[10, "torch-export-to-stablehlo"]], "Using torch.export": [[10, "using-torch-export"]], "Using extract_jax": [[10, "using-extract-jax"]], "Preserving High-Level PyTorch Operations in StableHLO by generating stablehlo.composite": [[10, "preserving-high-level-pytorch-operations-in-stablehlo-by-generating-stablehlo-composite"]], "Custom GPU Kernels via Triton": [[11, "custom-gpu-kernels-via-triton"]], "PyTorch/XLA documentation": [[12, "pytorch-xla-documentation"]], "Learn about Pytorch/XLA": [[12, null]], "Learn about accelerators": [[12, null]], "PyTorch/XLA features": [[12, null]], "Improve Pytorch/XLA workload performance": [[12, null]], "Contribute to Pytorch/XLA": [[12, null]], "PyTorch/XLA API": [[13, "pytorch-xla-api"]], "torch_xla": [[13, "module-torch_xla"]], "runtime": [[13, "module-torch_xla.runtime"]], "xla_model": [[13, "module-torch_xla.core.xla_model"]], "distributed": [[13, "module-torch_xla.distributed.parallel_loader"]], "spmd": [[13, "module-torch_xla.distributed.spmd"]], "experimental": [[13, "module-torch_xla.experimental"]], "debug": [[13, "module-torch_xla.debug.metrics"]], "Dynamic shape": [[14, "dynamic-shape"]], "Bounded dynamic shape": [[14, "bounded-dynamic-shape"]], "Eager Mode + Compile API": [[15, "eager-mode-compile-api"]], "Basic Usage": [[15, "basic-usage"]], "Inference": [[15, "inference"], [24, "inference"]], "Training": [[15, "training"], [24, "training"]], "Benchmark": [[15, "benchmark"]], "PJRT Runtime": [[16, "pjrt-runtime"]], "TL;DR": [[16, "tl-dr"]], "Benefits": [[16, "benefits"]], "Quickstart": [[16, "quickstart"]], "CPU": [[16, "cpu"]], "TPU": [[16, "tpu"]], "Pods": [[16, "pods"]], "Docker": [[16, "docker"]], "GPU": [[16, "gpu"]], "Single-node GPU training": [[16, "single-node-gpu-training"]], "Multi-node GPU training": [[16, "multi-node-gpu-training"]], "Differences from XRT": [[16, "differences-from-xrt"]], "Multithreading on TPU v2/v3": [[16, "id3"]], "Changes to xm.rendezvous": [[16, "changes-to-xm-rendezvous"]], "PJRT and torch.distributed": [[16, "pjrt-and-torch-distributed"]], "Performance": [[16, "performance"]], "New TPU runtime": [[16, "new-tpu-runtime"]], "PyTorch on XLA Devices": [[17, "pytorch-on-xla-devices"]], "Creating an XLA Tensor": [[17, "creating-an-xla-tensor"]], "XLA Tensors are PyTorch Tensors": [[17, "xla-tensors-are-pytorch-tensors"]], "Running Models on XLA Devices": [[17, "running-models-on-xla-devices"]], "Running on a Single XLA Device": [[17, "running-on-a-single-xla-device"]], "Running on Multiple XLA Devices with Multi-processing": [[17, "running-on-multiple-xla-devices-with-multi-processing"]], "Running on TPU Pods": [[17, "running-on-tpu-pods"]], "XLA Tensor Deep Dive": [[17, "id3"]], "XLA Tensors are Lazy": [[17, "xla-tensors-are-lazy"]], "Memory Layout": [[17, "memory-layout"]], "Moving XLA Tensors to and from the CPU": [[17, "moving-xla-tensors-to-and-from-the-cpu"]], "Saving and Loading XLA Tensors": [[17, "saving-and-loading-xla-tensors"]], "Compilation Caching": [[17, "compilation-caching"]], "Further Reading": [[17, "further-reading"], [31, "further-reading"]], "Troubleshoot": [[18, "troubleshoot"]], "Sanity Check": [[18, "sanity-check"]], "Check PyTorch/XLA Version": [[18, "check-pytorch-xla-version"]], "Perform A Simple Calculation": [[18, "perform-a-simple-calculation"]], "Run Resnet With Fake Data": [[18, "run-resnet-with-fake-data"]], "Performance Debugging": [[18, "performance-debugging"]], "PyTorch/XLA Debugging Tool": [[18, "pytorch-xla-debugging-tool"]], "Perform A Auto-Metrics Analysis": [[18, "perform-a-auto-metrics-analysis"]], "Compilation & Execution Analysis": [[18, "compilation-execution-analysis"]], "Get A Metrics Report": [[18, "get-a-metrics-report"]], "Understand The Metrics Report": [[18, "understand-the-metrics-report"]], "Clear The Metrics Report": [[18, "clear-the-metrics-report"]], "PyTorch/XLA + Dynamo Debugging Tool": [[18, "pytorch-xla-dynamo-debugging-tool"]], "Performance Profiling": [[18, "performance-profiling"]], "Simple Benchmarking": [[18, "simple-benchmarking"]], "Known Performance Caveats": [[18, "known-performance-caveats"]], "XLA Tensor Quirks": [[18, "xla-tensor-quirks"]], "More Debugging Tools": [[18, "more-debugging-tools"]], "Debugging Tensor Operations": [[18, "debugging-tensor-operations"]], "Environment Variables": [[18, "environment-variables"]], "Common Debugging Environment Variables Combinations": [[18, "common-debugging-environment-variables-combinations"]], "Reproducing PyTorch/XLA CI/CD unit test failures.": [[18, "reproducing-pytorch-xla-ci-cd-unit-test-failures"]], "Pytorch/XLA overview": [[19, "pytorch-xla-overview"]], "TPU Setup": [[19, "tpu-setup"]], "Reference implementations": [[19, "reference-implementations"]], "Converting code to PyTorch XLA": [[19, "converting-code-to-pytorch-xla"]], "Example 1. Stable Diffusion inference in PyTorch Lightning on a Single TPU Device": [[19, "example-1-stable-diffusion-inference-in-pytorch-lightning-on-a-single-tpu-device"]], "Example 2. HF Stable Diffusion Inference": [[19, "example-2-hf-stable-diffusion-inference"]], "Running on a Single TPU device": [[19, "running-on-a-single-tpu-device"]], "Profiling and performance analysis": [[19, "profiling-and-performance-analysis"]], "Running on Multiple TPU Devices": [[19, "running-on-multiple-tpu-devices"]], "Running on Pods": [[19, "running-on-pods"]], "Source of recompilations in torch_xla": [[20, "source-of-recompilations-in-torch-xla"]], "Let\u2019s first start with some facts/constraints:": [[20, "lets-first-start-with-some-facts-constraints"], [29, "lets-first-start-with-some-facts-constraints"]], "#1. From input dataset.": [[20, "from-input-dataset"], [29, "from-input-dataset"]], "#2. From operator output": [[20, "from-operator-output"], [29, "from-operator-output"]], "2.1 Bounded dynamic shape can fix the case when you use the tensor with dynamic shape as a Tensor, without querying its real dimension.": [[20, "bounded-dynamic-shape-can-fix-the-case-when-you-use-the-tensor-with-dynamic-shape-as-a-tensor-without-querying-its-real-dimension"], [29, "bounded-dynamic-shape-can-fix-the-case-when-you-use-the-tensor-with-dynamic-shape-as-a-tensor-without-querying-its-real-dimension"]], "2.2 what if real dimension is queried on a tensor with dynamic shape?": [[20, "what-if-real-dimension-is-queried-on-a-tensor-with-dynamic-shape"], [29, "what-if-real-dimension-is-queried-on-a-tensor-with-dynamic-shape"]], "#3. From control flow": [[20, "from-control-flow"], [29, "from-control-flow"]], "Conclusion:": [[20, "conclusion"], [29, "conclusion"]], "Appendix:": [[20, "appendix"], [29, "appendix"]], "Automatic Mixed Precision": [[21, "automatic-mixed-precision"]], "AMP for XLA:TPU": [[21, "amp-for-xla-tpu"]], "AMP for XLA:TPU Best Practices": [[21, "amp-for-xla-tpu-best-practices"]], "Supported Operators": [[21, "supported-operators"]], "AMP for XLA:GPU": [[21, "amp-for-xla-gpu"]], "AMP for XLA:GPU Best Practices": [[21, "amp-for-xla-gpu-best-practices"]], "Examples": [[21, "examples"]], "Use @assume_pure to speed up lazy tensor tracing": [[22, "use-assume-pure-to-speed-up-lazy-tensor-tracing"]], "Background and motivation": [[22, "background-and-motivation"]], "How to use @assume_pure": [[22, "how-to-use-assume-pure"]], "Using @assume_pure with a function": [[22, "using-assume-pure-with-a-function"]], "Using @assume_pure with a nn.Module": [[22, "using-assume-pure-with-a-nn-module"]], "Benchmarks": [[22, "benchmarks"]], "How to do DistributedDataParallel(DDP)": [[23, "how-to-do-distributeddataparallel-ddp"]], "Background / Motivation": [[23, "background-motivation"]], "How to use DistributedDataParallel": [[23, "how-to-use-distributeddataparallel"]], "Benchmarking": [[23, "benchmarking"]], "Resnet50 with fake data": [[23, "resnet50-with-fake-data"]], "MNIST with fake data": [[23, "mnist-with-fake-data"]], "MNIST with real data": [[23, "mnist-with-real-data"]], "Disclaimer": [[23, "disclaimer"]], "TorchDynamo integration in PyTorch XLA": [[24, "torchdynamo-integration-in-pytorch-xla"]], "Integration": [[24, "integration"]], "Feature gaps": [[24, "feature-gaps"]], "Take away": [[24, "take-away"]], "Optimize memory utilization using while_loop": [[25, "optimize-memory-utilization-using-while-loop"]], "while_loop": [[25, "while-loop"]], "Usage:": [[25, "usage"]], "simple example with while_loop:": [[25, "simple-example-with-while-loop"]], "Control group test case": [[25, "control-group-test-case"]], "Control group example with pure python while loop": [[25, "control-group-example-with-pure-python-while-loop"]], "Fully Sharded Data Parallel in PyTorch XLA": [[26, "fully-sharded-data-parallel-in-pytorch-xla"]], "Example training scripts on MNIST and ImageNet": [[26, "example-training-scripts-on-mnist-and-imagenet"]], "Installation": [[26, "installation"]], "Clone PyTorch/XLA repo": [[26, "clone-pytorch-xla-repo"]], "Train MNIST on v3-8 TPU": [[26, "train-mnist-on-v3-8-tpu"]], "Train ImageNet with ResNet-50 on v3-8 TPU": [[26, "train-imagenet-with-resnet-50-on-v3-8-tpu"]], "Example training scripts on TPU pod (with 10 billion parameters)": [[26, "example-training-scripts-on-tpu-pod-with-10-billion-parameters"]], "Fully Sharded Data Parallel using SPMD": [[27, "fully-sharded-data-parallel-using-spmd"]], "Sharding output": [[27, "sharding-output"]], "Gradient checkpointing": [[27, "gradient-checkpointing"]], "HuggingFace Llama 2 Example": [[27, "huggingface-llama-2-example"]], "Quantized Operations for XLA (Experimental feature)": [[28, "quantized-operations-for-xla-experimental-feature"]], "How to use:": [[28, "how-to-use"]], "Call XLA quantized op in model code": [[28, "call-xla-quantized-op-in-model-code"]], "Module Swap": [[28, "module-swap"]], "Supported Quantized Operations:": [[28, "supported-quantized-operations"]], "Matrix Multiply": [[28, "matrix-multiply"]], "Source of recompilations in Pytorch/XLA": [[29, "source-of-recompilations-in-pytorch-xla"]], "PyTorch/XLA SPMD advanced topics": [[30, "pytorch-xla-spmd-advanced-topics"]], "Sharding-Aware Host-to-Device Data Loading": [[30, "sharding-aware-host-to-device-data-loading"]], "Virtual Device Optimization": [[30, "virtual-device-optimization"]], "Hybrid Mesh": [[30, "hybrid-mesh"]], "Running SPMD on TPU Pod": [[30, "running-spmd-on-tpu-pod"]], "XLAShardedTensor": [[30, "xlashardedtensor"]], "DTensor Integration": [[30, "dtensor-integration"]], "Activation Sharding for torch.compile": [[30, "activation-sharding-for-torch-compile"]], "SPMD Debugging Tool": [[30, "spmd-debugging-tool"]], "Auto-Sharding": [[30, "auto-sharding"]], "PyTorch/XLA SPMD User Guide": [[31, "pytorch-xla-spmd-user-guide"]], "What is PyTorch/XLA SPMD?": [[31, "what-is-pytorch-xla-spmd"]], "How to use PyTorch/XLA SPMD?": [[31, "how-to-use-pytorch-xla-spmd"]], "SPMD Mode": [[31, "spmd-mode"]], "Mesh": [[31, "mesh"]], "Partition spec": [[31, "partition-spec"]], "Which device holds which shard?": [[31, "which-device-holds-which-shard"]], "Distributed Checkpointing": [[32, "distributed-checkpointing"]], "CheckpointManager": [[32, "checkpointmanager"]], "Restoring Optimizer State": [[32, "restoring-optimizer-state"]], "Process Groups": [[32, "process-groups"]], "Running SPMD on GPU": [[33, "running-spmd-on-gpu"]]}, "indexentries": {"hybridmesh (class in torch_xla.distributed.spmd)": [[13, "torch_xla.distributed.spmd.HybridMesh"]], "mesh (class in torch_xla.distributed.spmd)": [[13, "torch_xla.distributed.spmd.Mesh"]], "mpdeviceloader (class in torch_xla.distributed.parallel_loader)": [[13, "torch_xla.distributed.parallel_loader.MpDeviceLoader"]], "add_step_closure() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.add_step_closure"]], "addressable_device_count() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.addressable_device_count"]], "all_gather() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.all_gather"]], "all_reduce() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.all_reduce"]], "all_to_all() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.all_to_all"]], "clear_sharding() (in module torch_xla.distributed.spmd)": [[13, "torch_xla.distributed.spmd.clear_sharding"]], "compile() (in module torch_xla)": [[13, "torch_xla.compile"]], "counter_names() (in module torch_xla.debug.metrics)": [[13, "torch_xla.debug.metrics.counter_names"]], "counter_value() (in module torch_xla.debug.metrics)": [[13, "torch_xla.debug.metrics.counter_value"]], "device() (in module torch_xla)": [[13, "torch_xla.device"]], "device_count() (in module torch_xla)": [[13, "torch_xla.device_count"]], "device_type() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.device_type"]], "devices() (in module torch_xla)": [[13, "torch_xla.devices"]], "eager_mode() (in module torch_xla.experimental)": [[13, "torch_xla.experimental.eager_mode"]], "get_1d_mesh() (in module torch_xla.distributed.spmd)": [[13, "torch_xla.distributed.spmd.get_1d_mesh"]], "get_global_mesh() (in module torch_xla.distributed.spmd)": [[13, "torch_xla.distributed.spmd.get_global_mesh"]], "get_master_ip() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.get_master_ip"]], "get_memory_info() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.get_memory_info"]], "get_rng_state() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.get_rng_state"]], "get_stablehlo() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.get_stablehlo"]], "get_stablehlo_bytecode() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.get_stablehlo_bytecode"]], "global_device_count() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.global_device_count"]], "global_ordinal() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.global_ordinal"]], "global_runtime_device_count() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.global_runtime_device_count"]], "initialize_cache() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.initialize_cache"]], "is_master_ordinal() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.is_master_ordinal"]], "is_spmd() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.is_spmd"]], "local_device_count() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.local_device_count"]], "local_ordinal() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.local_ordinal"]], "local_process_count() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.local_process_count"]], "manual_seed() (in module torch_xla)": [[13, "torch_xla.manual_seed"]], "mark_sharding() (in module torch_xla.distributed.spmd)": [[13, "torch_xla.distributed.spmd.mark_sharding"]], "mesh_reduce() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.mesh_reduce"]], "metric_data() (in module torch_xla.debug.metrics)": [[13, "torch_xla.debug.metrics.metric_data"]], "metric_names() (in module torch_xla.debug.metrics)": [[13, "torch_xla.debug.metrics.metric_names"]], "metrics_report() (in module torch_xla.debug.metrics)": [[13, "torch_xla.debug.metrics.metrics_report"]], "module": [[13, "module-torch_xla"], [13, "module-torch_xla.core.xla_model"], [13, "module-torch_xla.debug.metrics"], [13, "module-torch_xla.distributed.parallel_loader"], [13, "module-torch_xla.distributed.spmd"], [13, "module-torch_xla.distributed.xla_multiprocessing"], [13, "module-torch_xla.experimental"], [13, "module-torch_xla.runtime"]], "optimizer_step() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.optimizer_step"]], "rendezvous() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.rendezvous"]], "save() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.save"]], "set_global_mesh() (in module torch_xla.distributed.spmd)": [[13, "torch_xla.distributed.spmd.set_global_mesh"]], "set_rng_state() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.set_rng_state"]], "short_metrics_report() (in module torch_xla.debug.metrics)": [[13, "torch_xla.debug.metrics.short_metrics_report"]], "spawn() (in module torch_xla.distributed.xla_multiprocessing)": [[13, "torch_xla.distributed.xla_multiprocessing.spawn"]], "sync() (in module torch_xla)": [[13, "torch_xla.sync"]], "torch_xla": [[13, "module-torch_xla"]], "torch_xla.core.xla_model": [[13, "module-torch_xla.core.xla_model"]], "torch_xla.debug.metrics": [[13, "module-torch_xla.debug.metrics"]], "torch_xla.distributed.parallel_loader": [[13, "module-torch_xla.distributed.parallel_loader"]], "torch_xla.distributed.spmd": [[13, "module-torch_xla.distributed.spmd"]], "torch_xla.distributed.xla_multiprocessing": [[13, "module-torch_xla.distributed.xla_multiprocessing"]], "torch_xla.experimental": [[13, "module-torch_xla.experimental"]], "torch_xla.runtime": [[13, "module-torch_xla.runtime"]], "use_spmd() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.use_spmd"]], "wait_device_ops() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.wait_device_ops"]], "world_size() (in module torch_xla.runtime)": [[13, "torch_xla.runtime.world_size"]], "xla_device() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.xla_device"]], "xla_device_hw() (in module torch_xla.core.xla_model)": [[13, "torch_xla.core.xla_model.xla_device_hw"]]}})